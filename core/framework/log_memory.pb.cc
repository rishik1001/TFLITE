// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/log_memory.proto

#include "tensorflow/core/framework/log_memory.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG

namespace _pb = ::PROTOBUF_NAMESPACE_ID;
namespace _pbi = _pb::internal;

namespace tensorflow {
PROTOBUF_CONSTEXPR MemoryLogStep::MemoryLogStep(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.handle_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.step_id_)*/int64_t{0}
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct MemoryLogStepDefaultTypeInternal {
  PROTOBUF_CONSTEXPR MemoryLogStepDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~MemoryLogStepDefaultTypeInternal() {}
  union {
    MemoryLogStep _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 MemoryLogStepDefaultTypeInternal _MemoryLogStep_default_instance_;
PROTOBUF_CONSTEXPR MemoryLogTensorAllocation::MemoryLogTensorAllocation(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.kernel_name_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.tensor_)*/nullptr
  , /*decltype(_impl_.step_id_)*/int64_t{0}
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct MemoryLogTensorAllocationDefaultTypeInternal {
  PROTOBUF_CONSTEXPR MemoryLogTensorAllocationDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~MemoryLogTensorAllocationDefaultTypeInternal() {}
  union {
    MemoryLogTensorAllocation _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 MemoryLogTensorAllocationDefaultTypeInternal _MemoryLogTensorAllocation_default_instance_;
PROTOBUF_CONSTEXPR MemoryLogTensorDeallocation::MemoryLogTensorDeallocation(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.allocator_name_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.allocation_id_)*/int64_t{0}
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct MemoryLogTensorDeallocationDefaultTypeInternal {
  PROTOBUF_CONSTEXPR MemoryLogTensorDeallocationDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~MemoryLogTensorDeallocationDefaultTypeInternal() {}
  union {
    MemoryLogTensorDeallocation _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 MemoryLogTensorDeallocationDefaultTypeInternal _MemoryLogTensorDeallocation_default_instance_;
PROTOBUF_CONSTEXPR MemoryLogTensorOutput::MemoryLogTensorOutput(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.kernel_name_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.tensor_)*/nullptr
  , /*decltype(_impl_.step_id_)*/int64_t{0}
  , /*decltype(_impl_.index_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct MemoryLogTensorOutputDefaultTypeInternal {
  PROTOBUF_CONSTEXPR MemoryLogTensorOutputDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~MemoryLogTensorOutputDefaultTypeInternal() {}
  union {
    MemoryLogTensorOutput _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 MemoryLogTensorOutputDefaultTypeInternal _MemoryLogTensorOutput_default_instance_;
PROTOBUF_CONSTEXPR MemoryLogRawAllocation::MemoryLogRawAllocation(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.operation_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.allocator_name_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.step_id_)*/int64_t{0}
  , /*decltype(_impl_.num_bytes_)*/int64_t{0}
  , /*decltype(_impl_.ptr_)*/uint64_t{0u}
  , /*decltype(_impl_.allocation_id_)*/int64_t{0}
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct MemoryLogRawAllocationDefaultTypeInternal {
  PROTOBUF_CONSTEXPR MemoryLogRawAllocationDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~MemoryLogRawAllocationDefaultTypeInternal() {}
  union {
    MemoryLogRawAllocation _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 MemoryLogRawAllocationDefaultTypeInternal _MemoryLogRawAllocation_default_instance_;
PROTOBUF_CONSTEXPR MemoryLogRawDeallocation::MemoryLogRawDeallocation(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.operation_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.allocator_name_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.step_id_)*/int64_t{0}
  , /*decltype(_impl_.allocation_id_)*/int64_t{0}
  , /*decltype(_impl_.deferred_)*/false
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct MemoryLogRawDeallocationDefaultTypeInternal {
  PROTOBUF_CONSTEXPR MemoryLogRawDeallocationDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~MemoryLogRawDeallocationDefaultTypeInternal() {}
  union {
    MemoryLogRawDeallocation _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 MemoryLogRawDeallocationDefaultTypeInternal _MemoryLogRawDeallocation_default_instance_;
}  // namespace tensorflow
static ::_pb::Metadata file_level_metadata_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto[6];
static constexpr ::_pb::EnumDescriptor const** file_level_enum_descriptors_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto = nullptr;
static constexpr ::_pb::ServiceDescriptor const** file_level_service_descriptors_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto = nullptr;

const uint32_t TableStruct_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogStep, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogStep, _impl_.step_id_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogStep, _impl_.handle_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogTensorAllocation, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogTensorAllocation, _impl_.step_id_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogTensorAllocation, _impl_.kernel_name_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogTensorAllocation, _impl_.tensor_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogTensorDeallocation, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogTensorDeallocation, _impl_.allocation_id_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogTensorDeallocation, _impl_.allocator_name_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogTensorOutput, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogTensorOutput, _impl_.step_id_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogTensorOutput, _impl_.kernel_name_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogTensorOutput, _impl_.index_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogTensorOutput, _impl_.tensor_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawAllocation, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawAllocation, _impl_.step_id_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawAllocation, _impl_.operation_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawAllocation, _impl_.num_bytes_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawAllocation, _impl_.ptr_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawAllocation, _impl_.allocation_id_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawAllocation, _impl_.allocator_name_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawDeallocation, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawDeallocation, _impl_.step_id_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawDeallocation, _impl_.operation_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawDeallocation, _impl_.allocation_id_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawDeallocation, _impl_.allocator_name_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryLogRawDeallocation, _impl_.deferred_),
};
static const ::_pbi::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, -1, sizeof(::tensorflow::MemoryLogStep)},
  { 8, -1, -1, sizeof(::tensorflow::MemoryLogTensorAllocation)},
  { 17, -1, -1, sizeof(::tensorflow::MemoryLogTensorDeallocation)},
  { 25, -1, -1, sizeof(::tensorflow::MemoryLogTensorOutput)},
  { 35, -1, -1, sizeof(::tensorflow::MemoryLogRawAllocation)},
  { 47, -1, -1, sizeof(::tensorflow::MemoryLogRawDeallocation)},
};

static const ::_pb::Message* const file_default_instances[] = {
  &::tensorflow::_MemoryLogStep_default_instance_._instance,
  &::tensorflow::_MemoryLogTensorAllocation_default_instance_._instance,
  &::tensorflow::_MemoryLogTensorDeallocation_default_instance_._instance,
  &::tensorflow::_MemoryLogTensorOutput_default_instance_._instance,
  &::tensorflow::_MemoryLogRawAllocation_default_instance_._instance,
  &::tensorflow::_MemoryLogRawDeallocation_default_instance_._instance,
};

const char descriptor_table_protodef_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n*tensorflow/core/framework/log_memory.p"
  "roto\022\ntensorflow\0322tensorflow/core/framew"
  "ork/tensor_description.proto\"0\n\rMemoryLo"
  "gStep\022\017\n\007step_id\030\001 \001(\003\022\016\n\006handle\030\002 \001(\t\"p"
  "\n\031MemoryLogTensorAllocation\022\017\n\007step_id\030\001"
  " \001(\003\022\023\n\013kernel_name\030\002 \001(\t\022-\n\006tensor\030\003 \001("
  "\0132\035.tensorflow.TensorDescription\"L\n\033Memo"
  "ryLogTensorDeallocation\022\025\n\rallocation_id"
  "\030\001 \001(\003\022\026\n\016allocator_name\030\002 \001(\t\"{\n\025Memory"
  "LogTensorOutput\022\017\n\007step_id\030\001 \001(\003\022\023\n\013kern"
  "el_name\030\002 \001(\t\022\r\n\005index\030\003 \001(\005\022-\n\006tensor\030\004"
  " \001(\0132\035.tensorflow.TensorDescription\"\213\001\n\026"
  "MemoryLogRawAllocation\022\017\n\007step_id\030\001 \001(\003\022"
  "\021\n\toperation\030\002 \001(\t\022\021\n\tnum_bytes\030\003 \001(\003\022\013\n"
  "\003ptr\030\004 \001(\004\022\025\n\rallocation_id\030\005 \001(\003\022\026\n\016all"
  "ocator_name\030\006 \001(\t\"\177\n\030MemoryLogRawDealloc"
  "ation\022\017\n\007step_id\030\001 \001(\003\022\021\n\toperation\030\002 \001("
  "\t\022\025\n\rallocation_id\030\003 \001(\003\022\026\n\016allocator_na"
  "me\030\004 \001(\t\022\020\n\010deferred\030\005 \001(\010B\203\001\n\030org.tenso"
  "rflow.frameworkB\017LogMemoryProtosP\001ZQgith"
  "ub.com/tensorflow/tensorflow/tensorflow/"
  "go/core/framework/log_memory_go_proto\370\001\001"
  "b\006proto3"
  ;
static const ::_pbi::DescriptorTable* const descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_deps[1] = {
  &::descriptor_table_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto,
};
static ::_pbi::once_flag descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_once;
const ::_pbi::DescriptorTable descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto = {
    false, false, 888, descriptor_table_protodef_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto,
    "tensorflow/core/framework/log_memory.proto",
    &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_once, descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_deps, 1, 6,
    schemas, file_default_instances, TableStruct_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto::offsets,
    file_level_metadata_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto, file_level_enum_descriptors_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto,
    file_level_service_descriptors_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto,
};
PROTOBUF_ATTRIBUTE_WEAK const ::_pbi::DescriptorTable* descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_getter() {
  return &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto;
}

// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::_pbi::AddDescriptorsRunner dynamic_init_dummy_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto(&descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto);
namespace tensorflow {

// ===================================================================

class MemoryLogStep::_Internal {
 public:
};

MemoryLogStep::MemoryLogStep(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.MemoryLogStep)
}
MemoryLogStep::MemoryLogStep(const MemoryLogStep& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  MemoryLogStep* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.handle_){}
    , decltype(_impl_.step_id_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _impl_.handle_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.handle_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_handle().empty()) {
    _this->_impl_.handle_.Set(from._internal_handle(), 
      _this->GetArenaForAllocation());
  }
  _this->_impl_.step_id_ = from._impl_.step_id_;
  // @@protoc_insertion_point(copy_constructor:tensorflow.MemoryLogStep)
}

inline void MemoryLogStep::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.handle_){}
    , decltype(_impl_.step_id_){int64_t{0}}
    , /*decltype(_impl_._cached_size_)*/{}
  };
  _impl_.handle_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.handle_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

MemoryLogStep::~MemoryLogStep() {
  // @@protoc_insertion_point(destructor:tensorflow.MemoryLogStep)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void MemoryLogStep::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.handle_.Destroy();
}

void MemoryLogStep::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void MemoryLogStep::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.MemoryLogStep)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.handle_.ClearToEmpty();
  _impl_.step_id_ = int64_t{0};
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* MemoryLogStep::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int64 step_id = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.step_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // string handle = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          auto str = _internal_mutable_handle();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "tensorflow.MemoryLogStep.handle"));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* MemoryLogStep::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.MemoryLogStep)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int64 step_id = 1;
  if (this->_internal_step_id() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt64ToArray(1, this->_internal_step_id(), target);
  }

  // string handle = 2;
  if (!this->_internal_handle().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_handle().data(), static_cast<int>(this->_internal_handle().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.MemoryLogStep.handle");
    target = stream->WriteStringMaybeAliased(
        2, this->_internal_handle(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.MemoryLogStep)
  return target;
}

size_t MemoryLogStep::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.MemoryLogStep)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // string handle = 2;
  if (!this->_internal_handle().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_handle());
  }

  // int64 step_id = 1;
  if (this->_internal_step_id() != 0) {
    total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(this->_internal_step_id());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData MemoryLogStep::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    MemoryLogStep::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*MemoryLogStep::GetClassData() const { return &_class_data_; }


void MemoryLogStep::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<MemoryLogStep*>(&to_msg);
  auto& from = static_cast<const MemoryLogStep&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.MemoryLogStep)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_handle().empty()) {
    _this->_internal_set_handle(from._internal_handle());
  }
  if (from._internal_step_id() != 0) {
    _this->_internal_set_step_id(from._internal_step_id());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void MemoryLogStep::CopyFrom(const MemoryLogStep& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.MemoryLogStep)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool MemoryLogStep::IsInitialized() const {
  return true;
}

void MemoryLogStep::InternalSwap(MemoryLogStep* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.handle_, lhs_arena,
      &other->_impl_.handle_, rhs_arena
  );
  swap(_impl_.step_id_, other->_impl_.step_id_);
}

::PROTOBUF_NAMESPACE_ID::Metadata MemoryLogStep::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto[0]);
}

// ===================================================================

class MemoryLogTensorAllocation::_Internal {
 public:
  static const ::tensorflow::TensorDescription& tensor(const MemoryLogTensorAllocation* msg);
};

const ::tensorflow::TensorDescription&
MemoryLogTensorAllocation::_Internal::tensor(const MemoryLogTensorAllocation* msg) {
  return *msg->_impl_.tensor_;
}
void MemoryLogTensorAllocation::clear_tensor() {
  if (GetArenaForAllocation() == nullptr && _impl_.tensor_ != nullptr) {
    delete _impl_.tensor_;
  }
  _impl_.tensor_ = nullptr;
}
MemoryLogTensorAllocation::MemoryLogTensorAllocation(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.MemoryLogTensorAllocation)
}
MemoryLogTensorAllocation::MemoryLogTensorAllocation(const MemoryLogTensorAllocation& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  MemoryLogTensorAllocation* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.kernel_name_){}
    , decltype(_impl_.tensor_){nullptr}
    , decltype(_impl_.step_id_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _impl_.kernel_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.kernel_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_kernel_name().empty()) {
    _this->_impl_.kernel_name_.Set(from._internal_kernel_name(), 
      _this->GetArenaForAllocation());
  }
  if (from._internal_has_tensor()) {
    _this->_impl_.tensor_ = new ::tensorflow::TensorDescription(*from._impl_.tensor_);
  }
  _this->_impl_.step_id_ = from._impl_.step_id_;
  // @@protoc_insertion_point(copy_constructor:tensorflow.MemoryLogTensorAllocation)
}

inline void MemoryLogTensorAllocation::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.kernel_name_){}
    , decltype(_impl_.tensor_){nullptr}
    , decltype(_impl_.step_id_){int64_t{0}}
    , /*decltype(_impl_._cached_size_)*/{}
  };
  _impl_.kernel_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.kernel_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

MemoryLogTensorAllocation::~MemoryLogTensorAllocation() {
  // @@protoc_insertion_point(destructor:tensorflow.MemoryLogTensorAllocation)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void MemoryLogTensorAllocation::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.kernel_name_.Destroy();
  if (this != internal_default_instance()) delete _impl_.tensor_;
}

void MemoryLogTensorAllocation::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void MemoryLogTensorAllocation::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.MemoryLogTensorAllocation)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.kernel_name_.ClearToEmpty();
  if (GetArenaForAllocation() == nullptr && _impl_.tensor_ != nullptr) {
    delete _impl_.tensor_;
  }
  _impl_.tensor_ = nullptr;
  _impl_.step_id_ = int64_t{0};
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* MemoryLogTensorAllocation::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int64 step_id = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.step_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // string kernel_name = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          auto str = _internal_mutable_kernel_name();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "tensorflow.MemoryLogTensorAllocation.kernel_name"));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.TensorDescription tensor = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr = ctx->ParseMessage(_internal_mutable_tensor(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* MemoryLogTensorAllocation::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.MemoryLogTensorAllocation)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int64 step_id = 1;
  if (this->_internal_step_id() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt64ToArray(1, this->_internal_step_id(), target);
  }

  // string kernel_name = 2;
  if (!this->_internal_kernel_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_kernel_name().data(), static_cast<int>(this->_internal_kernel_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.MemoryLogTensorAllocation.kernel_name");
    target = stream->WriteStringMaybeAliased(
        2, this->_internal_kernel_name(), target);
  }

  // .tensorflow.TensorDescription tensor = 3;
  if (this->_internal_has_tensor()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(3, _Internal::tensor(this),
        _Internal::tensor(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.MemoryLogTensorAllocation)
  return target;
}

size_t MemoryLogTensorAllocation::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.MemoryLogTensorAllocation)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // string kernel_name = 2;
  if (!this->_internal_kernel_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_kernel_name());
  }

  // .tensorflow.TensorDescription tensor = 3;
  if (this->_internal_has_tensor()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.tensor_);
  }

  // int64 step_id = 1;
  if (this->_internal_step_id() != 0) {
    total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(this->_internal_step_id());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData MemoryLogTensorAllocation::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    MemoryLogTensorAllocation::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*MemoryLogTensorAllocation::GetClassData() const { return &_class_data_; }


void MemoryLogTensorAllocation::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<MemoryLogTensorAllocation*>(&to_msg);
  auto& from = static_cast<const MemoryLogTensorAllocation&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.MemoryLogTensorAllocation)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_kernel_name().empty()) {
    _this->_internal_set_kernel_name(from._internal_kernel_name());
  }
  if (from._internal_has_tensor()) {
    _this->_internal_mutable_tensor()->::tensorflow::TensorDescription::MergeFrom(
        from._internal_tensor());
  }
  if (from._internal_step_id() != 0) {
    _this->_internal_set_step_id(from._internal_step_id());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void MemoryLogTensorAllocation::CopyFrom(const MemoryLogTensorAllocation& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.MemoryLogTensorAllocation)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool MemoryLogTensorAllocation::IsInitialized() const {
  return true;
}

void MemoryLogTensorAllocation::InternalSwap(MemoryLogTensorAllocation* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.kernel_name_, lhs_arena,
      &other->_impl_.kernel_name_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(MemoryLogTensorAllocation, _impl_.step_id_)
      + sizeof(MemoryLogTensorAllocation::_impl_.step_id_)
      - PROTOBUF_FIELD_OFFSET(MemoryLogTensorAllocation, _impl_.tensor_)>(
          reinterpret_cast<char*>(&_impl_.tensor_),
          reinterpret_cast<char*>(&other->_impl_.tensor_));
}

::PROTOBUF_NAMESPACE_ID::Metadata MemoryLogTensorAllocation::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto[1]);
}

// ===================================================================

class MemoryLogTensorDeallocation::_Internal {
 public:
};

MemoryLogTensorDeallocation::MemoryLogTensorDeallocation(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.MemoryLogTensorDeallocation)
}
MemoryLogTensorDeallocation::MemoryLogTensorDeallocation(const MemoryLogTensorDeallocation& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  MemoryLogTensorDeallocation* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.allocator_name_){}
    , decltype(_impl_.allocation_id_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _impl_.allocator_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.allocator_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_allocator_name().empty()) {
    _this->_impl_.allocator_name_.Set(from._internal_allocator_name(), 
      _this->GetArenaForAllocation());
  }
  _this->_impl_.allocation_id_ = from._impl_.allocation_id_;
  // @@protoc_insertion_point(copy_constructor:tensorflow.MemoryLogTensorDeallocation)
}

inline void MemoryLogTensorDeallocation::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.allocator_name_){}
    , decltype(_impl_.allocation_id_){int64_t{0}}
    , /*decltype(_impl_._cached_size_)*/{}
  };
  _impl_.allocator_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.allocator_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

MemoryLogTensorDeallocation::~MemoryLogTensorDeallocation() {
  // @@protoc_insertion_point(destructor:tensorflow.MemoryLogTensorDeallocation)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void MemoryLogTensorDeallocation::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.allocator_name_.Destroy();
}

void MemoryLogTensorDeallocation::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void MemoryLogTensorDeallocation::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.MemoryLogTensorDeallocation)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.allocator_name_.ClearToEmpty();
  _impl_.allocation_id_ = int64_t{0};
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* MemoryLogTensorDeallocation::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int64 allocation_id = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.allocation_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // string allocator_name = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          auto str = _internal_mutable_allocator_name();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "tensorflow.MemoryLogTensorDeallocation.allocator_name"));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* MemoryLogTensorDeallocation::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.MemoryLogTensorDeallocation)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int64 allocation_id = 1;
  if (this->_internal_allocation_id() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt64ToArray(1, this->_internal_allocation_id(), target);
  }

  // string allocator_name = 2;
  if (!this->_internal_allocator_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_allocator_name().data(), static_cast<int>(this->_internal_allocator_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.MemoryLogTensorDeallocation.allocator_name");
    target = stream->WriteStringMaybeAliased(
        2, this->_internal_allocator_name(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.MemoryLogTensorDeallocation)
  return target;
}

size_t MemoryLogTensorDeallocation::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.MemoryLogTensorDeallocation)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // string allocator_name = 2;
  if (!this->_internal_allocator_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_allocator_name());
  }

  // int64 allocation_id = 1;
  if (this->_internal_allocation_id() != 0) {
    total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(this->_internal_allocation_id());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData MemoryLogTensorDeallocation::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    MemoryLogTensorDeallocation::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*MemoryLogTensorDeallocation::GetClassData() const { return &_class_data_; }


void MemoryLogTensorDeallocation::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<MemoryLogTensorDeallocation*>(&to_msg);
  auto& from = static_cast<const MemoryLogTensorDeallocation&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.MemoryLogTensorDeallocation)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_allocator_name().empty()) {
    _this->_internal_set_allocator_name(from._internal_allocator_name());
  }
  if (from._internal_allocation_id() != 0) {
    _this->_internal_set_allocation_id(from._internal_allocation_id());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void MemoryLogTensorDeallocation::CopyFrom(const MemoryLogTensorDeallocation& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.MemoryLogTensorDeallocation)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool MemoryLogTensorDeallocation::IsInitialized() const {
  return true;
}

void MemoryLogTensorDeallocation::InternalSwap(MemoryLogTensorDeallocation* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.allocator_name_, lhs_arena,
      &other->_impl_.allocator_name_, rhs_arena
  );
  swap(_impl_.allocation_id_, other->_impl_.allocation_id_);
}

::PROTOBUF_NAMESPACE_ID::Metadata MemoryLogTensorDeallocation::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto[2]);
}

// ===================================================================

class MemoryLogTensorOutput::_Internal {
 public:
  static const ::tensorflow::TensorDescription& tensor(const MemoryLogTensorOutput* msg);
};

const ::tensorflow::TensorDescription&
MemoryLogTensorOutput::_Internal::tensor(const MemoryLogTensorOutput* msg) {
  return *msg->_impl_.tensor_;
}
void MemoryLogTensorOutput::clear_tensor() {
  if (GetArenaForAllocation() == nullptr && _impl_.tensor_ != nullptr) {
    delete _impl_.tensor_;
  }
  _impl_.tensor_ = nullptr;
}
MemoryLogTensorOutput::MemoryLogTensorOutput(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.MemoryLogTensorOutput)
}
MemoryLogTensorOutput::MemoryLogTensorOutput(const MemoryLogTensorOutput& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  MemoryLogTensorOutput* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.kernel_name_){}
    , decltype(_impl_.tensor_){nullptr}
    , decltype(_impl_.step_id_){}
    , decltype(_impl_.index_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _impl_.kernel_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.kernel_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_kernel_name().empty()) {
    _this->_impl_.kernel_name_.Set(from._internal_kernel_name(), 
      _this->GetArenaForAllocation());
  }
  if (from._internal_has_tensor()) {
    _this->_impl_.tensor_ = new ::tensorflow::TensorDescription(*from._impl_.tensor_);
  }
  ::memcpy(&_impl_.step_id_, &from._impl_.step_id_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.index_) -
    reinterpret_cast<char*>(&_impl_.step_id_)) + sizeof(_impl_.index_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.MemoryLogTensorOutput)
}

inline void MemoryLogTensorOutput::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.kernel_name_){}
    , decltype(_impl_.tensor_){nullptr}
    , decltype(_impl_.step_id_){int64_t{0}}
    , decltype(_impl_.index_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
  _impl_.kernel_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.kernel_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

MemoryLogTensorOutput::~MemoryLogTensorOutput() {
  // @@protoc_insertion_point(destructor:tensorflow.MemoryLogTensorOutput)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void MemoryLogTensorOutput::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.kernel_name_.Destroy();
  if (this != internal_default_instance()) delete _impl_.tensor_;
}

void MemoryLogTensorOutput::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void MemoryLogTensorOutput::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.MemoryLogTensorOutput)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.kernel_name_.ClearToEmpty();
  if (GetArenaForAllocation() == nullptr && _impl_.tensor_ != nullptr) {
    delete _impl_.tensor_;
  }
  _impl_.tensor_ = nullptr;
  ::memset(&_impl_.step_id_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.index_) -
      reinterpret_cast<char*>(&_impl_.step_id_)) + sizeof(_impl_.index_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* MemoryLogTensorOutput::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int64 step_id = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.step_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // string kernel_name = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          auto str = _internal_mutable_kernel_name();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "tensorflow.MemoryLogTensorOutput.kernel_name"));
        } else
          goto handle_unusual;
        continue;
      // int32 index = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _impl_.index_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.TensorDescription tensor = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
          ptr = ctx->ParseMessage(_internal_mutable_tensor(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* MemoryLogTensorOutput::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.MemoryLogTensorOutput)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int64 step_id = 1;
  if (this->_internal_step_id() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt64ToArray(1, this->_internal_step_id(), target);
  }

  // string kernel_name = 2;
  if (!this->_internal_kernel_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_kernel_name().data(), static_cast<int>(this->_internal_kernel_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.MemoryLogTensorOutput.kernel_name");
    target = stream->WriteStringMaybeAliased(
        2, this->_internal_kernel_name(), target);
  }

  // int32 index = 3;
  if (this->_internal_index() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(3, this->_internal_index(), target);
  }

  // .tensorflow.TensorDescription tensor = 4;
  if (this->_internal_has_tensor()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(4, _Internal::tensor(this),
        _Internal::tensor(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.MemoryLogTensorOutput)
  return target;
}

size_t MemoryLogTensorOutput::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.MemoryLogTensorOutput)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // string kernel_name = 2;
  if (!this->_internal_kernel_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_kernel_name());
  }

  // .tensorflow.TensorDescription tensor = 4;
  if (this->_internal_has_tensor()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.tensor_);
  }

  // int64 step_id = 1;
  if (this->_internal_step_id() != 0) {
    total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(this->_internal_step_id());
  }

  // int32 index = 3;
  if (this->_internal_index() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_index());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData MemoryLogTensorOutput::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    MemoryLogTensorOutput::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*MemoryLogTensorOutput::GetClassData() const { return &_class_data_; }


void MemoryLogTensorOutput::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<MemoryLogTensorOutput*>(&to_msg);
  auto& from = static_cast<const MemoryLogTensorOutput&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.MemoryLogTensorOutput)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_kernel_name().empty()) {
    _this->_internal_set_kernel_name(from._internal_kernel_name());
  }
  if (from._internal_has_tensor()) {
    _this->_internal_mutable_tensor()->::tensorflow::TensorDescription::MergeFrom(
        from._internal_tensor());
  }
  if (from._internal_step_id() != 0) {
    _this->_internal_set_step_id(from._internal_step_id());
  }
  if (from._internal_index() != 0) {
    _this->_internal_set_index(from._internal_index());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void MemoryLogTensorOutput::CopyFrom(const MemoryLogTensorOutput& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.MemoryLogTensorOutput)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool MemoryLogTensorOutput::IsInitialized() const {
  return true;
}

void MemoryLogTensorOutput::InternalSwap(MemoryLogTensorOutput* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.kernel_name_, lhs_arena,
      &other->_impl_.kernel_name_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(MemoryLogTensorOutput, _impl_.index_)
      + sizeof(MemoryLogTensorOutput::_impl_.index_)
      - PROTOBUF_FIELD_OFFSET(MemoryLogTensorOutput, _impl_.tensor_)>(
          reinterpret_cast<char*>(&_impl_.tensor_),
          reinterpret_cast<char*>(&other->_impl_.tensor_));
}

::PROTOBUF_NAMESPACE_ID::Metadata MemoryLogTensorOutput::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto[3]);
}

// ===================================================================

class MemoryLogRawAllocation::_Internal {
 public:
};

MemoryLogRawAllocation::MemoryLogRawAllocation(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.MemoryLogRawAllocation)
}
MemoryLogRawAllocation::MemoryLogRawAllocation(const MemoryLogRawAllocation& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  MemoryLogRawAllocation* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.operation_){}
    , decltype(_impl_.allocator_name_){}
    , decltype(_impl_.step_id_){}
    , decltype(_impl_.num_bytes_){}
    , decltype(_impl_.ptr_){}
    , decltype(_impl_.allocation_id_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _impl_.operation_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.operation_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_operation().empty()) {
    _this->_impl_.operation_.Set(from._internal_operation(), 
      _this->GetArenaForAllocation());
  }
  _impl_.allocator_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.allocator_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_allocator_name().empty()) {
    _this->_impl_.allocator_name_.Set(from._internal_allocator_name(), 
      _this->GetArenaForAllocation());
  }
  ::memcpy(&_impl_.step_id_, &from._impl_.step_id_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.allocation_id_) -
    reinterpret_cast<char*>(&_impl_.step_id_)) + sizeof(_impl_.allocation_id_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.MemoryLogRawAllocation)
}

inline void MemoryLogRawAllocation::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.operation_){}
    , decltype(_impl_.allocator_name_){}
    , decltype(_impl_.step_id_){int64_t{0}}
    , decltype(_impl_.num_bytes_){int64_t{0}}
    , decltype(_impl_.ptr_){uint64_t{0u}}
    , decltype(_impl_.allocation_id_){int64_t{0}}
    , /*decltype(_impl_._cached_size_)*/{}
  };
  _impl_.operation_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.operation_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  _impl_.allocator_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.allocator_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

MemoryLogRawAllocation::~MemoryLogRawAllocation() {
  // @@protoc_insertion_point(destructor:tensorflow.MemoryLogRawAllocation)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void MemoryLogRawAllocation::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.operation_.Destroy();
  _impl_.allocator_name_.Destroy();
}

void MemoryLogRawAllocation::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void MemoryLogRawAllocation::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.MemoryLogRawAllocation)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.operation_.ClearToEmpty();
  _impl_.allocator_name_.ClearToEmpty();
  ::memset(&_impl_.step_id_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.allocation_id_) -
      reinterpret_cast<char*>(&_impl_.step_id_)) + sizeof(_impl_.allocation_id_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* MemoryLogRawAllocation::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int64 step_id = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.step_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // string operation = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          auto str = _internal_mutable_operation();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "tensorflow.MemoryLogRawAllocation.operation"));
        } else
          goto handle_unusual;
        continue;
      // int64 num_bytes = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _impl_.num_bytes_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 ptr = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          _impl_.ptr_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int64 allocation_id = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 40)) {
          _impl_.allocation_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // string allocator_name = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 50)) {
          auto str = _internal_mutable_allocator_name();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "tensorflow.MemoryLogRawAllocation.allocator_name"));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* MemoryLogRawAllocation::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.MemoryLogRawAllocation)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int64 step_id = 1;
  if (this->_internal_step_id() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt64ToArray(1, this->_internal_step_id(), target);
  }

  // string operation = 2;
  if (!this->_internal_operation().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_operation().data(), static_cast<int>(this->_internal_operation().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.MemoryLogRawAllocation.operation");
    target = stream->WriteStringMaybeAliased(
        2, this->_internal_operation(), target);
  }

  // int64 num_bytes = 3;
  if (this->_internal_num_bytes() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt64ToArray(3, this->_internal_num_bytes(), target);
  }

  // uint64 ptr = 4;
  if (this->_internal_ptr() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(4, this->_internal_ptr(), target);
  }

  // int64 allocation_id = 5;
  if (this->_internal_allocation_id() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt64ToArray(5, this->_internal_allocation_id(), target);
  }

  // string allocator_name = 6;
  if (!this->_internal_allocator_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_allocator_name().data(), static_cast<int>(this->_internal_allocator_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.MemoryLogRawAllocation.allocator_name");
    target = stream->WriteStringMaybeAliased(
        6, this->_internal_allocator_name(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.MemoryLogRawAllocation)
  return target;
}

size_t MemoryLogRawAllocation::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.MemoryLogRawAllocation)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // string operation = 2;
  if (!this->_internal_operation().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_operation());
  }

  // string allocator_name = 6;
  if (!this->_internal_allocator_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_allocator_name());
  }

  // int64 step_id = 1;
  if (this->_internal_step_id() != 0) {
    total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(this->_internal_step_id());
  }

  // int64 num_bytes = 3;
  if (this->_internal_num_bytes() != 0) {
    total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(this->_internal_num_bytes());
  }

  // uint64 ptr = 4;
  if (this->_internal_ptr() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_ptr());
  }

  // int64 allocation_id = 5;
  if (this->_internal_allocation_id() != 0) {
    total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(this->_internal_allocation_id());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData MemoryLogRawAllocation::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    MemoryLogRawAllocation::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*MemoryLogRawAllocation::GetClassData() const { return &_class_data_; }


void MemoryLogRawAllocation::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<MemoryLogRawAllocation*>(&to_msg);
  auto& from = static_cast<const MemoryLogRawAllocation&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.MemoryLogRawAllocation)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_operation().empty()) {
    _this->_internal_set_operation(from._internal_operation());
  }
  if (!from._internal_allocator_name().empty()) {
    _this->_internal_set_allocator_name(from._internal_allocator_name());
  }
  if (from._internal_step_id() != 0) {
    _this->_internal_set_step_id(from._internal_step_id());
  }
  if (from._internal_num_bytes() != 0) {
    _this->_internal_set_num_bytes(from._internal_num_bytes());
  }
  if (from._internal_ptr() != 0) {
    _this->_internal_set_ptr(from._internal_ptr());
  }
  if (from._internal_allocation_id() != 0) {
    _this->_internal_set_allocation_id(from._internal_allocation_id());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void MemoryLogRawAllocation::CopyFrom(const MemoryLogRawAllocation& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.MemoryLogRawAllocation)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool MemoryLogRawAllocation::IsInitialized() const {
  return true;
}

void MemoryLogRawAllocation::InternalSwap(MemoryLogRawAllocation* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.operation_, lhs_arena,
      &other->_impl_.operation_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.allocator_name_, lhs_arena,
      &other->_impl_.allocator_name_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(MemoryLogRawAllocation, _impl_.allocation_id_)
      + sizeof(MemoryLogRawAllocation::_impl_.allocation_id_)
      - PROTOBUF_FIELD_OFFSET(MemoryLogRawAllocation, _impl_.step_id_)>(
          reinterpret_cast<char*>(&_impl_.step_id_),
          reinterpret_cast<char*>(&other->_impl_.step_id_));
}

::PROTOBUF_NAMESPACE_ID::Metadata MemoryLogRawAllocation::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto[4]);
}

// ===================================================================

class MemoryLogRawDeallocation::_Internal {
 public:
};

MemoryLogRawDeallocation::MemoryLogRawDeallocation(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.MemoryLogRawDeallocation)
}
MemoryLogRawDeallocation::MemoryLogRawDeallocation(const MemoryLogRawDeallocation& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  MemoryLogRawDeallocation* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.operation_){}
    , decltype(_impl_.allocator_name_){}
    , decltype(_impl_.step_id_){}
    , decltype(_impl_.allocation_id_){}
    , decltype(_impl_.deferred_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _impl_.operation_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.operation_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_operation().empty()) {
    _this->_impl_.operation_.Set(from._internal_operation(), 
      _this->GetArenaForAllocation());
  }
  _impl_.allocator_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.allocator_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_allocator_name().empty()) {
    _this->_impl_.allocator_name_.Set(from._internal_allocator_name(), 
      _this->GetArenaForAllocation());
  }
  ::memcpy(&_impl_.step_id_, &from._impl_.step_id_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.deferred_) -
    reinterpret_cast<char*>(&_impl_.step_id_)) + sizeof(_impl_.deferred_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.MemoryLogRawDeallocation)
}

inline void MemoryLogRawDeallocation::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.operation_){}
    , decltype(_impl_.allocator_name_){}
    , decltype(_impl_.step_id_){int64_t{0}}
    , decltype(_impl_.allocation_id_){int64_t{0}}
    , decltype(_impl_.deferred_){false}
    , /*decltype(_impl_._cached_size_)*/{}
  };
  _impl_.operation_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.operation_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  _impl_.allocator_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.allocator_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

MemoryLogRawDeallocation::~MemoryLogRawDeallocation() {
  // @@protoc_insertion_point(destructor:tensorflow.MemoryLogRawDeallocation)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void MemoryLogRawDeallocation::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.operation_.Destroy();
  _impl_.allocator_name_.Destroy();
}

void MemoryLogRawDeallocation::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void MemoryLogRawDeallocation::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.MemoryLogRawDeallocation)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.operation_.ClearToEmpty();
  _impl_.allocator_name_.ClearToEmpty();
  ::memset(&_impl_.step_id_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.deferred_) -
      reinterpret_cast<char*>(&_impl_.step_id_)) + sizeof(_impl_.deferred_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* MemoryLogRawDeallocation::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int64 step_id = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.step_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // string operation = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          auto str = _internal_mutable_operation();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "tensorflow.MemoryLogRawDeallocation.operation"));
        } else
          goto handle_unusual;
        continue;
      // int64 allocation_id = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _impl_.allocation_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // string allocator_name = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
          auto str = _internal_mutable_allocator_name();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "tensorflow.MemoryLogRawDeallocation.allocator_name"));
        } else
          goto handle_unusual;
        continue;
      // bool deferred = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 40)) {
          _impl_.deferred_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* MemoryLogRawDeallocation::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.MemoryLogRawDeallocation)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int64 step_id = 1;
  if (this->_internal_step_id() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt64ToArray(1, this->_internal_step_id(), target);
  }

  // string operation = 2;
  if (!this->_internal_operation().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_operation().data(), static_cast<int>(this->_internal_operation().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.MemoryLogRawDeallocation.operation");
    target = stream->WriteStringMaybeAliased(
        2, this->_internal_operation(), target);
  }

  // int64 allocation_id = 3;
  if (this->_internal_allocation_id() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt64ToArray(3, this->_internal_allocation_id(), target);
  }

  // string allocator_name = 4;
  if (!this->_internal_allocator_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_allocator_name().data(), static_cast<int>(this->_internal_allocator_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.MemoryLogRawDeallocation.allocator_name");
    target = stream->WriteStringMaybeAliased(
        4, this->_internal_allocator_name(), target);
  }

  // bool deferred = 5;
  if (this->_internal_deferred() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(5, this->_internal_deferred(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.MemoryLogRawDeallocation)
  return target;
}

size_t MemoryLogRawDeallocation::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.MemoryLogRawDeallocation)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // string operation = 2;
  if (!this->_internal_operation().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_operation());
  }

  // string allocator_name = 4;
  if (!this->_internal_allocator_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_allocator_name());
  }

  // int64 step_id = 1;
  if (this->_internal_step_id() != 0) {
    total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(this->_internal_step_id());
  }

  // int64 allocation_id = 3;
  if (this->_internal_allocation_id() != 0) {
    total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(this->_internal_allocation_id());
  }

  // bool deferred = 5;
  if (this->_internal_deferred() != 0) {
    total_size += 1 + 1;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData MemoryLogRawDeallocation::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    MemoryLogRawDeallocation::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*MemoryLogRawDeallocation::GetClassData() const { return &_class_data_; }


void MemoryLogRawDeallocation::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<MemoryLogRawDeallocation*>(&to_msg);
  auto& from = static_cast<const MemoryLogRawDeallocation&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.MemoryLogRawDeallocation)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_operation().empty()) {
    _this->_internal_set_operation(from._internal_operation());
  }
  if (!from._internal_allocator_name().empty()) {
    _this->_internal_set_allocator_name(from._internal_allocator_name());
  }
  if (from._internal_step_id() != 0) {
    _this->_internal_set_step_id(from._internal_step_id());
  }
  if (from._internal_allocation_id() != 0) {
    _this->_internal_set_allocation_id(from._internal_allocation_id());
  }
  if (from._internal_deferred() != 0) {
    _this->_internal_set_deferred(from._internal_deferred());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void MemoryLogRawDeallocation::CopyFrom(const MemoryLogRawDeallocation& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.MemoryLogRawDeallocation)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool MemoryLogRawDeallocation::IsInitialized() const {
  return true;
}

void MemoryLogRawDeallocation::InternalSwap(MemoryLogRawDeallocation* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.operation_, lhs_arena,
      &other->_impl_.operation_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.allocator_name_, lhs_arena,
      &other->_impl_.allocator_name_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(MemoryLogRawDeallocation, _impl_.deferred_)
      + sizeof(MemoryLogRawDeallocation::_impl_.deferred_)
      - PROTOBUF_FIELD_OFFSET(MemoryLogRawDeallocation, _impl_.step_id_)>(
          reinterpret_cast<char*>(&_impl_.step_id_),
          reinterpret_cast<char*>(&other->_impl_.step_id_));
}

::PROTOBUF_NAMESPACE_ID::Metadata MemoryLogRawDeallocation::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fframework_2flog_5fmemory_2eproto[5]);
}

// @@protoc_insertion_point(namespace_scope)
}  // namespace tensorflow
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::tensorflow::MemoryLogStep*
Arena::CreateMaybeMessage< ::tensorflow::MemoryLogStep >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::MemoryLogStep >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::MemoryLogTensorAllocation*
Arena::CreateMaybeMessage< ::tensorflow::MemoryLogTensorAllocation >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::MemoryLogTensorAllocation >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::MemoryLogTensorDeallocation*
Arena::CreateMaybeMessage< ::tensorflow::MemoryLogTensorDeallocation >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::MemoryLogTensorDeallocation >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::MemoryLogTensorOutput*
Arena::CreateMaybeMessage< ::tensorflow::MemoryLogTensorOutput >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::MemoryLogTensorOutput >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::MemoryLogRawAllocation*
Arena::CreateMaybeMessage< ::tensorflow::MemoryLogRawAllocation >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::MemoryLogRawAllocation >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::MemoryLogRawDeallocation*
Arena::CreateMaybeMessage< ::tensorflow::MemoryLogRawDeallocation >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::MemoryLogRawDeallocation >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
