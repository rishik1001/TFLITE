// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/tensor.proto

#include "tensorflow/core/framework/tensor.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG

namespace _pb = ::PROTOBUF_NAMESPACE_ID;
namespace _pbi = _pb::internal;

namespace tensorflow {
PROTOBUF_CONSTEXPR TensorProto::TensorProto(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.float_val_)*/{}
  , /*decltype(_impl_.double_val_)*/{}
  , /*decltype(_impl_.int_val_)*/{}
  , /*decltype(_impl_._int_val_cached_byte_size_)*/{0}
  , /*decltype(_impl_.string_val_)*/{}
  , /*decltype(_impl_.scomplex_val_)*/{}
  , /*decltype(_impl_.int64_val_)*/{}
  , /*decltype(_impl_._int64_val_cached_byte_size_)*/{0}
  , /*decltype(_impl_.bool_val_)*/{}
  , /*decltype(_impl_.dcomplex_val_)*/{}
  , /*decltype(_impl_.half_val_)*/{}
  , /*decltype(_impl_._half_val_cached_byte_size_)*/{0}
  , /*decltype(_impl_.resource_handle_val_)*/{}
  , /*decltype(_impl_.variant_val_)*/{}
  , /*decltype(_impl_.uint32_val_)*/{}
  , /*decltype(_impl_._uint32_val_cached_byte_size_)*/{0}
  , /*decltype(_impl_.uint64_val_)*/{}
  , /*decltype(_impl_._uint64_val_cached_byte_size_)*/{0}
  , /*decltype(_impl_.tensor_content_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.float8_val_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.tensor_shape_)*/nullptr
  , /*decltype(_impl_.dtype_)*/0
  , /*decltype(_impl_.version_number_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct TensorProtoDefaultTypeInternal {
  PROTOBUF_CONSTEXPR TensorProtoDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~TensorProtoDefaultTypeInternal() {}
  union {
    TensorProto _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 TensorProtoDefaultTypeInternal _TensorProto_default_instance_;
PROTOBUF_CONSTEXPR VariantTensorDataProto::VariantTensorDataProto(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.tensors_)*/{}
  , /*decltype(_impl_.type_name_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.metadata_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct VariantTensorDataProtoDefaultTypeInternal {
  PROTOBUF_CONSTEXPR VariantTensorDataProtoDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~VariantTensorDataProtoDefaultTypeInternal() {}
  union {
    VariantTensorDataProto _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 VariantTensorDataProtoDefaultTypeInternal _VariantTensorDataProto_default_instance_;
}  // namespace tensorflow
static ::_pb::Metadata file_level_metadata_tensorflow_2fcore_2fframework_2ftensor_2eproto[2];
static constexpr ::_pb::EnumDescriptor const** file_level_enum_descriptors_tensorflow_2fcore_2fframework_2ftensor_2eproto = nullptr;
static constexpr ::_pb::ServiceDescriptor const** file_level_service_descriptors_tensorflow_2fcore_2fframework_2ftensor_2eproto = nullptr;

const uint32_t TableStruct_tensorflow_2fcore_2fframework_2ftensor_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.dtype_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.tensor_shape_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.version_number_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.tensor_content_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.half_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.float_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.double_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.int_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.string_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.scomplex_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.int64_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.bool_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.dcomplex_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.resource_handle_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.variant_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.uint32_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.uint64_val_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::TensorProto, _impl_.float8_val_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::VariantTensorDataProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::VariantTensorDataProto, _impl_.type_name_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::VariantTensorDataProto, _impl_.metadata_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::VariantTensorDataProto, _impl_.tensors_),
};
static const ::_pbi::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, -1, sizeof(::tensorflow::TensorProto)},
  { 24, -1, -1, sizeof(::tensorflow::VariantTensorDataProto)},
};

static const ::_pb::Message* const file_default_instances[] = {
  &::tensorflow::_TensorProto_default_instance_._instance,
  &::tensorflow::_VariantTensorDataProto_default_instance_._instance,
};

const char descriptor_table_protodef_tensorflow_2fcore_2fframework_2ftensor_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n&tensorflow/core/framework/tensor.proto"
  "\022\ntensorflow\032/tensorflow/core/framework/"
  "resource_handle.proto\032,tensorflow/core/f"
  "ramework/tensor_shape.proto\032%tensorflow/"
  "core/framework/types.proto\"\240\004\n\013TensorPro"
  "to\022#\n\005dtype\030\001 \001(\0162\024.tensorflow.DataType\022"
  "2\n\014tensor_shape\030\002 \001(\0132\034.tensorflow.Tenso"
  "rShapeProto\022\026\n\016version_number\030\003 \001(\005\022\026\n\016t"
  "ensor_content\030\004 \001(\014\022\024\n\010half_val\030\r \003(\005B\002\020"
  "\001\022\025\n\tfloat_val\030\005 \003(\002B\002\020\001\022\026\n\ndouble_val\030\006"
  " \003(\001B\002\020\001\022\023\n\007int_val\030\007 \003(\005B\002\020\001\022\022\n\nstring_"
  "val\030\010 \003(\014\022\030\n\014scomplex_val\030\t \003(\002B\002\020\001\022\025\n\ti"
  "nt64_val\030\n \003(\003B\002\020\001\022\024\n\010bool_val\030\013 \003(\010B\002\020\001"
  "\022\030\n\014dcomplex_val\030\014 \003(\001B\002\020\001\022<\n\023resource_h"
  "andle_val\030\016 \003(\0132\037.tensorflow.ResourceHan"
  "dleProto\0227\n\013variant_val\030\017 \003(\0132\".tensorfl"
  "ow.VariantTensorDataProto\022\026\n\nuint32_val\030"
  "\020 \003(\rB\002\020\001\022\026\n\nuint64_val\030\021 \003(\004B\002\020\001\022\022\n\nflo"
  "at8_val\030\022 \001(\014\"g\n\026VariantTensorDataProto\022"
  "\021\n\ttype_name\030\001 \001(\t\022\020\n\010metadata\030\002 \001(\014\022(\n\007"
  "tensors\030\003 \003(\0132\027.tensorflow.TensorProtoB|"
  "\n\030org.tensorflow.frameworkB\014TensorProtos"
  "P\001ZMgithub.com/tensorflow/tensorflow/ten"
  "sorflow/go/core/framework/tensor_go_prot"
  "o\370\001\001b\006proto3"
  ;
static const ::_pbi::DescriptorTable* const descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto_deps[3] = {
  &::descriptor_table_tensorflow_2fcore_2fframework_2fresource_5fhandle_2eproto,
  &::descriptor_table_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto,
  &::descriptor_table_tensorflow_2fcore_2fframework_2ftypes_2eproto,
};
static ::_pbi::once_flag descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto_once;
const ::_pbi::DescriptorTable descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto = {
    false, false, 972, descriptor_table_protodef_tensorflow_2fcore_2fframework_2ftensor_2eproto,
    "tensorflow/core/framework/tensor.proto",
    &descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto_once, descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto_deps, 3, 2,
    schemas, file_default_instances, TableStruct_tensorflow_2fcore_2fframework_2ftensor_2eproto::offsets,
    file_level_metadata_tensorflow_2fcore_2fframework_2ftensor_2eproto, file_level_enum_descriptors_tensorflow_2fcore_2fframework_2ftensor_2eproto,
    file_level_service_descriptors_tensorflow_2fcore_2fframework_2ftensor_2eproto,
};
PROTOBUF_ATTRIBUTE_WEAK const ::_pbi::DescriptorTable* descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto_getter() {
  return &descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto;
}

// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::_pbi::AddDescriptorsRunner dynamic_init_dummy_tensorflow_2fcore_2fframework_2ftensor_2eproto(&descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto);
namespace tensorflow {

// ===================================================================

class TensorProto::_Internal {
 public:
  static const ::tensorflow::TensorShapeProto& tensor_shape(const TensorProto* msg);
};

const ::tensorflow::TensorShapeProto&
TensorProto::_Internal::tensor_shape(const TensorProto* msg) {
  return *msg->_impl_.tensor_shape_;
}
void TensorProto::clear_tensor_shape() {
  if (GetArenaForAllocation() == nullptr && _impl_.tensor_shape_ != nullptr) {
    delete _impl_.tensor_shape_;
  }
  _impl_.tensor_shape_ = nullptr;
}
void TensorProto::clear_resource_handle_val() {
  _impl_.resource_handle_val_.Clear();
}
TensorProto::TensorProto(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.TensorProto)
}
TensorProto::TensorProto(const TensorProto& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  TensorProto* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.float_val_){from._impl_.float_val_}
    , decltype(_impl_.double_val_){from._impl_.double_val_}
    , decltype(_impl_.int_val_){from._impl_.int_val_}
    , /*decltype(_impl_._int_val_cached_byte_size_)*/{0}
    , decltype(_impl_.string_val_){from._impl_.string_val_}
    , decltype(_impl_.scomplex_val_){from._impl_.scomplex_val_}
    , decltype(_impl_.int64_val_){from._impl_.int64_val_}
    , /*decltype(_impl_._int64_val_cached_byte_size_)*/{0}
    , decltype(_impl_.bool_val_){from._impl_.bool_val_}
    , decltype(_impl_.dcomplex_val_){from._impl_.dcomplex_val_}
    , decltype(_impl_.half_val_){from._impl_.half_val_}
    , /*decltype(_impl_._half_val_cached_byte_size_)*/{0}
    , decltype(_impl_.resource_handle_val_){from._impl_.resource_handle_val_}
    , decltype(_impl_.variant_val_){from._impl_.variant_val_}
    , decltype(_impl_.uint32_val_){from._impl_.uint32_val_}
    , /*decltype(_impl_._uint32_val_cached_byte_size_)*/{0}
    , decltype(_impl_.uint64_val_){from._impl_.uint64_val_}
    , /*decltype(_impl_._uint64_val_cached_byte_size_)*/{0}
    , decltype(_impl_.tensor_content_){}
    , decltype(_impl_.float8_val_){}
    , decltype(_impl_.tensor_shape_){nullptr}
    , decltype(_impl_.dtype_){}
    , decltype(_impl_.version_number_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _impl_.tensor_content_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.tensor_content_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_tensor_content().empty()) {
    _this->_impl_.tensor_content_.Set(from._internal_tensor_content(), 
      _this->GetArenaForAllocation());
  }
  _impl_.float8_val_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.float8_val_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_float8_val().empty()) {
    _this->_impl_.float8_val_.Set(from._internal_float8_val(), 
      _this->GetArenaForAllocation());
  }
  if (from._internal_has_tensor_shape()) {
    _this->_impl_.tensor_shape_ = new ::tensorflow::TensorShapeProto(*from._impl_.tensor_shape_);
  }
  ::memcpy(&_impl_.dtype_, &from._impl_.dtype_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.version_number_) -
    reinterpret_cast<char*>(&_impl_.dtype_)) + sizeof(_impl_.version_number_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.TensorProto)
}

inline void TensorProto::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.float_val_){arena}
    , decltype(_impl_.double_val_){arena}
    , decltype(_impl_.int_val_){arena}
    , /*decltype(_impl_._int_val_cached_byte_size_)*/{0}
    , decltype(_impl_.string_val_){arena}
    , decltype(_impl_.scomplex_val_){arena}
    , decltype(_impl_.int64_val_){arena}
    , /*decltype(_impl_._int64_val_cached_byte_size_)*/{0}
    , decltype(_impl_.bool_val_){arena}
    , decltype(_impl_.dcomplex_val_){arena}
    , decltype(_impl_.half_val_){arena}
    , /*decltype(_impl_._half_val_cached_byte_size_)*/{0}
    , decltype(_impl_.resource_handle_val_){arena}
    , decltype(_impl_.variant_val_){arena}
    , decltype(_impl_.uint32_val_){arena}
    , /*decltype(_impl_._uint32_val_cached_byte_size_)*/{0}
    , decltype(_impl_.uint64_val_){arena}
    , /*decltype(_impl_._uint64_val_cached_byte_size_)*/{0}
    , decltype(_impl_.tensor_content_){}
    , decltype(_impl_.float8_val_){}
    , decltype(_impl_.tensor_shape_){nullptr}
    , decltype(_impl_.dtype_){0}
    , decltype(_impl_.version_number_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
  _impl_.tensor_content_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.tensor_content_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  _impl_.float8_val_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.float8_val_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

TensorProto::~TensorProto() {
  // @@protoc_insertion_point(destructor:tensorflow.TensorProto)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void TensorProto::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.float_val_.~RepeatedField();
  _impl_.double_val_.~RepeatedField();
  _impl_.int_val_.~RepeatedField();
  _impl_.string_val_.~RepeatedPtrField();
  _impl_.scomplex_val_.~RepeatedField();
  _impl_.int64_val_.~RepeatedField();
  _impl_.bool_val_.~RepeatedField();
  _impl_.dcomplex_val_.~RepeatedField();
  _impl_.half_val_.~RepeatedField();
  _impl_.resource_handle_val_.~RepeatedPtrField();
  _impl_.variant_val_.~RepeatedPtrField();
  _impl_.uint32_val_.~RepeatedField();
  _impl_.uint64_val_.~RepeatedField();
  _impl_.tensor_content_.Destroy();
  _impl_.float8_val_.Destroy();
  if (this != internal_default_instance()) delete _impl_.tensor_shape_;
}

void TensorProto::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void TensorProto::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.TensorProto)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.float_val_.Clear();
  _impl_.double_val_.Clear();
  _impl_.int_val_.Clear();
  _impl_.string_val_.Clear();
  _impl_.scomplex_val_.Clear();
  _impl_.int64_val_.Clear();
  _impl_.bool_val_.Clear();
  _impl_.dcomplex_val_.Clear();
  _impl_.half_val_.Clear();
  _impl_.resource_handle_val_.Clear();
  _impl_.variant_val_.Clear();
  _impl_.uint32_val_.Clear();
  _impl_.uint64_val_.Clear();
  _impl_.tensor_content_.ClearToEmpty();
  _impl_.float8_val_.ClearToEmpty();
  if (GetArenaForAllocation() == nullptr && _impl_.tensor_shape_ != nullptr) {
    delete _impl_.tensor_shape_;
  }
  _impl_.tensor_shape_ = nullptr;
  ::memset(&_impl_.dtype_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.version_number_) -
      reinterpret_cast<char*>(&_impl_.dtype_)) + sizeof(_impl_.version_number_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* TensorProto::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .tensorflow.DataType dtype = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_dtype(static_cast<::tensorflow::DataType>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.TensorShapeProto tensor_shape = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_tensor_shape(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 version_number = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _impl_.version_number_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // bytes tensor_content = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
          auto str = _internal_mutable_tensor_content();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated float float_val = 5 [packed = true];
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 42)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedFloatParser(_internal_mutable_float_val(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 45) {
          _internal_add_float_val(::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr));
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // repeated double double_val = 6 [packed = true];
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 50)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedDoubleParser(_internal_mutable_double_val(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 49) {
          _internal_add_double_val(::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<double>(ptr));
          ptr += sizeof(double);
        } else
          goto handle_unusual;
        continue;
      // repeated int32 int_val = 7 [packed = true];
      case 7:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 58)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt32Parser(_internal_mutable_int_val(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 56) {
          _internal_add_int_val(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated bytes string_val = 8;
      case 8:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 66)) {
          ptr -= 1;
          do {
            ptr += 1;
            auto str = _internal_add_string_val();
            ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<66>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated float scomplex_val = 9 [packed = true];
      case 9:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 74)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedFloatParser(_internal_mutable_scomplex_val(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 77) {
          _internal_add_scomplex_val(::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr));
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // repeated int64 int64_val = 10 [packed = true];
      case 10:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 82)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt64Parser(_internal_mutable_int64_val(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 80) {
          _internal_add_int64_val(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated bool bool_val = 11 [packed = true];
      case 11:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 90)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedBoolParser(_internal_mutable_bool_val(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 88) {
          _internal_add_bool_val(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated double dcomplex_val = 12 [packed = true];
      case 12:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 98)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedDoubleParser(_internal_mutable_dcomplex_val(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 97) {
          _internal_add_dcomplex_val(::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<double>(ptr));
          ptr += sizeof(double);
        } else
          goto handle_unusual;
        continue;
      // repeated int32 half_val = 13 [packed = true];
      case 13:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 106)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt32Parser(_internal_mutable_half_val(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 104) {
          _internal_add_half_val(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated .tensorflow.ResourceHandleProto resource_handle_val = 14;
      case 14:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 114)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_resource_handle_val(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<114>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .tensorflow.VariantTensorDataProto variant_val = 15;
      case 15:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 122)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_variant_val(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<122>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated uint32 uint32_val = 16 [packed = true];
      case 16:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 130)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedUInt32Parser(_internal_mutable_uint32_val(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 128) {
          _internal_add_uint32_val(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated uint64 uint64_val = 17 [packed = true];
      case 17:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 138)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedUInt64Parser(_internal_mutable_uint64_val(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 136) {
          _internal_add_uint64_val(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // bytes float8_val = 18;
      case 18:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 146)) {
          auto str = _internal_mutable_float8_val();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* TensorProto::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.TensorProto)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.DataType dtype = 1;
  if (this->_internal_dtype() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      1, this->_internal_dtype(), target);
  }

  // .tensorflow.TensorShapeProto tensor_shape = 2;
  if (this->_internal_has_tensor_shape()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::tensor_shape(this),
        _Internal::tensor_shape(this).GetCachedSize(), target, stream);
  }

  // int32 version_number = 3;
  if (this->_internal_version_number() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(3, this->_internal_version_number(), target);
  }

  // bytes tensor_content = 4;
  if (!this->_internal_tensor_content().empty()) {
    target = stream->WriteBytesMaybeAliased(
        4, this->_internal_tensor_content(), target);
  }

  // repeated float float_val = 5 [packed = true];
  if (this->_internal_float_val_size() > 0) {
    target = stream->WriteFixedPacked(5, _internal_float_val(), target);
  }

  // repeated double double_val = 6 [packed = true];
  if (this->_internal_double_val_size() > 0) {
    target = stream->WriteFixedPacked(6, _internal_double_val(), target);
  }

  // repeated int32 int_val = 7 [packed = true];
  {
    int byte_size = _impl_._int_val_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteInt32Packed(
          7, _internal_int_val(), byte_size, target);
    }
  }

  // repeated bytes string_val = 8;
  for (int i = 0, n = this->_internal_string_val_size(); i < n; i++) {
    const auto& s = this->_internal_string_val(i);
    target = stream->WriteBytes(8, s, target);
  }

  // repeated float scomplex_val = 9 [packed = true];
  if (this->_internal_scomplex_val_size() > 0) {
    target = stream->WriteFixedPacked(9, _internal_scomplex_val(), target);
  }

  // repeated int64 int64_val = 10 [packed = true];
  {
    int byte_size = _impl_._int64_val_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteInt64Packed(
          10, _internal_int64_val(), byte_size, target);
    }
  }

  // repeated bool bool_val = 11 [packed = true];
  if (this->_internal_bool_val_size() > 0) {
    target = stream->WriteFixedPacked(11, _internal_bool_val(), target);
  }

  // repeated double dcomplex_val = 12 [packed = true];
  if (this->_internal_dcomplex_val_size() > 0) {
    target = stream->WriteFixedPacked(12, _internal_dcomplex_val(), target);
  }

  // repeated int32 half_val = 13 [packed = true];
  {
    int byte_size = _impl_._half_val_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteInt32Packed(
          13, _internal_half_val(), byte_size, target);
    }
  }

  // repeated .tensorflow.ResourceHandleProto resource_handle_val = 14;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_resource_handle_val_size()); i < n; i++) {
    const auto& repfield = this->_internal_resource_handle_val(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(14, repfield, repfield.GetCachedSize(), target, stream);
  }

  // repeated .tensorflow.VariantTensorDataProto variant_val = 15;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_variant_val_size()); i < n; i++) {
    const auto& repfield = this->_internal_variant_val(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(15, repfield, repfield.GetCachedSize(), target, stream);
  }

  // repeated uint32 uint32_val = 16 [packed = true];
  {
    int byte_size = _impl_._uint32_val_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteUInt32Packed(
          16, _internal_uint32_val(), byte_size, target);
    }
  }

  // repeated uint64 uint64_val = 17 [packed = true];
  {
    int byte_size = _impl_._uint64_val_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteUInt64Packed(
          17, _internal_uint64_val(), byte_size, target);
    }
  }

  // bytes float8_val = 18;
  if (!this->_internal_float8_val().empty()) {
    target = stream->WriteBytesMaybeAliased(
        18, this->_internal_float8_val(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.TensorProto)
  return target;
}

size_t TensorProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.TensorProto)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated float float_val = 5 [packed = true];
  {
    unsigned int count = static_cast<unsigned int>(this->_internal_float_val_size());
    size_t data_size = 4UL * count;
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    total_size += data_size;
  }

  // repeated double double_val = 6 [packed = true];
  {
    unsigned int count = static_cast<unsigned int>(this->_internal_double_val_size());
    size_t data_size = 8UL * count;
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    total_size += data_size;
  }

  // repeated int32 int_val = 7 [packed = true];
  {
    size_t data_size = ::_pbi::WireFormatLite::
      Int32Size(this->_impl_.int_val_);
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    int cached_size = ::_pbi::ToCachedSize(data_size);
    _impl_._int_val_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  // repeated bytes string_val = 8;
  total_size += 1 *
      ::PROTOBUF_NAMESPACE_ID::internal::FromIntSize(_impl_.string_val_.size());
  for (int i = 0, n = _impl_.string_val_.size(); i < n; i++) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::BytesSize(
      _impl_.string_val_.Get(i));
  }

  // repeated float scomplex_val = 9 [packed = true];
  {
    unsigned int count = static_cast<unsigned int>(this->_internal_scomplex_val_size());
    size_t data_size = 4UL * count;
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    total_size += data_size;
  }

  // repeated int64 int64_val = 10 [packed = true];
  {
    size_t data_size = ::_pbi::WireFormatLite::
      Int64Size(this->_impl_.int64_val_);
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    int cached_size = ::_pbi::ToCachedSize(data_size);
    _impl_._int64_val_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  // repeated bool bool_val = 11 [packed = true];
  {
    unsigned int count = static_cast<unsigned int>(this->_internal_bool_val_size());
    size_t data_size = 1UL * count;
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    total_size += data_size;
  }

  // repeated double dcomplex_val = 12 [packed = true];
  {
    unsigned int count = static_cast<unsigned int>(this->_internal_dcomplex_val_size());
    size_t data_size = 8UL * count;
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    total_size += data_size;
  }

  // repeated int32 half_val = 13 [packed = true];
  {
    size_t data_size = ::_pbi::WireFormatLite::
      Int32Size(this->_impl_.half_val_);
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    int cached_size = ::_pbi::ToCachedSize(data_size);
    _impl_._half_val_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  // repeated .tensorflow.ResourceHandleProto resource_handle_val = 14;
  total_size += 1UL * this->_internal_resource_handle_val_size();
  for (const auto& msg : this->_impl_.resource_handle_val_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .tensorflow.VariantTensorDataProto variant_val = 15;
  total_size += 1UL * this->_internal_variant_val_size();
  for (const auto& msg : this->_impl_.variant_val_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated uint32 uint32_val = 16 [packed = true];
  {
    size_t data_size = ::_pbi::WireFormatLite::
      UInt32Size(this->_impl_.uint32_val_);
    if (data_size > 0) {
      total_size += 2 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    int cached_size = ::_pbi::ToCachedSize(data_size);
    _impl_._uint32_val_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  // repeated uint64 uint64_val = 17 [packed = true];
  {
    size_t data_size = ::_pbi::WireFormatLite::
      UInt64Size(this->_impl_.uint64_val_);
    if (data_size > 0) {
      total_size += 2 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    int cached_size = ::_pbi::ToCachedSize(data_size);
    _impl_._uint64_val_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  // bytes tensor_content = 4;
  if (!this->_internal_tensor_content().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::BytesSize(
        this->_internal_tensor_content());
  }

  // bytes float8_val = 18;
  if (!this->_internal_float8_val().empty()) {
    total_size += 2 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::BytesSize(
        this->_internal_float8_val());
  }

  // .tensorflow.TensorShapeProto tensor_shape = 2;
  if (this->_internal_has_tensor_shape()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.tensor_shape_);
  }

  // .tensorflow.DataType dtype = 1;
  if (this->_internal_dtype() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_dtype());
  }

  // int32 version_number = 3;
  if (this->_internal_version_number() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_version_number());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData TensorProto::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    TensorProto::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*TensorProto::GetClassData() const { return &_class_data_; }


void TensorProto::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<TensorProto*>(&to_msg);
  auto& from = static_cast<const TensorProto&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.TensorProto)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.float_val_.MergeFrom(from._impl_.float_val_);
  _this->_impl_.double_val_.MergeFrom(from._impl_.double_val_);
  _this->_impl_.int_val_.MergeFrom(from._impl_.int_val_);
  _this->_impl_.string_val_.MergeFrom(from._impl_.string_val_);
  _this->_impl_.scomplex_val_.MergeFrom(from._impl_.scomplex_val_);
  _this->_impl_.int64_val_.MergeFrom(from._impl_.int64_val_);
  _this->_impl_.bool_val_.MergeFrom(from._impl_.bool_val_);
  _this->_impl_.dcomplex_val_.MergeFrom(from._impl_.dcomplex_val_);
  _this->_impl_.half_val_.MergeFrom(from._impl_.half_val_);
  _this->_impl_.resource_handle_val_.MergeFrom(from._impl_.resource_handle_val_);
  _this->_impl_.variant_val_.MergeFrom(from._impl_.variant_val_);
  _this->_impl_.uint32_val_.MergeFrom(from._impl_.uint32_val_);
  _this->_impl_.uint64_val_.MergeFrom(from._impl_.uint64_val_);
  if (!from._internal_tensor_content().empty()) {
    _this->_internal_set_tensor_content(from._internal_tensor_content());
  }
  if (!from._internal_float8_val().empty()) {
    _this->_internal_set_float8_val(from._internal_float8_val());
  }
  if (from._internal_has_tensor_shape()) {
    _this->_internal_mutable_tensor_shape()->::tensorflow::TensorShapeProto::MergeFrom(
        from._internal_tensor_shape());
  }
  if (from._internal_dtype() != 0) {
    _this->_internal_set_dtype(from._internal_dtype());
  }
  if (from._internal_version_number() != 0) {
    _this->_internal_set_version_number(from._internal_version_number());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void TensorProto::CopyFrom(const TensorProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.TensorProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool TensorProto::IsInitialized() const {
  return true;
}

void TensorProto::InternalSwap(TensorProto* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.float_val_.InternalSwap(&other->_impl_.float_val_);
  _impl_.double_val_.InternalSwap(&other->_impl_.double_val_);
  _impl_.int_val_.InternalSwap(&other->_impl_.int_val_);
  _impl_.string_val_.InternalSwap(&other->_impl_.string_val_);
  _impl_.scomplex_val_.InternalSwap(&other->_impl_.scomplex_val_);
  _impl_.int64_val_.InternalSwap(&other->_impl_.int64_val_);
  _impl_.bool_val_.InternalSwap(&other->_impl_.bool_val_);
  _impl_.dcomplex_val_.InternalSwap(&other->_impl_.dcomplex_val_);
  _impl_.half_val_.InternalSwap(&other->_impl_.half_val_);
  _impl_.resource_handle_val_.InternalSwap(&other->_impl_.resource_handle_val_);
  _impl_.variant_val_.InternalSwap(&other->_impl_.variant_val_);
  _impl_.uint32_val_.InternalSwap(&other->_impl_.uint32_val_);
  _impl_.uint64_val_.InternalSwap(&other->_impl_.uint64_val_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.tensor_content_, lhs_arena,
      &other->_impl_.tensor_content_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.float8_val_, lhs_arena,
      &other->_impl_.float8_val_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(TensorProto, _impl_.version_number_)
      + sizeof(TensorProto::_impl_.version_number_)
      - PROTOBUF_FIELD_OFFSET(TensorProto, _impl_.tensor_shape_)>(
          reinterpret_cast<char*>(&_impl_.tensor_shape_),
          reinterpret_cast<char*>(&other->_impl_.tensor_shape_));
}

::PROTOBUF_NAMESPACE_ID::Metadata TensorProto::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fframework_2ftensor_2eproto[0]);
}

// ===================================================================

class VariantTensorDataProto::_Internal {
 public:
};

VariantTensorDataProto::VariantTensorDataProto(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.VariantTensorDataProto)
}
VariantTensorDataProto::VariantTensorDataProto(const VariantTensorDataProto& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  VariantTensorDataProto* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.tensors_){from._impl_.tensors_}
    , decltype(_impl_.type_name_){}
    , decltype(_impl_.metadata_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _impl_.type_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.type_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_type_name().empty()) {
    _this->_impl_.type_name_.Set(from._internal_type_name(), 
      _this->GetArenaForAllocation());
  }
  _impl_.metadata_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.metadata_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_metadata().empty()) {
    _this->_impl_.metadata_.Set(from._internal_metadata(), 
      _this->GetArenaForAllocation());
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.VariantTensorDataProto)
}

inline void VariantTensorDataProto::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.tensors_){arena}
    , decltype(_impl_.type_name_){}
    , decltype(_impl_.metadata_){}
    , /*decltype(_impl_._cached_size_)*/{}
  };
  _impl_.type_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.type_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  _impl_.metadata_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.metadata_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

VariantTensorDataProto::~VariantTensorDataProto() {
  // @@protoc_insertion_point(destructor:tensorflow.VariantTensorDataProto)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void VariantTensorDataProto::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.tensors_.~RepeatedPtrField();
  _impl_.type_name_.Destroy();
  _impl_.metadata_.Destroy();
}

void VariantTensorDataProto::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void VariantTensorDataProto::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.VariantTensorDataProto)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.tensors_.Clear();
  _impl_.type_name_.ClearToEmpty();
  _impl_.metadata_.ClearToEmpty();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* VariantTensorDataProto::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // string type_name = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_type_name();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "tensorflow.VariantTensorDataProto.type_name"));
        } else
          goto handle_unusual;
        continue;
      // bytes metadata = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          auto str = _internal_mutable_metadata();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated .tensorflow.TensorProto tensors = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_tensors(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<26>(ptr));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* VariantTensorDataProto::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.VariantTensorDataProto)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // string type_name = 1;
  if (!this->_internal_type_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_type_name().data(), static_cast<int>(this->_internal_type_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.VariantTensorDataProto.type_name");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_type_name(), target);
  }

  // bytes metadata = 2;
  if (!this->_internal_metadata().empty()) {
    target = stream->WriteBytesMaybeAliased(
        2, this->_internal_metadata(), target);
  }

  // repeated .tensorflow.TensorProto tensors = 3;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_tensors_size()); i < n; i++) {
    const auto& repfield = this->_internal_tensors(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(3, repfield, repfield.GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.VariantTensorDataProto)
  return target;
}

size_t VariantTensorDataProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.VariantTensorDataProto)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .tensorflow.TensorProto tensors = 3;
  total_size += 1UL * this->_internal_tensors_size();
  for (const auto& msg : this->_impl_.tensors_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // string type_name = 1;
  if (!this->_internal_type_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_type_name());
  }

  // bytes metadata = 2;
  if (!this->_internal_metadata().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::BytesSize(
        this->_internal_metadata());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData VariantTensorDataProto::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    VariantTensorDataProto::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*VariantTensorDataProto::GetClassData() const { return &_class_data_; }


void VariantTensorDataProto::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<VariantTensorDataProto*>(&to_msg);
  auto& from = static_cast<const VariantTensorDataProto&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.VariantTensorDataProto)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.tensors_.MergeFrom(from._impl_.tensors_);
  if (!from._internal_type_name().empty()) {
    _this->_internal_set_type_name(from._internal_type_name());
  }
  if (!from._internal_metadata().empty()) {
    _this->_internal_set_metadata(from._internal_metadata());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void VariantTensorDataProto::CopyFrom(const VariantTensorDataProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.VariantTensorDataProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool VariantTensorDataProto::IsInitialized() const {
  return true;
}

void VariantTensorDataProto::InternalSwap(VariantTensorDataProto* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.tensors_.InternalSwap(&other->_impl_.tensors_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.type_name_, lhs_arena,
      &other->_impl_.type_name_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.metadata_, lhs_arena,
      &other->_impl_.metadata_, rhs_arena
  );
}

::PROTOBUF_NAMESPACE_ID::Metadata VariantTensorDataProto::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fframework_2ftensor_2eproto[1]);
}

// @@protoc_insertion_point(namespace_scope)
}  // namespace tensorflow
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::tensorflow::TensorProto*
Arena::CreateMaybeMessage< ::tensorflow::TensorProto >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::TensorProto >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::VariantTensorDataProto*
Arena::CreateMaybeMessage< ::tensorflow::VariantTensorDataProto >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::VariantTensorDataProto >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
