// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/tpu/optimization_parameters.proto

#include "tensorflow/core/protobuf/tpu/optimization_parameters.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG

namespace _pb = ::PROTOBUF_NAMESPACE_ID;
namespace _pbi = _pb::internal;

namespace tensorflow {
namespace tpu {
PROTOBUF_CONSTEXPR ClippingLimits::ClippingLimits(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.lower_)*/nullptr
  , /*decltype(_impl_.upper_)*/nullptr
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct ClippingLimitsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR ClippingLimitsDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~ClippingLimitsDefaultTypeInternal() {}
  union {
    ClippingLimits _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 ClippingLimitsDefaultTypeInternal _ClippingLimits_default_instance_;
PROTOBUF_CONSTEXPR SimulatedQuantization::SimulatedQuantization(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.clipping_limits_)*/nullptr
  , /*decltype(_impl_.enabled_)*/false
  , /*decltype(_impl_.num_buckets_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct SimulatedQuantizationDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SimulatedQuantizationDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~SimulatedQuantizationDefaultTypeInternal() {}
  union {
    SimulatedQuantization _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SimulatedQuantizationDefaultTypeInternal _SimulatedQuantization_default_instance_;
PROTOBUF_CONSTEXPR DynamicLearningRate::DynamicLearningRate(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.tag_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct DynamicLearningRateDefaultTypeInternal {
  PROTOBUF_CONSTEXPR DynamicLearningRateDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~DynamicLearningRateDefaultTypeInternal() {}
  union {
    DynamicLearningRate _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 DynamicLearningRateDefaultTypeInternal _DynamicLearningRate_default_instance_;
PROTOBUF_CONSTEXPR LearningRate::LearningRate(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.learning_rate_)*/{}
  , /*decltype(_impl_._cached_size_)*/{}
  , /*decltype(_impl_._oneof_case_)*/{}} {}
struct LearningRateDefaultTypeInternal {
  PROTOBUF_CONSTEXPR LearningRateDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~LearningRateDefaultTypeInternal() {}
  union {
    LearningRate _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 LearningRateDefaultTypeInternal _LearningRate_default_instance_;
PROTOBUF_CONSTEXPR AdagradParameters::AdagradParameters(
    ::_pbi::ConstantInitialized) {}
struct AdagradParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR AdagradParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~AdagradParametersDefaultTypeInternal() {}
  union {
    AdagradParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 AdagradParametersDefaultTypeInternal _AdagradParameters_default_instance_;
PROTOBUF_CONSTEXPR AdagradMomentumParameters::AdagradMomentumParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.momentum_)*/0
  , /*decltype(_impl_.use_nesterov_)*/false
  , /*decltype(_impl_.exponent_)*/0
  , /*decltype(_impl_.beta2_)*/0
  , /*decltype(_impl_.epsilon_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct AdagradMomentumParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR AdagradMomentumParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~AdagradMomentumParametersDefaultTypeInternal() {}
  union {
    AdagradMomentumParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 AdagradMomentumParametersDefaultTypeInternal _AdagradMomentumParameters_default_instance_;
PROTOBUF_CONSTEXPR BoundedAdagradParameters::BoundedAdagradParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.update_accumulator_first_)*/false
  , /*decltype(_impl_.max_var_update_)*/0
  , /*decltype(_impl_.max_accumulator_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct BoundedAdagradParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR BoundedAdagradParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~BoundedAdagradParametersDefaultTypeInternal() {}
  union {
    BoundedAdagradParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 BoundedAdagradParametersDefaultTypeInternal _BoundedAdagradParameters_default_instance_;
PROTOBUF_CONSTEXPR StochasticGradientDescentParameters::StochasticGradientDescentParameters(
    ::_pbi::ConstantInitialized) {}
struct StochasticGradientDescentParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StochasticGradientDescentParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~StochasticGradientDescentParametersDefaultTypeInternal() {}
  union {
    StochasticGradientDescentParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StochasticGradientDescentParametersDefaultTypeInternal _StochasticGradientDescentParameters_default_instance_;
PROTOBUF_CONSTEXPR FtrlParameters::FtrlParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.l1_)*/0
  , /*decltype(_impl_.l2_)*/0
  , /*decltype(_impl_.lr_power_)*/0
  , /*decltype(_impl_.beta_)*/0
  , /*decltype(_impl_.multiply_linear_by_lr_)*/false
  , /*decltype(_impl_.allow_zero_accumulator_)*/false
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct FtrlParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR FtrlParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~FtrlParametersDefaultTypeInternal() {}
  union {
    FtrlParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 FtrlParametersDefaultTypeInternal _FtrlParameters_default_instance_;
PROTOBUF_CONSTEXPR AdamParameters::AdamParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.beta1_)*/0
  , /*decltype(_impl_.beta2_)*/0
  , /*decltype(_impl_.epsilon_)*/0
  , /*decltype(_impl_.use_non_lazy_adam_)*/false
  , /*decltype(_impl_.use_sum_inside_sqrt_)*/false
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct AdamParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR AdamParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~AdamParametersDefaultTypeInternal() {}
  union {
    AdamParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 AdamParametersDefaultTypeInternal _AdamParameters_default_instance_;
PROTOBUF_CONSTEXPR MomentumParameters::MomentumParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.momentum_)*/0
  , /*decltype(_impl_.use_nesterov_)*/false
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct MomentumParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR MomentumParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~MomentumParametersDefaultTypeInternal() {}
  union {
    MomentumParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 MomentumParametersDefaultTypeInternal _MomentumParameters_default_instance_;
PROTOBUF_CONSTEXPR LionParameters::LionParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.beta1_)*/0
  , /*decltype(_impl_.beta2_)*/0
  , /*decltype(_impl_.use_non_lazy_lion_)*/false
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct LionParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR LionParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~LionParametersDefaultTypeInternal() {}
  union {
    LionParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 LionParametersDefaultTypeInternal _LionParameters_default_instance_;
PROTOBUF_CONSTEXPR RmsPropParameters::RmsPropParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.rho_)*/0
  , /*decltype(_impl_.momentum_)*/0
  , /*decltype(_impl_.epsilon_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct RmsPropParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RmsPropParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~RmsPropParametersDefaultTypeInternal() {}
  union {
    RmsPropParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RmsPropParametersDefaultTypeInternal _RmsPropParameters_default_instance_;
PROTOBUF_CONSTEXPR CenteredRmsPropParameters::CenteredRmsPropParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.rho_)*/0
  , /*decltype(_impl_.momentum_)*/0
  , /*decltype(_impl_.epsilon_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct CenteredRmsPropParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR CenteredRmsPropParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~CenteredRmsPropParametersDefaultTypeInternal() {}
  union {
    CenteredRmsPropParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 CenteredRmsPropParametersDefaultTypeInternal _CenteredRmsPropParameters_default_instance_;
PROTOBUF_CONSTEXPR MdlAdagradLightParameters::MdlAdagradLightParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.l2_)*/0
  , /*decltype(_impl_.lr_power_)*/0
  , /*decltype(_impl_.min_servable_mdl_benefit_)*/0
  , /*decltype(_impl_.mdl_mix_in_margin_)*/0
  , /*decltype(_impl_.mdl_benefit_rampup_coeff_)*/0
  , /*decltype(_impl_.mdl_min_weight_)*/0
  , /*decltype(_impl_.benefit_revisit_scale_)*/0
  , /*decltype(_impl_.max_event_benefit_)*/0
  , /*decltype(_impl_.max_total_benefit_)*/0
  , /*decltype(_impl_.mdl_hard_limit_)*/0
  , /*decltype(_impl_.hard_limit_min_benefit_)*/false
  , /*decltype(_impl_.mdl_regularize_)*/false
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct MdlAdagradLightParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR MdlAdagradLightParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~MdlAdagradLightParametersDefaultTypeInternal() {}
  union {
    MdlAdagradLightParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 MdlAdagradLightParametersDefaultTypeInternal _MdlAdagradLightParameters_default_instance_;
PROTOBUF_CONSTEXPR AdadeltaParameters::AdadeltaParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.rho_)*/0
  , /*decltype(_impl_.epsilon_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct AdadeltaParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR AdadeltaParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~AdadeltaParametersDefaultTypeInternal() {}
  union {
    AdadeltaParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 AdadeltaParametersDefaultTypeInternal _AdadeltaParameters_default_instance_;
PROTOBUF_CONSTEXPR ProximalAdagradParameters::ProximalAdagradParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.l1_)*/0
  , /*decltype(_impl_.l2_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct ProximalAdagradParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR ProximalAdagradParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~ProximalAdagradParametersDefaultTypeInternal() {}
  union {
    ProximalAdagradParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 ProximalAdagradParametersDefaultTypeInternal _ProximalAdagradParameters_default_instance_;
PROTOBUF_CONSTEXPR OnlineYogiParameters::OnlineYogiParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.l1_)*/0
  , /*decltype(_impl_.l2_)*/0
  , /*decltype(_impl_.beta2_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct OnlineYogiParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR OnlineYogiParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~OnlineYogiParametersDefaultTypeInternal() {}
  union {
    OnlineYogiParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 OnlineYogiParametersDefaultTypeInternal _OnlineYogiParameters_default_instance_;
PROTOBUF_CONSTEXPR ProximalYogiParameters::ProximalYogiParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.l1_)*/0
  , /*decltype(_impl_.l2_)*/0
  , /*decltype(_impl_.beta1_)*/0
  , /*decltype(_impl_.beta2_)*/0
  , /*decltype(_impl_.epsilon_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct ProximalYogiParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR ProximalYogiParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~ProximalYogiParametersDefaultTypeInternal() {}
  union {
    ProximalYogiParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 ProximalYogiParametersDefaultTypeInternal _ProximalYogiParameters_default_instance_;
PROTOBUF_CONSTEXPR FrequencyEstimatorParameters::FrequencyEstimatorParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.tau_)*/0
  , /*decltype(_impl_.max_delta_)*/0
  , /*decltype(_impl_.outlier_threshold_)*/0
  , /*decltype(_impl_.weight_exponent_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct FrequencyEstimatorParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR FrequencyEstimatorParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~FrequencyEstimatorParametersDefaultTypeInternal() {}
  union {
    FrequencyEstimatorParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 FrequencyEstimatorParametersDefaultTypeInternal _FrequencyEstimatorParameters_default_instance_;
PROTOBUF_CONSTEXPR UserDefinedProgramParameters::UserDefinedProgramParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.program_)*/nullptr
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct UserDefinedProgramParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR UserDefinedProgramParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~UserDefinedProgramParametersDefaultTypeInternal() {}
  union {
    UserDefinedProgramParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 UserDefinedProgramParametersDefaultTypeInternal _UserDefinedProgramParameters_default_instance_;
PROTOBUF_CONSTEXPR AssignParameters::AssignParameters(
    ::_pbi::ConstantInitialized) {}
struct AssignParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR AssignParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~AssignParametersDefaultTypeInternal() {}
  union {
    AssignParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 AssignParametersDefaultTypeInternal _AssignParameters_default_instance_;
PROTOBUF_CONSTEXPR GradientAccumulationStatus::GradientAccumulationStatus(
    ::_pbi::ConstantInitialized) {}
struct GradientAccumulationStatusDefaultTypeInternal {
  PROTOBUF_CONSTEXPR GradientAccumulationStatusDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~GradientAccumulationStatusDefaultTypeInternal() {}
  union {
    GradientAccumulationStatus _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 GradientAccumulationStatusDefaultTypeInternal _GradientAccumulationStatus_default_instance_;
PROTOBUF_CONSTEXPR LowDimensionalPackingStatus::LowDimensionalPackingStatus(
    ::_pbi::ConstantInitialized) {}
struct LowDimensionalPackingStatusDefaultTypeInternal {
  PROTOBUF_CONSTEXPR LowDimensionalPackingStatusDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~LowDimensionalPackingStatusDefaultTypeInternal() {}
  union {
    LowDimensionalPackingStatus _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 LowDimensionalPackingStatusDefaultTypeInternal _LowDimensionalPackingStatus_default_instance_;
PROTOBUF_CONSTEXPR HotIdReplicationConfiguration::HotIdReplicationConfiguration(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.status_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct HotIdReplicationConfigurationDefaultTypeInternal {
  PROTOBUF_CONSTEXPR HotIdReplicationConfigurationDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~HotIdReplicationConfigurationDefaultTypeInternal() {}
  union {
    HotIdReplicationConfiguration _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 HotIdReplicationConfigurationDefaultTypeInternal _HotIdReplicationConfiguration_default_instance_;
PROTOBUF_CONSTEXPR OptimizationParameters::OptimizationParameters(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.clipping_limits_)*/nullptr
  , /*decltype(_impl_.gradient_clipping_limits_)*/nullptr
  , /*decltype(_impl_.learning_rate_)*/nullptr
  , /*decltype(_impl_.hot_id_replication_configuration_)*/nullptr
  , /*decltype(_impl_.simulated_quantization_)*/nullptr
  , /*decltype(_impl_.weight_decay_factor_)*/0
  , /*decltype(_impl_.gradient_accumulation_status_)*/0
  , /*decltype(_impl_.multiply_weight_decay_factor_by_learning_rate_)*/false
  , /*decltype(_impl_.low_dimensional_packing_status_)*/0
  , /*decltype(_impl_.parameters_)*/{}
  , /*decltype(_impl_._cached_size_)*/{}
  , /*decltype(_impl_._oneof_case_)*/{}} {}
struct OptimizationParametersDefaultTypeInternal {
  PROTOBUF_CONSTEXPR OptimizationParametersDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~OptimizationParametersDefaultTypeInternal() {}
  union {
    OptimizationParameters _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 OptimizationParametersDefaultTypeInternal _OptimizationParameters_default_instance_;
PROTOBUF_CONSTEXPR StateVariableSpecification_UserDefined::StateVariableSpecification_UserDefined(
    ::_pbi::ConstantInitialized) {}
struct StateVariableSpecification_UserDefinedDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StateVariableSpecification_UserDefinedDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~StateVariableSpecification_UserDefinedDefaultTypeInternal() {}
  union {
    StateVariableSpecification_UserDefined _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StateVariableSpecification_UserDefinedDefaultTypeInternal _StateVariableSpecification_UserDefined_default_instance_;
PROTOBUF_CONSTEXPR StateVariableSpecification_FillWithConstant::StateVariableSpecification_FillWithConstant(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.initial_value_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct StateVariableSpecification_FillWithConstantDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StateVariableSpecification_FillWithConstantDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~StateVariableSpecification_FillWithConstantDefaultTypeInternal() {}
  union {
    StateVariableSpecification_FillWithConstant _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StateVariableSpecification_FillWithConstantDefaultTypeInternal _StateVariableSpecification_FillWithConstant_default_instance_;
PROTOBUF_CONSTEXPR StateVariableSpecification::StateVariableSpecification(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.name_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.usage_)*/{}
  , /*decltype(_impl_._cached_size_)*/{}
  , /*decltype(_impl_._oneof_case_)*/{}} {}
struct StateVariableSpecificationDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StateVariableSpecificationDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~StateVariableSpecificationDefaultTypeInternal() {}
  union {
    StateVariableSpecification _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StateVariableSpecificationDefaultTypeInternal _StateVariableSpecification_default_instance_;
}  // namespace tpu
}  // namespace tensorflow
static ::_pb::Metadata file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[29];
static const ::_pb::EnumDescriptor* file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[3];
static constexpr ::_pb::ServiceDescriptor const** file_level_service_descriptors_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto = nullptr;

const uint32_t TableStruct_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::ClippingLimits, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::ClippingLimits, _impl_.lower_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::ClippingLimits, _impl_.upper_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::SimulatedQuantization, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::SimulatedQuantization, _impl_.enabled_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::SimulatedQuantization, _impl_.clipping_limits_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::SimulatedQuantization, _impl_.num_buckets_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::DynamicLearningRate, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::DynamicLearningRate, _impl_.tag_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::LearningRate, _internal_metadata_),
  ~0u,  // no _extensions_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::LearningRate, _impl_._oneof_case_[0]),
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::LearningRate, _impl_.learning_rate_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdagradParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdagradMomentumParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdagradMomentumParameters, _impl_.momentum_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdagradMomentumParameters, _impl_.use_nesterov_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdagradMomentumParameters, _impl_.exponent_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdagradMomentumParameters, _impl_.beta2_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdagradMomentumParameters, _impl_.epsilon_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::BoundedAdagradParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::BoundedAdagradParameters, _impl_.update_accumulator_first_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::BoundedAdagradParameters, _impl_.max_var_update_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::BoundedAdagradParameters, _impl_.max_accumulator_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::StochasticGradientDescentParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::FtrlParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::FtrlParameters, _impl_.l1_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::FtrlParameters, _impl_.l2_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::FtrlParameters, _impl_.lr_power_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::FtrlParameters, _impl_.beta_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::FtrlParameters, _impl_.multiply_linear_by_lr_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::FtrlParameters, _impl_.allow_zero_accumulator_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdamParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdamParameters, _impl_.beta1_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdamParameters, _impl_.beta2_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdamParameters, _impl_.epsilon_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdamParameters, _impl_.use_non_lazy_adam_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdamParameters, _impl_.use_sum_inside_sqrt_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MomentumParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MomentumParameters, _impl_.momentum_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MomentumParameters, _impl_.use_nesterov_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::LionParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::LionParameters, _impl_.beta1_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::LionParameters, _impl_.beta2_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::LionParameters, _impl_.use_non_lazy_lion_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::RmsPropParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::RmsPropParameters, _impl_.rho_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::RmsPropParameters, _impl_.momentum_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::RmsPropParameters, _impl_.epsilon_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::CenteredRmsPropParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::CenteredRmsPropParameters, _impl_.rho_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::CenteredRmsPropParameters, _impl_.momentum_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::CenteredRmsPropParameters, _impl_.epsilon_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _impl_.l2_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _impl_.lr_power_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _impl_.min_servable_mdl_benefit_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _impl_.mdl_mix_in_margin_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _impl_.mdl_benefit_rampup_coeff_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _impl_.mdl_min_weight_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _impl_.benefit_revisit_scale_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _impl_.max_event_benefit_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _impl_.max_total_benefit_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _impl_.mdl_hard_limit_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _impl_.hard_limit_min_benefit_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::MdlAdagradLightParameters, _impl_.mdl_regularize_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdadeltaParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdadeltaParameters, _impl_.rho_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AdadeltaParameters, _impl_.epsilon_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::ProximalAdagradParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::ProximalAdagradParameters, _impl_.l1_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::ProximalAdagradParameters, _impl_.l2_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OnlineYogiParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OnlineYogiParameters, _impl_.l1_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OnlineYogiParameters, _impl_.l2_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OnlineYogiParameters, _impl_.beta2_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::ProximalYogiParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::ProximalYogiParameters, _impl_.l1_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::ProximalYogiParameters, _impl_.l2_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::ProximalYogiParameters, _impl_.beta1_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::ProximalYogiParameters, _impl_.beta2_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::ProximalYogiParameters, _impl_.epsilon_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::FrequencyEstimatorParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::FrequencyEstimatorParameters, _impl_.tau_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::FrequencyEstimatorParameters, _impl_.max_delta_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::FrequencyEstimatorParameters, _impl_.outlier_threshold_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::FrequencyEstimatorParameters, _impl_.weight_exponent_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::UserDefinedProgramParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::UserDefinedProgramParameters, _impl_.program_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::AssignParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::GradientAccumulationStatus, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::LowDimensionalPackingStatus, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::HotIdReplicationConfiguration, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::HotIdReplicationConfiguration, _impl_.status_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OptimizationParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OptimizationParameters, _impl_._oneof_case_[0]),
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OptimizationParameters, _impl_.learning_rate_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OptimizationParameters, _impl_.clipping_limits_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OptimizationParameters, _impl_.gradient_clipping_limits_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OptimizationParameters, _impl_.weight_decay_factor_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OptimizationParameters, _impl_.multiply_weight_decay_factor_by_learning_rate_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OptimizationParameters, _impl_.simulated_quantization_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OptimizationParameters, _impl_.gradient_accumulation_status_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OptimizationParameters, _impl_.low_dimensional_packing_status_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OptimizationParameters, _impl_.hot_id_replication_configuration_),
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::OptimizationParameters, _impl_.parameters_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::StateVariableSpecification_UserDefined, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::StateVariableSpecification_FillWithConstant, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::StateVariableSpecification_FillWithConstant, _impl_.initial_value_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::StateVariableSpecification, _internal_metadata_),
  ~0u,  // no _extensions_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::StateVariableSpecification, _impl_._oneof_case_[0]),
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::StateVariableSpecification, _impl_.name_),
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  PROTOBUF_FIELD_OFFSET(::tensorflow::tpu::StateVariableSpecification, _impl_.usage_),
};
static const ::_pbi::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, -1, sizeof(::tensorflow::tpu::ClippingLimits)},
  { 8, -1, -1, sizeof(::tensorflow::tpu::SimulatedQuantization)},
  { 17, -1, -1, sizeof(::tensorflow::tpu::DynamicLearningRate)},
  { 24, -1, -1, sizeof(::tensorflow::tpu::LearningRate)},
  { 33, -1, -1, sizeof(::tensorflow::tpu::AdagradParameters)},
  { 39, -1, -1, sizeof(::tensorflow::tpu::AdagradMomentumParameters)},
  { 50, -1, -1, sizeof(::tensorflow::tpu::BoundedAdagradParameters)},
  { 59, -1, -1, sizeof(::tensorflow::tpu::StochasticGradientDescentParameters)},
  { 65, -1, -1, sizeof(::tensorflow::tpu::FtrlParameters)},
  { 77, -1, -1, sizeof(::tensorflow::tpu::AdamParameters)},
  { 88, -1, -1, sizeof(::tensorflow::tpu::MomentumParameters)},
  { 96, -1, -1, sizeof(::tensorflow::tpu::LionParameters)},
  { 105, -1, -1, sizeof(::tensorflow::tpu::RmsPropParameters)},
  { 114, -1, -1, sizeof(::tensorflow::tpu::CenteredRmsPropParameters)},
  { 123, -1, -1, sizeof(::tensorflow::tpu::MdlAdagradLightParameters)},
  { 141, -1, -1, sizeof(::tensorflow::tpu::AdadeltaParameters)},
  { 149, -1, -1, sizeof(::tensorflow::tpu::ProximalAdagradParameters)},
  { 157, -1, -1, sizeof(::tensorflow::tpu::OnlineYogiParameters)},
  { 166, -1, -1, sizeof(::tensorflow::tpu::ProximalYogiParameters)},
  { 177, -1, -1, sizeof(::tensorflow::tpu::FrequencyEstimatorParameters)},
  { 187, -1, -1, sizeof(::tensorflow::tpu::UserDefinedProgramParameters)},
  { 194, -1, -1, sizeof(::tensorflow::tpu::AssignParameters)},
  { 200, -1, -1, sizeof(::tensorflow::tpu::GradientAccumulationStatus)},
  { 206, -1, -1, sizeof(::tensorflow::tpu::LowDimensionalPackingStatus)},
  { 212, -1, -1, sizeof(::tensorflow::tpu::HotIdReplicationConfiguration)},
  { 219, -1, -1, sizeof(::tensorflow::tpu::OptimizationParameters)},
  { 253, -1, -1, sizeof(::tensorflow::tpu::StateVariableSpecification_UserDefined)},
  { 259, -1, -1, sizeof(::tensorflow::tpu::StateVariableSpecification_FillWithConstant)},
  { 266, -1, -1, sizeof(::tensorflow::tpu::StateVariableSpecification)},
};

static const ::_pb::Message* const file_default_instances[] = {
  &::tensorflow::tpu::_ClippingLimits_default_instance_._instance,
  &::tensorflow::tpu::_SimulatedQuantization_default_instance_._instance,
  &::tensorflow::tpu::_DynamicLearningRate_default_instance_._instance,
  &::tensorflow::tpu::_LearningRate_default_instance_._instance,
  &::tensorflow::tpu::_AdagradParameters_default_instance_._instance,
  &::tensorflow::tpu::_AdagradMomentumParameters_default_instance_._instance,
  &::tensorflow::tpu::_BoundedAdagradParameters_default_instance_._instance,
  &::tensorflow::tpu::_StochasticGradientDescentParameters_default_instance_._instance,
  &::tensorflow::tpu::_FtrlParameters_default_instance_._instance,
  &::tensorflow::tpu::_AdamParameters_default_instance_._instance,
  &::tensorflow::tpu::_MomentumParameters_default_instance_._instance,
  &::tensorflow::tpu::_LionParameters_default_instance_._instance,
  &::tensorflow::tpu::_RmsPropParameters_default_instance_._instance,
  &::tensorflow::tpu::_CenteredRmsPropParameters_default_instance_._instance,
  &::tensorflow::tpu::_MdlAdagradLightParameters_default_instance_._instance,
  &::tensorflow::tpu::_AdadeltaParameters_default_instance_._instance,
  &::tensorflow::tpu::_ProximalAdagradParameters_default_instance_._instance,
  &::tensorflow::tpu::_OnlineYogiParameters_default_instance_._instance,
  &::tensorflow::tpu::_ProximalYogiParameters_default_instance_._instance,
  &::tensorflow::tpu::_FrequencyEstimatorParameters_default_instance_._instance,
  &::tensorflow::tpu::_UserDefinedProgramParameters_default_instance_._instance,
  &::tensorflow::tpu::_AssignParameters_default_instance_._instance,
  &::tensorflow::tpu::_GradientAccumulationStatus_default_instance_._instance,
  &::tensorflow::tpu::_LowDimensionalPackingStatus_default_instance_._instance,
  &::tensorflow::tpu::_HotIdReplicationConfiguration_default_instance_._instance,
  &::tensorflow::tpu::_OptimizationParameters_default_instance_._instance,
  &::tensorflow::tpu::_StateVariableSpecification_UserDefined_default_instance_._instance,
  &::tensorflow::tpu::_StateVariableSpecification_FillWithConstant_default_instance_._instance,
  &::tensorflow::tpu::_StateVariableSpecification_default_instance_._instance,
};

const char descriptor_table_protodef_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n:tensorflow/core/protobuf/tpu/optimizat"
  "ion_parameters.proto\022\016tensorflow.tpu\032\036go"
  "ogle/protobuf/wrappers.proto\032\025xla/servic"
  "e/hlo.proto\"h\n\016ClippingLimits\022*\n\005lower\030\001"
  " \001(\0132\033.google.protobuf.FloatValue\022*\n\005upp"
  "er\030\002 \001(\0132\033.google.protobuf.FloatValue\"v\n"
  "\025SimulatedQuantization\022\017\n\007enabled\030\001 \001(\010\022"
  "7\n\017clipping_limits\030\002 \001(\0132\036.tensorflow.tp"
  "u.ClippingLimits\022\023\n\013num_buckets\030\003 \001(\005\"\"\n"
  "\023DynamicLearningRate\022\013\n\003tag\030\001 \001(\005\"k\n\014Lea"
  "rningRate\022\022\n\010constant\030\001 \001(\002H\000\0226\n\007dynamic"
  "\030\002 \001(\0132#.tensorflow.tpu.DynamicLearningR"
  "ateH\000B\017\n\rlearning_rate\".\n\021AdagradParamet"
  "ersJ\004\010\001\020\002R\023initial_accumulator\"u\n\031Adagra"
  "dMomentumParameters\022\020\n\010momentum\030\001 \001(\002\022\024\n"
  "\014use_nesterov\030\002 \001(\010\022\020\n\010exponent\030\003 \001(\002\022\r\n"
  "\005beta2\030\004 \001(\002\022\017\n\007epsilon\030\005 \001(\002\"m\n\030Bounded"
  "AdagradParameters\022 \n\030update_accumulator_"
  "first\030\001 \001(\010\022\026\n\016max_var_update\030\002 \001(\002\022\027\n\017m"
  "ax_accumulator\030\003 \001(\002\"%\n#StochasticGradie"
  "ntDescentParameters\"\266\001\n\016FtrlParameters\022\n"
  "\n\002l1\030\001 \001(\002\022\n\n\002l2\030\002 \001(\002\022\020\n\010lr_power\030\003 \001(\002"
  "\022\014\n\004beta\030\007 \001(\002\022\035\n\025multiply_linear_by_lr\030"
  "\006 \001(\010\022\"\n\026allow_zero_accumulator\030\010 \001(\010B\002\030"
  "\001J\004\010\004\020\005J\004\010\005\020\006R\rinitial_accumR\016initial_li"
  "near\"\231\001\n\016AdamParameters\022\r\n\005beta1\030\003 \001(\002\022\r"
  "\n\005beta2\030\004 \001(\002\022\017\n\007epsilon\030\005 \001(\002\022\031\n\021use_no"
  "n_lazy_adam\030\010 \001(\010\022\033\n\023use_sum_inside_sqrt"
  "\030\n \001(\010J\004\010\006\020\007J\004\010\007\020\010R\tinitial_mR\tinitial_v"
  "\"Q\n\022MomentumParameters\022\020\n\010momentum\030\001 \001(\002"
  "\022\024\n\014use_nesterov\030\002 \001(\010J\004\010\003\020\004R\rinitial_ac"
  "cum\"I\n\016LionParameters\022\r\n\005beta1\030\001 \001(\002\022\r\n\005"
  "beta2\030\002 \001(\002\022\031\n\021use_non_lazy_lion\030\003 \001(\010\"h"
  "\n\021RmsPropParameters\022\013\n\003rho\030\001 \001(\002\022\020\n\010mome"
  "ntum\030\002 \001(\002\022\017\n\007epsilon\030\003 \001(\002J\004\010\004\020\005J\004\010\005\020\006R"
  "\ninitial_msR\013initial_mom\"\202\001\n\031CenteredRms"
  "PropParameters\022\013\n\003rho\030\001 \001(\002\022\020\n\010momentum\030"
  "\002 \001(\002\022\017\n\007epsilon\030\003 \001(\002J\004\010\004\020\005J\004\010\005\020\006J\004\010\006\020\007"
  "R\ninitial_msR\013initial_momR\ninitial_mg\"\235\003"
  "\n\031MdlAdagradLightParameters\022\n\n\002l2\030\001 \001(\002\022"
  "\020\n\010lr_power\030\002 \001(\002\022 \n\030min_servable_mdl_be"
  "nefit\030\003 \001(\002\022\031\n\021mdl_mix_in_margin\030\004 \001(\002\022 "
  "\n\030mdl_benefit_rampup_coeff\030\005 \001(\002\022\026\n\016mdl_"
  "min_weight\030\006 \001(\002\022\035\n\025benefit_revisit_scal"
  "e\030\007 \001(\002\022\031\n\021max_event_benefit\030\010 \001(\002\022\031\n\021ma"
  "x_total_benefit\030\t \001(\002\022\026\n\016mdl_hard_limit\030"
  "\n \001(\002\022\036\n\026hard_limit_min_benefit\030\013 \001(\010\022\026\n"
  "\016mdl_regularize\030\014 \001(\010J\004\010\r\020\016J\004\010\016\020\017J\004\010\017\020\020R"
  "\023initial_accumulatorR\016initial_weightR\017in"
  "itial_benefit\"c\n\022AdadeltaParameters\022\013\n\003r"
  "ho\030\001 \001(\002\022\017\n\007epsilon\030\002 \001(\002J\004\010\003\020\004J\004\010\004\020\005R\023i"
  "nitial_accumulatorR\016initial_update\"N\n\031Pr"
  "oximalAdagradParameters\022\n\n\002l1\030\001 \001(\002\022\n\n\002l"
  "2\030\002 \001(\002J\004\010\003\020\004R\023initial_accumulator\"I\n\024On"
  "lineYogiParameters\022\n\n\002l1\030\001 \001(\002\022\n\n\002l2\030\002 \001"
  "(\002\022\r\n\005beta2\030\003 \001(\002J\004\010\006\020\007J\004\010\007\020\010\"k\n\026Proxima"
  "lYogiParameters\022\n\n\002l1\030\001 \001(\002\022\n\n\002l2\030\002 \001(\002\022"
  "\r\n\005beta1\030\003 \001(\002\022\r\n\005beta2\030\004 \001(\002\022\017\n\007epsilon"
  "\030\005 \001(\002J\004\010\010\020\tJ\004\010\t\020\n\"r\n\034FrequencyEstimator"
  "Parameters\022\013\n\003tau\030\001 \001(\002\022\021\n\tmax_delta\030\002 \001"
  "(\002\022\031\n\021outlier_threshold\030\003 \001(\002\022\027\n\017weight_"
  "exponent\030\004 \001(\002\"J\n\034UserDefinedProgramPara"
  "meters\022$\n\007program\030\001 \001(\0132\023.xla.HloModuleP"
  "rotoJ\004\010\002\020\003\"\022\n\020AssignParameters\"R\n\032Gradie"
  "ntAccumulationStatus\"4\n\006Status\022\017\n\013UNSPEC"
  "IFIED\020\000\022\013\n\007ENABLED\020\001\022\014\n\010DISABLED\020\002\"S\n\033Lo"
  "wDimensionalPackingStatus\"4\n\006Status\022\017\n\013U"
  "NSPECIFIED\020\000\022\013\n\007ENABLED\020\001\022\014\n\010DISABLED\020\002\""
  "\257\001\n\035HotIdReplicationConfiguration\022D\n\006sta"
  "tus\030\001 \001(\01624.tensorflow.tpu.HotIdReplicat"
  "ionConfiguration.Status\"H\n\006Status\022\017\n\013UNS"
  "PECIFIED\020\000\022\013\n\007ENABLED\020\001\022\014\n\010DISABLED\020\002\022\022\n"
  "\016MIGRATION_ONLY\020\003\"\204\016\n\026OptimizationParame"
  "ters\0223\n\rlearning_rate\030\r \001(\0132\034.tensorflow"
  ".tpu.LearningRate\0227\n\017clipping_limits\030\002 \001"
  "(\0132\036.tensorflow.tpu.ClippingLimits\022@\n\030gr"
  "adient_clipping_limits\030\007 \001(\0132\036.tensorflo"
  "w.tpu.ClippingLimits\022\033\n\023weight_decay_fac"
  "tor\030\020 \001(\002\0225\n-multiply_weight_decay_facto"
  "r_by_learning_rate\030\026 \001(\010\022E\n\026simulated_qu"
  "antization\030\033 \001(\0132%.tensorflow.tpu.Simula"
  "tedQuantization\022W\n\034gradient_accumulation"
  "_status\030\021 \001(\01621.tensorflow.tpu.GradientA"
  "ccumulationStatus.Status\022Z\n\036low_dimensio"
  "nal_packing_status\030\034 \001(\01622.tensorflow.tp"
  "u.LowDimensionalPackingStatus.Status\022W\n "
  "hot_id_replication_configuration\030\022 \001(\0132-"
  ".tensorflow.tpu.HotIdReplicationConfigur"
  "ation\0224\n\007adagrad\030\003 \001(\0132!.tensorflow.tpu."
  "AdagradParametersH\000\022E\n\020adagrad_momentum\030"
  "\032 \001(\0132).tensorflow.tpu.AdagradMomentumPa"
  "rametersH\000\022C\n\017bounded_adagrad\030\023 \001(\0132(.te"
  "nsorflow.tpu.BoundedAdagradParametersH\000\022"
  "Z\n\033stochastic_gradient_descent\030\004 \001(\01323.t"
  "ensorflow.tpu.StochasticGradientDescentP"
  "arametersH\000\022.\n\004ftrl\030\005 \001(\0132\036.tensorflow.t"
  "pu.FtrlParametersH\000\022.\n\004adam\030\006 \001(\0132\036.tens"
  "orflow.tpu.AdamParametersH\000\0226\n\010momentum\030"
  "\010 \001(\0132\".tensorflow.tpu.MomentumParameter"
  "sH\000\022.\n\004lion\030\035 \001(\0132\036.tensorflow.tpu.LionP"
  "arametersH\000\0225\n\010rms_prop\030\t \001(\0132!.tensorfl"
  "ow.tpu.RmsPropParametersH\000\022F\n\021centered_r"
  "ms_prop\030\n \001(\0132).tensorflow.tpu.CenteredR"
  "msPropParametersH\000\022F\n\021mdl_adagrad_light\030"
  "\013 \001(\0132).tensorflow.tpu.MdlAdagradLightPa"
  "rametersH\000\0226\n\010adadelta\030\014 \001(\0132\".tensorflo"
  "w.tpu.AdadeltaParametersH\000\022E\n\020proximal_a"
  "dagrad\030\016 \001(\0132).tensorflow.tpu.ProximalAd"
  "agradParametersH\000\022;\n\013online_yogi\030\024 \001(\0132$"
  ".tensorflow.tpu.OnlineYogiParametersH\000\022\?"
  "\n\rproximal_yogi\030\025 \001(\0132&.tensorflow.tpu.P"
  "roximalYogiParametersH\000\022K\n\023frequency_est"
  "imator\030\027 \001(\0132,.tensorflow.tpu.FrequencyE"
  "stimatorParametersH\000\022L\n\024user_defined_pro"
  "gram\030\030 \001(\0132,.tensorflow.tpu.UserDefinedP"
  "rogramParametersH\000\0222\n\006assign\030\031 \001(\0132 .ten"
  "sorflow.tpu.AssignParametersH\000B\014\n\nparame"
  "tersJ\004\010\001\020\002J\004\010\017\020\020\"\236\002\n\032StateVariableSpecif"
  "ication\022\014\n\004name\030\001 \001(\t\022N\n\014user_defined\030\002 "
  "\001(\01326.tensorflow.tpu.StateVariableSpecif"
  "ication.UserDefinedH\000\022Y\n\022fill_with_const"
  "ant\030\003 \001(\0132;.tensorflow.tpu.StateVariable"
  "Specification.FillWithConstantH\000\032\023\n\013User"
  "DefinedJ\004\010\001\020\002\032)\n\020FillWithConstant\022\025\n\rini"
  "tial_value\030\001 \001(\001B\007\n\005usageb\006proto3"
  ;
static const ::_pbi::DescriptorTable* const descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_deps[2] = {
  &::descriptor_table_google_2fprotobuf_2fwrappers_2eproto,
  &::descriptor_table_xla_2fservice_2fhlo_2eproto,
};
static ::_pbi::once_flag descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once;
const ::_pbi::DescriptorTable descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto = {
    false, false, 4993, descriptor_table_protodef_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto,
    "tensorflow/core/protobuf/tpu/optimization_parameters.proto",
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once, descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_deps, 2, 29,
    schemas, file_default_instances, TableStruct_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto::offsets,
    file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto, file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto,
    file_level_service_descriptors_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto,
};
PROTOBUF_ATTRIBUTE_WEAK const ::_pbi::DescriptorTable* descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter() {
  return &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto;
}

// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::_pbi::AddDescriptorsRunner dynamic_init_dummy_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto(&descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto);
namespace tensorflow {
namespace tpu {
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* GradientAccumulationStatus_Status_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto);
  return file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[0];
}
bool GradientAccumulationStatus_Status_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr GradientAccumulationStatus_Status GradientAccumulationStatus::UNSPECIFIED;
constexpr GradientAccumulationStatus_Status GradientAccumulationStatus::ENABLED;
constexpr GradientAccumulationStatus_Status GradientAccumulationStatus::DISABLED;
constexpr GradientAccumulationStatus_Status GradientAccumulationStatus::Status_MIN;
constexpr GradientAccumulationStatus_Status GradientAccumulationStatus::Status_MAX;
constexpr int GradientAccumulationStatus::Status_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* LowDimensionalPackingStatus_Status_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto);
  return file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[1];
}
bool LowDimensionalPackingStatus_Status_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr LowDimensionalPackingStatus_Status LowDimensionalPackingStatus::UNSPECIFIED;
constexpr LowDimensionalPackingStatus_Status LowDimensionalPackingStatus::ENABLED;
constexpr LowDimensionalPackingStatus_Status LowDimensionalPackingStatus::DISABLED;
constexpr LowDimensionalPackingStatus_Status LowDimensionalPackingStatus::Status_MIN;
constexpr LowDimensionalPackingStatus_Status LowDimensionalPackingStatus::Status_MAX;
constexpr int LowDimensionalPackingStatus::Status_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* HotIdReplicationConfiguration_Status_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto);
  return file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[2];
}
bool HotIdReplicationConfiguration_Status_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
    case 3:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr HotIdReplicationConfiguration_Status HotIdReplicationConfiguration::UNSPECIFIED;
constexpr HotIdReplicationConfiguration_Status HotIdReplicationConfiguration::ENABLED;
constexpr HotIdReplicationConfiguration_Status HotIdReplicationConfiguration::DISABLED;
constexpr HotIdReplicationConfiguration_Status HotIdReplicationConfiguration::MIGRATION_ONLY;
constexpr HotIdReplicationConfiguration_Status HotIdReplicationConfiguration::Status_MIN;
constexpr HotIdReplicationConfiguration_Status HotIdReplicationConfiguration::Status_MAX;
constexpr int HotIdReplicationConfiguration::Status_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

// ===================================================================

class ClippingLimits::_Internal {
 public:
  static const ::PROTOBUF_NAMESPACE_ID::FloatValue& lower(const ClippingLimits* msg);
  static const ::PROTOBUF_NAMESPACE_ID::FloatValue& upper(const ClippingLimits* msg);
};

const ::PROTOBUF_NAMESPACE_ID::FloatValue&
ClippingLimits::_Internal::lower(const ClippingLimits* msg) {
  return *msg->_impl_.lower_;
}
const ::PROTOBUF_NAMESPACE_ID::FloatValue&
ClippingLimits::_Internal::upper(const ClippingLimits* msg) {
  return *msg->_impl_.upper_;
}
void ClippingLimits::clear_lower() {
  if (GetArenaForAllocation() == nullptr && _impl_.lower_ != nullptr) {
    delete _impl_.lower_;
  }
  _impl_.lower_ = nullptr;
}
void ClippingLimits::clear_upper() {
  if (GetArenaForAllocation() == nullptr && _impl_.upper_ != nullptr) {
    delete _impl_.upper_;
  }
  _impl_.upper_ = nullptr;
}
ClippingLimits::ClippingLimits(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.ClippingLimits)
}
ClippingLimits::ClippingLimits(const ClippingLimits& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  ClippingLimits* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.lower_){nullptr}
    , decltype(_impl_.upper_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  if (from._internal_has_lower()) {
    _this->_impl_.lower_ = new ::PROTOBUF_NAMESPACE_ID::FloatValue(*from._impl_.lower_);
  }
  if (from._internal_has_upper()) {
    _this->_impl_.upper_ = new ::PROTOBUF_NAMESPACE_ID::FloatValue(*from._impl_.upper_);
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.ClippingLimits)
}

inline void ClippingLimits::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.lower_){nullptr}
    , decltype(_impl_.upper_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

ClippingLimits::~ClippingLimits() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.ClippingLimits)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void ClippingLimits::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (this != internal_default_instance()) delete _impl_.lower_;
  if (this != internal_default_instance()) delete _impl_.upper_;
}

void ClippingLimits::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void ClippingLimits::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.ClippingLimits)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaForAllocation() == nullptr && _impl_.lower_ != nullptr) {
    delete _impl_.lower_;
  }
  _impl_.lower_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.upper_ != nullptr) {
    delete _impl_.upper_;
  }
  _impl_.upper_ = nullptr;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ClippingLimits::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .google.protobuf.FloatValue lower = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_lower(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .google.protobuf.FloatValue upper = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_upper(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ClippingLimits::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.ClippingLimits)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .google.protobuf.FloatValue lower = 1;
  if (this->_internal_has_lower()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(1, _Internal::lower(this),
        _Internal::lower(this).GetCachedSize(), target, stream);
  }

  // .google.protobuf.FloatValue upper = 2;
  if (this->_internal_has_upper()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::upper(this),
        _Internal::upper(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.ClippingLimits)
  return target;
}

size_t ClippingLimits::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.ClippingLimits)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .google.protobuf.FloatValue lower = 1;
  if (this->_internal_has_lower()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.lower_);
  }

  // .google.protobuf.FloatValue upper = 2;
  if (this->_internal_has_upper()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.upper_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ClippingLimits::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    ClippingLimits::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ClippingLimits::GetClassData() const { return &_class_data_; }


void ClippingLimits::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<ClippingLimits*>(&to_msg);
  auto& from = static_cast<const ClippingLimits&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.ClippingLimits)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_has_lower()) {
    _this->_internal_mutable_lower()->::PROTOBUF_NAMESPACE_ID::FloatValue::MergeFrom(
        from._internal_lower());
  }
  if (from._internal_has_upper()) {
    _this->_internal_mutable_upper()->::PROTOBUF_NAMESPACE_ID::FloatValue::MergeFrom(
        from._internal_upper());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ClippingLimits::CopyFrom(const ClippingLimits& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.ClippingLimits)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ClippingLimits::IsInitialized() const {
  return true;
}

void ClippingLimits::InternalSwap(ClippingLimits* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(ClippingLimits, _impl_.upper_)
      + sizeof(ClippingLimits::_impl_.upper_)
      - PROTOBUF_FIELD_OFFSET(ClippingLimits, _impl_.lower_)>(
          reinterpret_cast<char*>(&_impl_.lower_),
          reinterpret_cast<char*>(&other->_impl_.lower_));
}

::PROTOBUF_NAMESPACE_ID::Metadata ClippingLimits::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[0]);
}

// ===================================================================

class SimulatedQuantization::_Internal {
 public:
  static const ::tensorflow::tpu::ClippingLimits& clipping_limits(const SimulatedQuantization* msg);
};

const ::tensorflow::tpu::ClippingLimits&
SimulatedQuantization::_Internal::clipping_limits(const SimulatedQuantization* msg) {
  return *msg->_impl_.clipping_limits_;
}
SimulatedQuantization::SimulatedQuantization(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.SimulatedQuantization)
}
SimulatedQuantization::SimulatedQuantization(const SimulatedQuantization& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  SimulatedQuantization* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.clipping_limits_){nullptr}
    , decltype(_impl_.enabled_){}
    , decltype(_impl_.num_buckets_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  if (from._internal_has_clipping_limits()) {
    _this->_impl_.clipping_limits_ = new ::tensorflow::tpu::ClippingLimits(*from._impl_.clipping_limits_);
  }
  ::memcpy(&_impl_.enabled_, &from._impl_.enabled_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.num_buckets_) -
    reinterpret_cast<char*>(&_impl_.enabled_)) + sizeof(_impl_.num_buckets_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.SimulatedQuantization)
}

inline void SimulatedQuantization::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.clipping_limits_){nullptr}
    , decltype(_impl_.enabled_){false}
    , decltype(_impl_.num_buckets_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

SimulatedQuantization::~SimulatedQuantization() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.SimulatedQuantization)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void SimulatedQuantization::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (this != internal_default_instance()) delete _impl_.clipping_limits_;
}

void SimulatedQuantization::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void SimulatedQuantization::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.SimulatedQuantization)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaForAllocation() == nullptr && _impl_.clipping_limits_ != nullptr) {
    delete _impl_.clipping_limits_;
  }
  _impl_.clipping_limits_ = nullptr;
  ::memset(&_impl_.enabled_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.num_buckets_) -
      reinterpret_cast<char*>(&_impl_.enabled_)) + sizeof(_impl_.num_buckets_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* SimulatedQuantization::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // bool enabled = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.enabled_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.ClippingLimits clipping_limits = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_clipping_limits(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 num_buckets = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _impl_.num_buckets_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* SimulatedQuantization::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.SimulatedQuantization)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // bool enabled = 1;
  if (this->_internal_enabled() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(1, this->_internal_enabled(), target);
  }

  // .tensorflow.tpu.ClippingLimits clipping_limits = 2;
  if (this->_internal_has_clipping_limits()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::clipping_limits(this),
        _Internal::clipping_limits(this).GetCachedSize(), target, stream);
  }

  // int32 num_buckets = 3;
  if (this->_internal_num_buckets() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(3, this->_internal_num_buckets(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.SimulatedQuantization)
  return target;
}

size_t SimulatedQuantization::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.SimulatedQuantization)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.tpu.ClippingLimits clipping_limits = 2;
  if (this->_internal_has_clipping_limits()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.clipping_limits_);
  }

  // bool enabled = 1;
  if (this->_internal_enabled() != 0) {
    total_size += 1 + 1;
  }

  // int32 num_buckets = 3;
  if (this->_internal_num_buckets() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_num_buckets());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData SimulatedQuantization::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    SimulatedQuantization::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*SimulatedQuantization::GetClassData() const { return &_class_data_; }


void SimulatedQuantization::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<SimulatedQuantization*>(&to_msg);
  auto& from = static_cast<const SimulatedQuantization&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.SimulatedQuantization)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_has_clipping_limits()) {
    _this->_internal_mutable_clipping_limits()->::tensorflow::tpu::ClippingLimits::MergeFrom(
        from._internal_clipping_limits());
  }
  if (from._internal_enabled() != 0) {
    _this->_internal_set_enabled(from._internal_enabled());
  }
  if (from._internal_num_buckets() != 0) {
    _this->_internal_set_num_buckets(from._internal_num_buckets());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void SimulatedQuantization::CopyFrom(const SimulatedQuantization& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.SimulatedQuantization)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SimulatedQuantization::IsInitialized() const {
  return true;
}

void SimulatedQuantization::InternalSwap(SimulatedQuantization* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(SimulatedQuantization, _impl_.num_buckets_)
      + sizeof(SimulatedQuantization::_impl_.num_buckets_)
      - PROTOBUF_FIELD_OFFSET(SimulatedQuantization, _impl_.clipping_limits_)>(
          reinterpret_cast<char*>(&_impl_.clipping_limits_),
          reinterpret_cast<char*>(&other->_impl_.clipping_limits_));
}

::PROTOBUF_NAMESPACE_ID::Metadata SimulatedQuantization::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[1]);
}

// ===================================================================

class DynamicLearningRate::_Internal {
 public:
};

DynamicLearningRate::DynamicLearningRate(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.DynamicLearningRate)
}
DynamicLearningRate::DynamicLearningRate(const DynamicLearningRate& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  DynamicLearningRate* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.tag_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _this->_impl_.tag_ = from._impl_.tag_;
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.DynamicLearningRate)
}

inline void DynamicLearningRate::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.tag_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

DynamicLearningRate::~DynamicLearningRate() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.DynamicLearningRate)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void DynamicLearningRate::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void DynamicLearningRate::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void DynamicLearningRate::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.DynamicLearningRate)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.tag_ = 0;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* DynamicLearningRate::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int32 tag = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.tag_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* DynamicLearningRate::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.DynamicLearningRate)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int32 tag = 1;
  if (this->_internal_tag() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(1, this->_internal_tag(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.DynamicLearningRate)
  return target;
}

size_t DynamicLearningRate::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.DynamicLearningRate)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // int32 tag = 1;
  if (this->_internal_tag() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_tag());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData DynamicLearningRate::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    DynamicLearningRate::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*DynamicLearningRate::GetClassData() const { return &_class_data_; }


void DynamicLearningRate::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<DynamicLearningRate*>(&to_msg);
  auto& from = static_cast<const DynamicLearningRate&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.DynamicLearningRate)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_tag() != 0) {
    _this->_internal_set_tag(from._internal_tag());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void DynamicLearningRate::CopyFrom(const DynamicLearningRate& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.DynamicLearningRate)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool DynamicLearningRate::IsInitialized() const {
  return true;
}

void DynamicLearningRate::InternalSwap(DynamicLearningRate* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_.tag_, other->_impl_.tag_);
}

::PROTOBUF_NAMESPACE_ID::Metadata DynamicLearningRate::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[2]);
}

// ===================================================================

class LearningRate::_Internal {
 public:
  static const ::tensorflow::tpu::DynamicLearningRate& dynamic(const LearningRate* msg);
};

const ::tensorflow::tpu::DynamicLearningRate&
LearningRate::_Internal::dynamic(const LearningRate* msg) {
  return *msg->_impl_.learning_rate_.dynamic_;
}
void LearningRate::set_allocated_dynamic(::tensorflow::tpu::DynamicLearningRate* dynamic) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_learning_rate();
  if (dynamic) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(dynamic);
    if (message_arena != submessage_arena) {
      dynamic = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, dynamic, submessage_arena);
    }
    set_has_dynamic();
    _impl_.learning_rate_.dynamic_ = dynamic;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.LearningRate.dynamic)
}
LearningRate::LearningRate(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.LearningRate)
}
LearningRate::LearningRate(const LearningRate& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  LearningRate* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.learning_rate_){}
    , /*decltype(_impl_._cached_size_)*/{}
    , /*decltype(_impl_._oneof_case_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  clear_has_learning_rate();
  switch (from.learning_rate_case()) {
    case kConstant: {
      _this->_internal_set_constant(from._internal_constant());
      break;
    }
    case kDynamic: {
      _this->_internal_mutable_dynamic()->::tensorflow::tpu::DynamicLearningRate::MergeFrom(
          from._internal_dynamic());
      break;
    }
    case LEARNING_RATE_NOT_SET: {
      break;
    }
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.LearningRate)
}

inline void LearningRate::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.learning_rate_){}
    , /*decltype(_impl_._cached_size_)*/{}
    , /*decltype(_impl_._oneof_case_)*/{}
  };
  clear_has_learning_rate();
}

LearningRate::~LearningRate() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.LearningRate)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void LearningRate::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (has_learning_rate()) {
    clear_learning_rate();
  }
}

void LearningRate::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void LearningRate::clear_learning_rate() {
// @@protoc_insertion_point(one_of_clear_start:tensorflow.tpu.LearningRate)
  switch (learning_rate_case()) {
    case kConstant: {
      // No need to clear
      break;
    }
    case kDynamic: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.learning_rate_.dynamic_;
      }
      break;
    }
    case LEARNING_RATE_NOT_SET: {
      break;
    }
  }
  _impl_._oneof_case_[0] = LEARNING_RATE_NOT_SET;
}


void LearningRate::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.LearningRate)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  clear_learning_rate();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* LearningRate::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float constant = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _internal_set_constant(::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr));
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.DynamicLearningRate dynamic = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_dynamic(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* LearningRate::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.LearningRate)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float constant = 1;
  if (_internal_has_constant()) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_constant(), target);
  }

  // .tensorflow.tpu.DynamicLearningRate dynamic = 2;
  if (_internal_has_dynamic()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::dynamic(this),
        _Internal::dynamic(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.LearningRate)
  return target;
}

size_t LearningRate::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.LearningRate)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  switch (learning_rate_case()) {
    // float constant = 1;
    case kConstant: {
      total_size += 1 + 4;
      break;
    }
    // .tensorflow.tpu.DynamicLearningRate dynamic = 2;
    case kDynamic: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.learning_rate_.dynamic_);
      break;
    }
    case LEARNING_RATE_NOT_SET: {
      break;
    }
  }
  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData LearningRate::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    LearningRate::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*LearningRate::GetClassData() const { return &_class_data_; }


void LearningRate::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<LearningRate*>(&to_msg);
  auto& from = static_cast<const LearningRate&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.LearningRate)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  switch (from.learning_rate_case()) {
    case kConstant: {
      _this->_internal_set_constant(from._internal_constant());
      break;
    }
    case kDynamic: {
      _this->_internal_mutable_dynamic()->::tensorflow::tpu::DynamicLearningRate::MergeFrom(
          from._internal_dynamic());
      break;
    }
    case LEARNING_RATE_NOT_SET: {
      break;
    }
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void LearningRate::CopyFrom(const LearningRate& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.LearningRate)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool LearningRate::IsInitialized() const {
  return true;
}

void LearningRate::InternalSwap(LearningRate* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_.learning_rate_, other->_impl_.learning_rate_);
  swap(_impl_._oneof_case_[0], other->_impl_._oneof_case_[0]);
}

::PROTOBUF_NAMESPACE_ID::Metadata LearningRate::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[3]);
}

// ===================================================================

class AdagradParameters::_Internal {
 public:
};

AdagradParameters::AdagradParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase(arena, is_message_owned) {
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.AdagradParameters)
}
AdagradParameters::AdagradParameters(const AdagradParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase() {
  AdagradParameters* const _this = this; (void)_this;
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.AdagradParameters)
}





const ::PROTOBUF_NAMESPACE_ID::Message::ClassData AdagradParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::CopyImpl,
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::MergeImpl,
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*AdagradParameters::GetClassData() const { return &_class_data_; }







::PROTOBUF_NAMESPACE_ID::Metadata AdagradParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[4]);
}

// ===================================================================

class AdagradMomentumParameters::_Internal {
 public:
};

AdagradMomentumParameters::AdagradMomentumParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.AdagradMomentumParameters)
}
AdagradMomentumParameters::AdagradMomentumParameters(const AdagradMomentumParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  AdagradMomentumParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.momentum_){}
    , decltype(_impl_.use_nesterov_){}
    , decltype(_impl_.exponent_){}
    , decltype(_impl_.beta2_){}
    , decltype(_impl_.epsilon_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.momentum_, &from._impl_.momentum_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.epsilon_) -
    reinterpret_cast<char*>(&_impl_.momentum_)) + sizeof(_impl_.epsilon_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.AdagradMomentumParameters)
}

inline void AdagradMomentumParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.momentum_){0}
    , decltype(_impl_.use_nesterov_){false}
    , decltype(_impl_.exponent_){0}
    , decltype(_impl_.beta2_){0}
    , decltype(_impl_.epsilon_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

AdagradMomentumParameters::~AdagradMomentumParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.AdagradMomentumParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void AdagradMomentumParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void AdagradMomentumParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void AdagradMomentumParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.AdagradMomentumParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.momentum_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.epsilon_) -
      reinterpret_cast<char*>(&_impl_.momentum_)) + sizeof(_impl_.epsilon_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* AdagradMomentumParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float momentum = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _impl_.momentum_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // bool use_nesterov = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.use_nesterov_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // float exponent = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 29)) {
          _impl_.exponent_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float beta2 = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 37)) {
          _impl_.beta2_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float epsilon = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 45)) {
          _impl_.epsilon_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* AdagradMomentumParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.AdagradMomentumParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float momentum = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_momentum = this->_internal_momentum();
  uint32_t raw_momentum;
  memcpy(&raw_momentum, &tmp_momentum, sizeof(tmp_momentum));
  if (raw_momentum != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_momentum(), target);
  }

  // bool use_nesterov = 2;
  if (this->_internal_use_nesterov() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(2, this->_internal_use_nesterov(), target);
  }

  // float exponent = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_exponent = this->_internal_exponent();
  uint32_t raw_exponent;
  memcpy(&raw_exponent, &tmp_exponent, sizeof(tmp_exponent));
  if (raw_exponent != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(3, this->_internal_exponent(), target);
  }

  // float beta2 = 4;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = this->_internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(4, this->_internal_beta2(), target);
  }

  // float epsilon = 5;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = this->_internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(5, this->_internal_epsilon(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.AdagradMomentumParameters)
  return target;
}

size_t AdagradMomentumParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.AdagradMomentumParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float momentum = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_momentum = this->_internal_momentum();
  uint32_t raw_momentum;
  memcpy(&raw_momentum, &tmp_momentum, sizeof(tmp_momentum));
  if (raw_momentum != 0) {
    total_size += 1 + 4;
  }

  // bool use_nesterov = 2;
  if (this->_internal_use_nesterov() != 0) {
    total_size += 1 + 1;
  }

  // float exponent = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_exponent = this->_internal_exponent();
  uint32_t raw_exponent;
  memcpy(&raw_exponent, &tmp_exponent, sizeof(tmp_exponent));
  if (raw_exponent != 0) {
    total_size += 1 + 4;
  }

  // float beta2 = 4;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = this->_internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    total_size += 1 + 4;
  }

  // float epsilon = 5;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = this->_internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    total_size += 1 + 4;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData AdagradMomentumParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    AdagradMomentumParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*AdagradMomentumParameters::GetClassData() const { return &_class_data_; }


void AdagradMomentumParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<AdagradMomentumParameters*>(&to_msg);
  auto& from = static_cast<const AdagradMomentumParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.AdagradMomentumParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_momentum = from._internal_momentum();
  uint32_t raw_momentum;
  memcpy(&raw_momentum, &tmp_momentum, sizeof(tmp_momentum));
  if (raw_momentum != 0) {
    _this->_internal_set_momentum(from._internal_momentum());
  }
  if (from._internal_use_nesterov() != 0) {
    _this->_internal_set_use_nesterov(from._internal_use_nesterov());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_exponent = from._internal_exponent();
  uint32_t raw_exponent;
  memcpy(&raw_exponent, &tmp_exponent, sizeof(tmp_exponent));
  if (raw_exponent != 0) {
    _this->_internal_set_exponent(from._internal_exponent());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = from._internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    _this->_internal_set_beta2(from._internal_beta2());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = from._internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    _this->_internal_set_epsilon(from._internal_epsilon());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void AdagradMomentumParameters::CopyFrom(const AdagradMomentumParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.AdagradMomentumParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool AdagradMomentumParameters::IsInitialized() const {
  return true;
}

void AdagradMomentumParameters::InternalSwap(AdagradMomentumParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(AdagradMomentumParameters, _impl_.epsilon_)
      + sizeof(AdagradMomentumParameters::_impl_.epsilon_)
      - PROTOBUF_FIELD_OFFSET(AdagradMomentumParameters, _impl_.momentum_)>(
          reinterpret_cast<char*>(&_impl_.momentum_),
          reinterpret_cast<char*>(&other->_impl_.momentum_));
}

::PROTOBUF_NAMESPACE_ID::Metadata AdagradMomentumParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[5]);
}

// ===================================================================

class BoundedAdagradParameters::_Internal {
 public:
};

BoundedAdagradParameters::BoundedAdagradParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.BoundedAdagradParameters)
}
BoundedAdagradParameters::BoundedAdagradParameters(const BoundedAdagradParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  BoundedAdagradParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.update_accumulator_first_){}
    , decltype(_impl_.max_var_update_){}
    , decltype(_impl_.max_accumulator_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.update_accumulator_first_, &from._impl_.update_accumulator_first_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.max_accumulator_) -
    reinterpret_cast<char*>(&_impl_.update_accumulator_first_)) + sizeof(_impl_.max_accumulator_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.BoundedAdagradParameters)
}

inline void BoundedAdagradParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.update_accumulator_first_){false}
    , decltype(_impl_.max_var_update_){0}
    , decltype(_impl_.max_accumulator_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

BoundedAdagradParameters::~BoundedAdagradParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.BoundedAdagradParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void BoundedAdagradParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void BoundedAdagradParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void BoundedAdagradParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.BoundedAdagradParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.update_accumulator_first_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.max_accumulator_) -
      reinterpret_cast<char*>(&_impl_.update_accumulator_first_)) + sizeof(_impl_.max_accumulator_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* BoundedAdagradParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // bool update_accumulator_first = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.update_accumulator_first_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // float max_var_update = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 21)) {
          _impl_.max_var_update_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float max_accumulator = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 29)) {
          _impl_.max_accumulator_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* BoundedAdagradParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.BoundedAdagradParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // bool update_accumulator_first = 1;
  if (this->_internal_update_accumulator_first() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(1, this->_internal_update_accumulator_first(), target);
  }

  // float max_var_update = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_var_update = this->_internal_max_var_update();
  uint32_t raw_max_var_update;
  memcpy(&raw_max_var_update, &tmp_max_var_update, sizeof(tmp_max_var_update));
  if (raw_max_var_update != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(2, this->_internal_max_var_update(), target);
  }

  // float max_accumulator = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_accumulator = this->_internal_max_accumulator();
  uint32_t raw_max_accumulator;
  memcpy(&raw_max_accumulator, &tmp_max_accumulator, sizeof(tmp_max_accumulator));
  if (raw_max_accumulator != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(3, this->_internal_max_accumulator(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.BoundedAdagradParameters)
  return target;
}

size_t BoundedAdagradParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.BoundedAdagradParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // bool update_accumulator_first = 1;
  if (this->_internal_update_accumulator_first() != 0) {
    total_size += 1 + 1;
  }

  // float max_var_update = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_var_update = this->_internal_max_var_update();
  uint32_t raw_max_var_update;
  memcpy(&raw_max_var_update, &tmp_max_var_update, sizeof(tmp_max_var_update));
  if (raw_max_var_update != 0) {
    total_size += 1 + 4;
  }

  // float max_accumulator = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_accumulator = this->_internal_max_accumulator();
  uint32_t raw_max_accumulator;
  memcpy(&raw_max_accumulator, &tmp_max_accumulator, sizeof(tmp_max_accumulator));
  if (raw_max_accumulator != 0) {
    total_size += 1 + 4;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData BoundedAdagradParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    BoundedAdagradParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*BoundedAdagradParameters::GetClassData() const { return &_class_data_; }


void BoundedAdagradParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<BoundedAdagradParameters*>(&to_msg);
  auto& from = static_cast<const BoundedAdagradParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.BoundedAdagradParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_update_accumulator_first() != 0) {
    _this->_internal_set_update_accumulator_first(from._internal_update_accumulator_first());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_var_update = from._internal_max_var_update();
  uint32_t raw_max_var_update;
  memcpy(&raw_max_var_update, &tmp_max_var_update, sizeof(tmp_max_var_update));
  if (raw_max_var_update != 0) {
    _this->_internal_set_max_var_update(from._internal_max_var_update());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_accumulator = from._internal_max_accumulator();
  uint32_t raw_max_accumulator;
  memcpy(&raw_max_accumulator, &tmp_max_accumulator, sizeof(tmp_max_accumulator));
  if (raw_max_accumulator != 0) {
    _this->_internal_set_max_accumulator(from._internal_max_accumulator());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void BoundedAdagradParameters::CopyFrom(const BoundedAdagradParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.BoundedAdagradParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool BoundedAdagradParameters::IsInitialized() const {
  return true;
}

void BoundedAdagradParameters::InternalSwap(BoundedAdagradParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(BoundedAdagradParameters, _impl_.max_accumulator_)
      + sizeof(BoundedAdagradParameters::_impl_.max_accumulator_)
      - PROTOBUF_FIELD_OFFSET(BoundedAdagradParameters, _impl_.update_accumulator_first_)>(
          reinterpret_cast<char*>(&_impl_.update_accumulator_first_),
          reinterpret_cast<char*>(&other->_impl_.update_accumulator_first_));
}

::PROTOBUF_NAMESPACE_ID::Metadata BoundedAdagradParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[6]);
}

// ===================================================================

class StochasticGradientDescentParameters::_Internal {
 public:
};

StochasticGradientDescentParameters::StochasticGradientDescentParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase(arena, is_message_owned) {
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.StochasticGradientDescentParameters)
}
StochasticGradientDescentParameters::StochasticGradientDescentParameters(const StochasticGradientDescentParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase() {
  StochasticGradientDescentParameters* const _this = this; (void)_this;
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.StochasticGradientDescentParameters)
}





const ::PROTOBUF_NAMESPACE_ID::Message::ClassData StochasticGradientDescentParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::CopyImpl,
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::MergeImpl,
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*StochasticGradientDescentParameters::GetClassData() const { return &_class_data_; }







::PROTOBUF_NAMESPACE_ID::Metadata StochasticGradientDescentParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[7]);
}

// ===================================================================

class FtrlParameters::_Internal {
 public:
};

FtrlParameters::FtrlParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.FtrlParameters)
}
FtrlParameters::FtrlParameters(const FtrlParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  FtrlParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.l1_){}
    , decltype(_impl_.l2_){}
    , decltype(_impl_.lr_power_){}
    , decltype(_impl_.beta_){}
    , decltype(_impl_.multiply_linear_by_lr_){}
    , decltype(_impl_.allow_zero_accumulator_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.l1_, &from._impl_.l1_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.allow_zero_accumulator_) -
    reinterpret_cast<char*>(&_impl_.l1_)) + sizeof(_impl_.allow_zero_accumulator_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.FtrlParameters)
}

inline void FtrlParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.l1_){0}
    , decltype(_impl_.l2_){0}
    , decltype(_impl_.lr_power_){0}
    , decltype(_impl_.beta_){0}
    , decltype(_impl_.multiply_linear_by_lr_){false}
    , decltype(_impl_.allow_zero_accumulator_){false}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

FtrlParameters::~FtrlParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.FtrlParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void FtrlParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void FtrlParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void FtrlParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.FtrlParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.l1_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.allow_zero_accumulator_) -
      reinterpret_cast<char*>(&_impl_.l1_)) + sizeof(_impl_.allow_zero_accumulator_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* FtrlParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float l1 = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _impl_.l1_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float l2 = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 21)) {
          _impl_.l2_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float lr_power = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 29)) {
          _impl_.lr_power_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // bool multiply_linear_by_lr = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 48)) {
          _impl_.multiply_linear_by_lr_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // float beta = 7;
      case 7:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 61)) {
          _impl_.beta_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // bool allow_zero_accumulator = 8 [deprecated = true];
      case 8:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 64)) {
          _impl_.allow_zero_accumulator_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* FtrlParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.FtrlParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float l1 = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l1 = this->_internal_l1();
  uint32_t raw_l1;
  memcpy(&raw_l1, &tmp_l1, sizeof(tmp_l1));
  if (raw_l1 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_l1(), target);
  }

  // float l2 = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = this->_internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(2, this->_internal_l2(), target);
  }

  // float lr_power = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_lr_power = this->_internal_lr_power();
  uint32_t raw_lr_power;
  memcpy(&raw_lr_power, &tmp_lr_power, sizeof(tmp_lr_power));
  if (raw_lr_power != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(3, this->_internal_lr_power(), target);
  }

  // bool multiply_linear_by_lr = 6;
  if (this->_internal_multiply_linear_by_lr() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(6, this->_internal_multiply_linear_by_lr(), target);
  }

  // float beta = 7;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta = this->_internal_beta();
  uint32_t raw_beta;
  memcpy(&raw_beta, &tmp_beta, sizeof(tmp_beta));
  if (raw_beta != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(7, this->_internal_beta(), target);
  }

  // bool allow_zero_accumulator = 8 [deprecated = true];
  if (this->_internal_allow_zero_accumulator() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(8, this->_internal_allow_zero_accumulator(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.FtrlParameters)
  return target;
}

size_t FtrlParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.FtrlParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float l1 = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l1 = this->_internal_l1();
  uint32_t raw_l1;
  memcpy(&raw_l1, &tmp_l1, sizeof(tmp_l1));
  if (raw_l1 != 0) {
    total_size += 1 + 4;
  }

  // float l2 = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = this->_internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    total_size += 1 + 4;
  }

  // float lr_power = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_lr_power = this->_internal_lr_power();
  uint32_t raw_lr_power;
  memcpy(&raw_lr_power, &tmp_lr_power, sizeof(tmp_lr_power));
  if (raw_lr_power != 0) {
    total_size += 1 + 4;
  }

  // float beta = 7;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta = this->_internal_beta();
  uint32_t raw_beta;
  memcpy(&raw_beta, &tmp_beta, sizeof(tmp_beta));
  if (raw_beta != 0) {
    total_size += 1 + 4;
  }

  // bool multiply_linear_by_lr = 6;
  if (this->_internal_multiply_linear_by_lr() != 0) {
    total_size += 1 + 1;
  }

  // bool allow_zero_accumulator = 8 [deprecated = true];
  if (this->_internal_allow_zero_accumulator() != 0) {
    total_size += 1 + 1;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData FtrlParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    FtrlParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*FtrlParameters::GetClassData() const { return &_class_data_; }


void FtrlParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<FtrlParameters*>(&to_msg);
  auto& from = static_cast<const FtrlParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.FtrlParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l1 = from._internal_l1();
  uint32_t raw_l1;
  memcpy(&raw_l1, &tmp_l1, sizeof(tmp_l1));
  if (raw_l1 != 0) {
    _this->_internal_set_l1(from._internal_l1());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = from._internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    _this->_internal_set_l2(from._internal_l2());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_lr_power = from._internal_lr_power();
  uint32_t raw_lr_power;
  memcpy(&raw_lr_power, &tmp_lr_power, sizeof(tmp_lr_power));
  if (raw_lr_power != 0) {
    _this->_internal_set_lr_power(from._internal_lr_power());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta = from._internal_beta();
  uint32_t raw_beta;
  memcpy(&raw_beta, &tmp_beta, sizeof(tmp_beta));
  if (raw_beta != 0) {
    _this->_internal_set_beta(from._internal_beta());
  }
  if (from._internal_multiply_linear_by_lr() != 0) {
    _this->_internal_set_multiply_linear_by_lr(from._internal_multiply_linear_by_lr());
  }
  if (from._internal_allow_zero_accumulator() != 0) {
    _this->_internal_set_allow_zero_accumulator(from._internal_allow_zero_accumulator());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void FtrlParameters::CopyFrom(const FtrlParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.FtrlParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool FtrlParameters::IsInitialized() const {
  return true;
}

void FtrlParameters::InternalSwap(FtrlParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(FtrlParameters, _impl_.allow_zero_accumulator_)
      + sizeof(FtrlParameters::_impl_.allow_zero_accumulator_)
      - PROTOBUF_FIELD_OFFSET(FtrlParameters, _impl_.l1_)>(
          reinterpret_cast<char*>(&_impl_.l1_),
          reinterpret_cast<char*>(&other->_impl_.l1_));
}

::PROTOBUF_NAMESPACE_ID::Metadata FtrlParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[8]);
}

// ===================================================================

class AdamParameters::_Internal {
 public:
};

AdamParameters::AdamParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.AdamParameters)
}
AdamParameters::AdamParameters(const AdamParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  AdamParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.beta1_){}
    , decltype(_impl_.beta2_){}
    , decltype(_impl_.epsilon_){}
    , decltype(_impl_.use_non_lazy_adam_){}
    , decltype(_impl_.use_sum_inside_sqrt_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.beta1_, &from._impl_.beta1_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.use_sum_inside_sqrt_) -
    reinterpret_cast<char*>(&_impl_.beta1_)) + sizeof(_impl_.use_sum_inside_sqrt_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.AdamParameters)
}

inline void AdamParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.beta1_){0}
    , decltype(_impl_.beta2_){0}
    , decltype(_impl_.epsilon_){0}
    , decltype(_impl_.use_non_lazy_adam_){false}
    , decltype(_impl_.use_sum_inside_sqrt_){false}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

AdamParameters::~AdamParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.AdamParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void AdamParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void AdamParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void AdamParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.AdamParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.beta1_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.use_sum_inside_sqrt_) -
      reinterpret_cast<char*>(&_impl_.beta1_)) + sizeof(_impl_.use_sum_inside_sqrt_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* AdamParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float beta1 = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 29)) {
          _impl_.beta1_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float beta2 = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 37)) {
          _impl_.beta2_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float epsilon = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 45)) {
          _impl_.epsilon_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // bool use_non_lazy_adam = 8;
      case 8:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 64)) {
          _impl_.use_non_lazy_adam_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // bool use_sum_inside_sqrt = 10;
      case 10:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 80)) {
          _impl_.use_sum_inside_sqrt_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* AdamParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.AdamParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float beta1 = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta1 = this->_internal_beta1();
  uint32_t raw_beta1;
  memcpy(&raw_beta1, &tmp_beta1, sizeof(tmp_beta1));
  if (raw_beta1 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(3, this->_internal_beta1(), target);
  }

  // float beta2 = 4;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = this->_internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(4, this->_internal_beta2(), target);
  }

  // float epsilon = 5;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = this->_internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(5, this->_internal_epsilon(), target);
  }

  // bool use_non_lazy_adam = 8;
  if (this->_internal_use_non_lazy_adam() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(8, this->_internal_use_non_lazy_adam(), target);
  }

  // bool use_sum_inside_sqrt = 10;
  if (this->_internal_use_sum_inside_sqrt() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(10, this->_internal_use_sum_inside_sqrt(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.AdamParameters)
  return target;
}

size_t AdamParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.AdamParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float beta1 = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta1 = this->_internal_beta1();
  uint32_t raw_beta1;
  memcpy(&raw_beta1, &tmp_beta1, sizeof(tmp_beta1));
  if (raw_beta1 != 0) {
    total_size += 1 + 4;
  }

  // float beta2 = 4;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = this->_internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    total_size += 1 + 4;
  }

  // float epsilon = 5;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = this->_internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    total_size += 1 + 4;
  }

  // bool use_non_lazy_adam = 8;
  if (this->_internal_use_non_lazy_adam() != 0) {
    total_size += 1 + 1;
  }

  // bool use_sum_inside_sqrt = 10;
  if (this->_internal_use_sum_inside_sqrt() != 0) {
    total_size += 1 + 1;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData AdamParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    AdamParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*AdamParameters::GetClassData() const { return &_class_data_; }


void AdamParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<AdamParameters*>(&to_msg);
  auto& from = static_cast<const AdamParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.AdamParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta1 = from._internal_beta1();
  uint32_t raw_beta1;
  memcpy(&raw_beta1, &tmp_beta1, sizeof(tmp_beta1));
  if (raw_beta1 != 0) {
    _this->_internal_set_beta1(from._internal_beta1());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = from._internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    _this->_internal_set_beta2(from._internal_beta2());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = from._internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    _this->_internal_set_epsilon(from._internal_epsilon());
  }
  if (from._internal_use_non_lazy_adam() != 0) {
    _this->_internal_set_use_non_lazy_adam(from._internal_use_non_lazy_adam());
  }
  if (from._internal_use_sum_inside_sqrt() != 0) {
    _this->_internal_set_use_sum_inside_sqrt(from._internal_use_sum_inside_sqrt());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void AdamParameters::CopyFrom(const AdamParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.AdamParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool AdamParameters::IsInitialized() const {
  return true;
}

void AdamParameters::InternalSwap(AdamParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(AdamParameters, _impl_.use_sum_inside_sqrt_)
      + sizeof(AdamParameters::_impl_.use_sum_inside_sqrt_)
      - PROTOBUF_FIELD_OFFSET(AdamParameters, _impl_.beta1_)>(
          reinterpret_cast<char*>(&_impl_.beta1_),
          reinterpret_cast<char*>(&other->_impl_.beta1_));
}

::PROTOBUF_NAMESPACE_ID::Metadata AdamParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[9]);
}

// ===================================================================

class MomentumParameters::_Internal {
 public:
};

MomentumParameters::MomentumParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.MomentumParameters)
}
MomentumParameters::MomentumParameters(const MomentumParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  MomentumParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.momentum_){}
    , decltype(_impl_.use_nesterov_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.momentum_, &from._impl_.momentum_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.use_nesterov_) -
    reinterpret_cast<char*>(&_impl_.momentum_)) + sizeof(_impl_.use_nesterov_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.MomentumParameters)
}

inline void MomentumParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.momentum_){0}
    , decltype(_impl_.use_nesterov_){false}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

MomentumParameters::~MomentumParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.MomentumParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void MomentumParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void MomentumParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void MomentumParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.MomentumParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.momentum_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.use_nesterov_) -
      reinterpret_cast<char*>(&_impl_.momentum_)) + sizeof(_impl_.use_nesterov_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* MomentumParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float momentum = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _impl_.momentum_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // bool use_nesterov = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.use_nesterov_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* MomentumParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.MomentumParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float momentum = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_momentum = this->_internal_momentum();
  uint32_t raw_momentum;
  memcpy(&raw_momentum, &tmp_momentum, sizeof(tmp_momentum));
  if (raw_momentum != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_momentum(), target);
  }

  // bool use_nesterov = 2;
  if (this->_internal_use_nesterov() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(2, this->_internal_use_nesterov(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.MomentumParameters)
  return target;
}

size_t MomentumParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.MomentumParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float momentum = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_momentum = this->_internal_momentum();
  uint32_t raw_momentum;
  memcpy(&raw_momentum, &tmp_momentum, sizeof(tmp_momentum));
  if (raw_momentum != 0) {
    total_size += 1 + 4;
  }

  // bool use_nesterov = 2;
  if (this->_internal_use_nesterov() != 0) {
    total_size += 1 + 1;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData MomentumParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    MomentumParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*MomentumParameters::GetClassData() const { return &_class_data_; }


void MomentumParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<MomentumParameters*>(&to_msg);
  auto& from = static_cast<const MomentumParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.MomentumParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_momentum = from._internal_momentum();
  uint32_t raw_momentum;
  memcpy(&raw_momentum, &tmp_momentum, sizeof(tmp_momentum));
  if (raw_momentum != 0) {
    _this->_internal_set_momentum(from._internal_momentum());
  }
  if (from._internal_use_nesterov() != 0) {
    _this->_internal_set_use_nesterov(from._internal_use_nesterov());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void MomentumParameters::CopyFrom(const MomentumParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.MomentumParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool MomentumParameters::IsInitialized() const {
  return true;
}

void MomentumParameters::InternalSwap(MomentumParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(MomentumParameters, _impl_.use_nesterov_)
      + sizeof(MomentumParameters::_impl_.use_nesterov_)
      - PROTOBUF_FIELD_OFFSET(MomentumParameters, _impl_.momentum_)>(
          reinterpret_cast<char*>(&_impl_.momentum_),
          reinterpret_cast<char*>(&other->_impl_.momentum_));
}

::PROTOBUF_NAMESPACE_ID::Metadata MomentumParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[10]);
}

// ===================================================================

class LionParameters::_Internal {
 public:
};

LionParameters::LionParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.LionParameters)
}
LionParameters::LionParameters(const LionParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  LionParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.beta1_){}
    , decltype(_impl_.beta2_){}
    , decltype(_impl_.use_non_lazy_lion_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.beta1_, &from._impl_.beta1_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.use_non_lazy_lion_) -
    reinterpret_cast<char*>(&_impl_.beta1_)) + sizeof(_impl_.use_non_lazy_lion_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.LionParameters)
}

inline void LionParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.beta1_){0}
    , decltype(_impl_.beta2_){0}
    , decltype(_impl_.use_non_lazy_lion_){false}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

LionParameters::~LionParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.LionParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void LionParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void LionParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void LionParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.LionParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.beta1_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.use_non_lazy_lion_) -
      reinterpret_cast<char*>(&_impl_.beta1_)) + sizeof(_impl_.use_non_lazy_lion_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* LionParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float beta1 = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _impl_.beta1_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float beta2 = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 21)) {
          _impl_.beta2_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // bool use_non_lazy_lion = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _impl_.use_non_lazy_lion_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* LionParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.LionParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float beta1 = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta1 = this->_internal_beta1();
  uint32_t raw_beta1;
  memcpy(&raw_beta1, &tmp_beta1, sizeof(tmp_beta1));
  if (raw_beta1 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_beta1(), target);
  }

  // float beta2 = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = this->_internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(2, this->_internal_beta2(), target);
  }

  // bool use_non_lazy_lion = 3;
  if (this->_internal_use_non_lazy_lion() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(3, this->_internal_use_non_lazy_lion(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.LionParameters)
  return target;
}

size_t LionParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.LionParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float beta1 = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta1 = this->_internal_beta1();
  uint32_t raw_beta1;
  memcpy(&raw_beta1, &tmp_beta1, sizeof(tmp_beta1));
  if (raw_beta1 != 0) {
    total_size += 1 + 4;
  }

  // float beta2 = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = this->_internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    total_size += 1 + 4;
  }

  // bool use_non_lazy_lion = 3;
  if (this->_internal_use_non_lazy_lion() != 0) {
    total_size += 1 + 1;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData LionParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    LionParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*LionParameters::GetClassData() const { return &_class_data_; }


void LionParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<LionParameters*>(&to_msg);
  auto& from = static_cast<const LionParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.LionParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta1 = from._internal_beta1();
  uint32_t raw_beta1;
  memcpy(&raw_beta1, &tmp_beta1, sizeof(tmp_beta1));
  if (raw_beta1 != 0) {
    _this->_internal_set_beta1(from._internal_beta1());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = from._internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    _this->_internal_set_beta2(from._internal_beta2());
  }
  if (from._internal_use_non_lazy_lion() != 0) {
    _this->_internal_set_use_non_lazy_lion(from._internal_use_non_lazy_lion());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void LionParameters::CopyFrom(const LionParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.LionParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool LionParameters::IsInitialized() const {
  return true;
}

void LionParameters::InternalSwap(LionParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(LionParameters, _impl_.use_non_lazy_lion_)
      + sizeof(LionParameters::_impl_.use_non_lazy_lion_)
      - PROTOBUF_FIELD_OFFSET(LionParameters, _impl_.beta1_)>(
          reinterpret_cast<char*>(&_impl_.beta1_),
          reinterpret_cast<char*>(&other->_impl_.beta1_));
}

::PROTOBUF_NAMESPACE_ID::Metadata LionParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[11]);
}

// ===================================================================

class RmsPropParameters::_Internal {
 public:
};

RmsPropParameters::RmsPropParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.RmsPropParameters)
}
RmsPropParameters::RmsPropParameters(const RmsPropParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  RmsPropParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.rho_){}
    , decltype(_impl_.momentum_){}
    , decltype(_impl_.epsilon_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.rho_, &from._impl_.rho_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.epsilon_) -
    reinterpret_cast<char*>(&_impl_.rho_)) + sizeof(_impl_.epsilon_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.RmsPropParameters)
}

inline void RmsPropParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.rho_){0}
    , decltype(_impl_.momentum_){0}
    , decltype(_impl_.epsilon_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

RmsPropParameters::~RmsPropParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.RmsPropParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void RmsPropParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void RmsPropParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void RmsPropParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.RmsPropParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.rho_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.epsilon_) -
      reinterpret_cast<char*>(&_impl_.rho_)) + sizeof(_impl_.epsilon_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* RmsPropParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float rho = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _impl_.rho_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float momentum = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 21)) {
          _impl_.momentum_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float epsilon = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 29)) {
          _impl_.epsilon_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* RmsPropParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.RmsPropParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float rho = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_rho = this->_internal_rho();
  uint32_t raw_rho;
  memcpy(&raw_rho, &tmp_rho, sizeof(tmp_rho));
  if (raw_rho != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_rho(), target);
  }

  // float momentum = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_momentum = this->_internal_momentum();
  uint32_t raw_momentum;
  memcpy(&raw_momentum, &tmp_momentum, sizeof(tmp_momentum));
  if (raw_momentum != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(2, this->_internal_momentum(), target);
  }

  // float epsilon = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = this->_internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(3, this->_internal_epsilon(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.RmsPropParameters)
  return target;
}

size_t RmsPropParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.RmsPropParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float rho = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_rho = this->_internal_rho();
  uint32_t raw_rho;
  memcpy(&raw_rho, &tmp_rho, sizeof(tmp_rho));
  if (raw_rho != 0) {
    total_size += 1 + 4;
  }

  // float momentum = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_momentum = this->_internal_momentum();
  uint32_t raw_momentum;
  memcpy(&raw_momentum, &tmp_momentum, sizeof(tmp_momentum));
  if (raw_momentum != 0) {
    total_size += 1 + 4;
  }

  // float epsilon = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = this->_internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    total_size += 1 + 4;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData RmsPropParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    RmsPropParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*RmsPropParameters::GetClassData() const { return &_class_data_; }


void RmsPropParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<RmsPropParameters*>(&to_msg);
  auto& from = static_cast<const RmsPropParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.RmsPropParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_rho = from._internal_rho();
  uint32_t raw_rho;
  memcpy(&raw_rho, &tmp_rho, sizeof(tmp_rho));
  if (raw_rho != 0) {
    _this->_internal_set_rho(from._internal_rho());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_momentum = from._internal_momentum();
  uint32_t raw_momentum;
  memcpy(&raw_momentum, &tmp_momentum, sizeof(tmp_momentum));
  if (raw_momentum != 0) {
    _this->_internal_set_momentum(from._internal_momentum());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = from._internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    _this->_internal_set_epsilon(from._internal_epsilon());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void RmsPropParameters::CopyFrom(const RmsPropParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.RmsPropParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RmsPropParameters::IsInitialized() const {
  return true;
}

void RmsPropParameters::InternalSwap(RmsPropParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RmsPropParameters, _impl_.epsilon_)
      + sizeof(RmsPropParameters::_impl_.epsilon_)
      - PROTOBUF_FIELD_OFFSET(RmsPropParameters, _impl_.rho_)>(
          reinterpret_cast<char*>(&_impl_.rho_),
          reinterpret_cast<char*>(&other->_impl_.rho_));
}

::PROTOBUF_NAMESPACE_ID::Metadata RmsPropParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[12]);
}

// ===================================================================

class CenteredRmsPropParameters::_Internal {
 public:
};

CenteredRmsPropParameters::CenteredRmsPropParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.CenteredRmsPropParameters)
}
CenteredRmsPropParameters::CenteredRmsPropParameters(const CenteredRmsPropParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  CenteredRmsPropParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.rho_){}
    , decltype(_impl_.momentum_){}
    , decltype(_impl_.epsilon_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.rho_, &from._impl_.rho_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.epsilon_) -
    reinterpret_cast<char*>(&_impl_.rho_)) + sizeof(_impl_.epsilon_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.CenteredRmsPropParameters)
}

inline void CenteredRmsPropParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.rho_){0}
    , decltype(_impl_.momentum_){0}
    , decltype(_impl_.epsilon_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

CenteredRmsPropParameters::~CenteredRmsPropParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.CenteredRmsPropParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void CenteredRmsPropParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void CenteredRmsPropParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void CenteredRmsPropParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.CenteredRmsPropParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.rho_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.epsilon_) -
      reinterpret_cast<char*>(&_impl_.rho_)) + sizeof(_impl_.epsilon_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* CenteredRmsPropParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float rho = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _impl_.rho_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float momentum = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 21)) {
          _impl_.momentum_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float epsilon = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 29)) {
          _impl_.epsilon_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* CenteredRmsPropParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.CenteredRmsPropParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float rho = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_rho = this->_internal_rho();
  uint32_t raw_rho;
  memcpy(&raw_rho, &tmp_rho, sizeof(tmp_rho));
  if (raw_rho != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_rho(), target);
  }

  // float momentum = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_momentum = this->_internal_momentum();
  uint32_t raw_momentum;
  memcpy(&raw_momentum, &tmp_momentum, sizeof(tmp_momentum));
  if (raw_momentum != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(2, this->_internal_momentum(), target);
  }

  // float epsilon = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = this->_internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(3, this->_internal_epsilon(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.CenteredRmsPropParameters)
  return target;
}

size_t CenteredRmsPropParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.CenteredRmsPropParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float rho = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_rho = this->_internal_rho();
  uint32_t raw_rho;
  memcpy(&raw_rho, &tmp_rho, sizeof(tmp_rho));
  if (raw_rho != 0) {
    total_size += 1 + 4;
  }

  // float momentum = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_momentum = this->_internal_momentum();
  uint32_t raw_momentum;
  memcpy(&raw_momentum, &tmp_momentum, sizeof(tmp_momentum));
  if (raw_momentum != 0) {
    total_size += 1 + 4;
  }

  // float epsilon = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = this->_internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    total_size += 1 + 4;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData CenteredRmsPropParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    CenteredRmsPropParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*CenteredRmsPropParameters::GetClassData() const { return &_class_data_; }


void CenteredRmsPropParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<CenteredRmsPropParameters*>(&to_msg);
  auto& from = static_cast<const CenteredRmsPropParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.CenteredRmsPropParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_rho = from._internal_rho();
  uint32_t raw_rho;
  memcpy(&raw_rho, &tmp_rho, sizeof(tmp_rho));
  if (raw_rho != 0) {
    _this->_internal_set_rho(from._internal_rho());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_momentum = from._internal_momentum();
  uint32_t raw_momentum;
  memcpy(&raw_momentum, &tmp_momentum, sizeof(tmp_momentum));
  if (raw_momentum != 0) {
    _this->_internal_set_momentum(from._internal_momentum());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = from._internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    _this->_internal_set_epsilon(from._internal_epsilon());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void CenteredRmsPropParameters::CopyFrom(const CenteredRmsPropParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.CenteredRmsPropParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CenteredRmsPropParameters::IsInitialized() const {
  return true;
}

void CenteredRmsPropParameters::InternalSwap(CenteredRmsPropParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(CenteredRmsPropParameters, _impl_.epsilon_)
      + sizeof(CenteredRmsPropParameters::_impl_.epsilon_)
      - PROTOBUF_FIELD_OFFSET(CenteredRmsPropParameters, _impl_.rho_)>(
          reinterpret_cast<char*>(&_impl_.rho_),
          reinterpret_cast<char*>(&other->_impl_.rho_));
}

::PROTOBUF_NAMESPACE_ID::Metadata CenteredRmsPropParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[13]);
}

// ===================================================================

class MdlAdagradLightParameters::_Internal {
 public:
};

MdlAdagradLightParameters::MdlAdagradLightParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.MdlAdagradLightParameters)
}
MdlAdagradLightParameters::MdlAdagradLightParameters(const MdlAdagradLightParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  MdlAdagradLightParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.l2_){}
    , decltype(_impl_.lr_power_){}
    , decltype(_impl_.min_servable_mdl_benefit_){}
    , decltype(_impl_.mdl_mix_in_margin_){}
    , decltype(_impl_.mdl_benefit_rampup_coeff_){}
    , decltype(_impl_.mdl_min_weight_){}
    , decltype(_impl_.benefit_revisit_scale_){}
    , decltype(_impl_.max_event_benefit_){}
    , decltype(_impl_.max_total_benefit_){}
    , decltype(_impl_.mdl_hard_limit_){}
    , decltype(_impl_.hard_limit_min_benefit_){}
    , decltype(_impl_.mdl_regularize_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.l2_, &from._impl_.l2_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.mdl_regularize_) -
    reinterpret_cast<char*>(&_impl_.l2_)) + sizeof(_impl_.mdl_regularize_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.MdlAdagradLightParameters)
}

inline void MdlAdagradLightParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.l2_){0}
    , decltype(_impl_.lr_power_){0}
    , decltype(_impl_.min_servable_mdl_benefit_){0}
    , decltype(_impl_.mdl_mix_in_margin_){0}
    , decltype(_impl_.mdl_benefit_rampup_coeff_){0}
    , decltype(_impl_.mdl_min_weight_){0}
    , decltype(_impl_.benefit_revisit_scale_){0}
    , decltype(_impl_.max_event_benefit_){0}
    , decltype(_impl_.max_total_benefit_){0}
    , decltype(_impl_.mdl_hard_limit_){0}
    , decltype(_impl_.hard_limit_min_benefit_){false}
    , decltype(_impl_.mdl_regularize_){false}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

MdlAdagradLightParameters::~MdlAdagradLightParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.MdlAdagradLightParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void MdlAdagradLightParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void MdlAdagradLightParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void MdlAdagradLightParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.MdlAdagradLightParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.l2_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.mdl_regularize_) -
      reinterpret_cast<char*>(&_impl_.l2_)) + sizeof(_impl_.mdl_regularize_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* MdlAdagradLightParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float l2 = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _impl_.l2_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float lr_power = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 21)) {
          _impl_.lr_power_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float min_servable_mdl_benefit = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 29)) {
          _impl_.min_servable_mdl_benefit_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float mdl_mix_in_margin = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 37)) {
          _impl_.mdl_mix_in_margin_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float mdl_benefit_rampup_coeff = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 45)) {
          _impl_.mdl_benefit_rampup_coeff_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float mdl_min_weight = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 53)) {
          _impl_.mdl_min_weight_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float benefit_revisit_scale = 7;
      case 7:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 61)) {
          _impl_.benefit_revisit_scale_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float max_event_benefit = 8;
      case 8:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 69)) {
          _impl_.max_event_benefit_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float max_total_benefit = 9;
      case 9:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 77)) {
          _impl_.max_total_benefit_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float mdl_hard_limit = 10;
      case 10:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 85)) {
          _impl_.mdl_hard_limit_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // bool hard_limit_min_benefit = 11;
      case 11:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 88)) {
          _impl_.hard_limit_min_benefit_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // bool mdl_regularize = 12;
      case 12:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 96)) {
          _impl_.mdl_regularize_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* MdlAdagradLightParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.MdlAdagradLightParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float l2 = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = this->_internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_l2(), target);
  }

  // float lr_power = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_lr_power = this->_internal_lr_power();
  uint32_t raw_lr_power;
  memcpy(&raw_lr_power, &tmp_lr_power, sizeof(tmp_lr_power));
  if (raw_lr_power != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(2, this->_internal_lr_power(), target);
  }

  // float min_servable_mdl_benefit = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_min_servable_mdl_benefit = this->_internal_min_servable_mdl_benefit();
  uint32_t raw_min_servable_mdl_benefit;
  memcpy(&raw_min_servable_mdl_benefit, &tmp_min_servable_mdl_benefit, sizeof(tmp_min_servable_mdl_benefit));
  if (raw_min_servable_mdl_benefit != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(3, this->_internal_min_servable_mdl_benefit(), target);
  }

  // float mdl_mix_in_margin = 4;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_mdl_mix_in_margin = this->_internal_mdl_mix_in_margin();
  uint32_t raw_mdl_mix_in_margin;
  memcpy(&raw_mdl_mix_in_margin, &tmp_mdl_mix_in_margin, sizeof(tmp_mdl_mix_in_margin));
  if (raw_mdl_mix_in_margin != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(4, this->_internal_mdl_mix_in_margin(), target);
  }

  // float mdl_benefit_rampup_coeff = 5;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_mdl_benefit_rampup_coeff = this->_internal_mdl_benefit_rampup_coeff();
  uint32_t raw_mdl_benefit_rampup_coeff;
  memcpy(&raw_mdl_benefit_rampup_coeff, &tmp_mdl_benefit_rampup_coeff, sizeof(tmp_mdl_benefit_rampup_coeff));
  if (raw_mdl_benefit_rampup_coeff != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(5, this->_internal_mdl_benefit_rampup_coeff(), target);
  }

  // float mdl_min_weight = 6;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_mdl_min_weight = this->_internal_mdl_min_weight();
  uint32_t raw_mdl_min_weight;
  memcpy(&raw_mdl_min_weight, &tmp_mdl_min_weight, sizeof(tmp_mdl_min_weight));
  if (raw_mdl_min_weight != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(6, this->_internal_mdl_min_weight(), target);
  }

  // float benefit_revisit_scale = 7;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_benefit_revisit_scale = this->_internal_benefit_revisit_scale();
  uint32_t raw_benefit_revisit_scale;
  memcpy(&raw_benefit_revisit_scale, &tmp_benefit_revisit_scale, sizeof(tmp_benefit_revisit_scale));
  if (raw_benefit_revisit_scale != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(7, this->_internal_benefit_revisit_scale(), target);
  }

  // float max_event_benefit = 8;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_event_benefit = this->_internal_max_event_benefit();
  uint32_t raw_max_event_benefit;
  memcpy(&raw_max_event_benefit, &tmp_max_event_benefit, sizeof(tmp_max_event_benefit));
  if (raw_max_event_benefit != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(8, this->_internal_max_event_benefit(), target);
  }

  // float max_total_benefit = 9;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_total_benefit = this->_internal_max_total_benefit();
  uint32_t raw_max_total_benefit;
  memcpy(&raw_max_total_benefit, &tmp_max_total_benefit, sizeof(tmp_max_total_benefit));
  if (raw_max_total_benefit != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(9, this->_internal_max_total_benefit(), target);
  }

  // float mdl_hard_limit = 10;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_mdl_hard_limit = this->_internal_mdl_hard_limit();
  uint32_t raw_mdl_hard_limit;
  memcpy(&raw_mdl_hard_limit, &tmp_mdl_hard_limit, sizeof(tmp_mdl_hard_limit));
  if (raw_mdl_hard_limit != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(10, this->_internal_mdl_hard_limit(), target);
  }

  // bool hard_limit_min_benefit = 11;
  if (this->_internal_hard_limit_min_benefit() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(11, this->_internal_hard_limit_min_benefit(), target);
  }

  // bool mdl_regularize = 12;
  if (this->_internal_mdl_regularize() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(12, this->_internal_mdl_regularize(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.MdlAdagradLightParameters)
  return target;
}

size_t MdlAdagradLightParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.MdlAdagradLightParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float l2 = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = this->_internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    total_size += 1 + 4;
  }

  // float lr_power = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_lr_power = this->_internal_lr_power();
  uint32_t raw_lr_power;
  memcpy(&raw_lr_power, &tmp_lr_power, sizeof(tmp_lr_power));
  if (raw_lr_power != 0) {
    total_size += 1 + 4;
  }

  // float min_servable_mdl_benefit = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_min_servable_mdl_benefit = this->_internal_min_servable_mdl_benefit();
  uint32_t raw_min_servable_mdl_benefit;
  memcpy(&raw_min_servable_mdl_benefit, &tmp_min_servable_mdl_benefit, sizeof(tmp_min_servable_mdl_benefit));
  if (raw_min_servable_mdl_benefit != 0) {
    total_size += 1 + 4;
  }

  // float mdl_mix_in_margin = 4;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_mdl_mix_in_margin = this->_internal_mdl_mix_in_margin();
  uint32_t raw_mdl_mix_in_margin;
  memcpy(&raw_mdl_mix_in_margin, &tmp_mdl_mix_in_margin, sizeof(tmp_mdl_mix_in_margin));
  if (raw_mdl_mix_in_margin != 0) {
    total_size += 1 + 4;
  }

  // float mdl_benefit_rampup_coeff = 5;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_mdl_benefit_rampup_coeff = this->_internal_mdl_benefit_rampup_coeff();
  uint32_t raw_mdl_benefit_rampup_coeff;
  memcpy(&raw_mdl_benefit_rampup_coeff, &tmp_mdl_benefit_rampup_coeff, sizeof(tmp_mdl_benefit_rampup_coeff));
  if (raw_mdl_benefit_rampup_coeff != 0) {
    total_size += 1 + 4;
  }

  // float mdl_min_weight = 6;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_mdl_min_weight = this->_internal_mdl_min_weight();
  uint32_t raw_mdl_min_weight;
  memcpy(&raw_mdl_min_weight, &tmp_mdl_min_weight, sizeof(tmp_mdl_min_weight));
  if (raw_mdl_min_weight != 0) {
    total_size += 1 + 4;
  }

  // float benefit_revisit_scale = 7;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_benefit_revisit_scale = this->_internal_benefit_revisit_scale();
  uint32_t raw_benefit_revisit_scale;
  memcpy(&raw_benefit_revisit_scale, &tmp_benefit_revisit_scale, sizeof(tmp_benefit_revisit_scale));
  if (raw_benefit_revisit_scale != 0) {
    total_size += 1 + 4;
  }

  // float max_event_benefit = 8;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_event_benefit = this->_internal_max_event_benefit();
  uint32_t raw_max_event_benefit;
  memcpy(&raw_max_event_benefit, &tmp_max_event_benefit, sizeof(tmp_max_event_benefit));
  if (raw_max_event_benefit != 0) {
    total_size += 1 + 4;
  }

  // float max_total_benefit = 9;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_total_benefit = this->_internal_max_total_benefit();
  uint32_t raw_max_total_benefit;
  memcpy(&raw_max_total_benefit, &tmp_max_total_benefit, sizeof(tmp_max_total_benefit));
  if (raw_max_total_benefit != 0) {
    total_size += 1 + 4;
  }

  // float mdl_hard_limit = 10;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_mdl_hard_limit = this->_internal_mdl_hard_limit();
  uint32_t raw_mdl_hard_limit;
  memcpy(&raw_mdl_hard_limit, &tmp_mdl_hard_limit, sizeof(tmp_mdl_hard_limit));
  if (raw_mdl_hard_limit != 0) {
    total_size += 1 + 4;
  }

  // bool hard_limit_min_benefit = 11;
  if (this->_internal_hard_limit_min_benefit() != 0) {
    total_size += 1 + 1;
  }

  // bool mdl_regularize = 12;
  if (this->_internal_mdl_regularize() != 0) {
    total_size += 1 + 1;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData MdlAdagradLightParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    MdlAdagradLightParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*MdlAdagradLightParameters::GetClassData() const { return &_class_data_; }


void MdlAdagradLightParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<MdlAdagradLightParameters*>(&to_msg);
  auto& from = static_cast<const MdlAdagradLightParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.MdlAdagradLightParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = from._internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    _this->_internal_set_l2(from._internal_l2());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_lr_power = from._internal_lr_power();
  uint32_t raw_lr_power;
  memcpy(&raw_lr_power, &tmp_lr_power, sizeof(tmp_lr_power));
  if (raw_lr_power != 0) {
    _this->_internal_set_lr_power(from._internal_lr_power());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_min_servable_mdl_benefit = from._internal_min_servable_mdl_benefit();
  uint32_t raw_min_servable_mdl_benefit;
  memcpy(&raw_min_servable_mdl_benefit, &tmp_min_servable_mdl_benefit, sizeof(tmp_min_servable_mdl_benefit));
  if (raw_min_servable_mdl_benefit != 0) {
    _this->_internal_set_min_servable_mdl_benefit(from._internal_min_servable_mdl_benefit());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_mdl_mix_in_margin = from._internal_mdl_mix_in_margin();
  uint32_t raw_mdl_mix_in_margin;
  memcpy(&raw_mdl_mix_in_margin, &tmp_mdl_mix_in_margin, sizeof(tmp_mdl_mix_in_margin));
  if (raw_mdl_mix_in_margin != 0) {
    _this->_internal_set_mdl_mix_in_margin(from._internal_mdl_mix_in_margin());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_mdl_benefit_rampup_coeff = from._internal_mdl_benefit_rampup_coeff();
  uint32_t raw_mdl_benefit_rampup_coeff;
  memcpy(&raw_mdl_benefit_rampup_coeff, &tmp_mdl_benefit_rampup_coeff, sizeof(tmp_mdl_benefit_rampup_coeff));
  if (raw_mdl_benefit_rampup_coeff != 0) {
    _this->_internal_set_mdl_benefit_rampup_coeff(from._internal_mdl_benefit_rampup_coeff());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_mdl_min_weight = from._internal_mdl_min_weight();
  uint32_t raw_mdl_min_weight;
  memcpy(&raw_mdl_min_weight, &tmp_mdl_min_weight, sizeof(tmp_mdl_min_weight));
  if (raw_mdl_min_weight != 0) {
    _this->_internal_set_mdl_min_weight(from._internal_mdl_min_weight());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_benefit_revisit_scale = from._internal_benefit_revisit_scale();
  uint32_t raw_benefit_revisit_scale;
  memcpy(&raw_benefit_revisit_scale, &tmp_benefit_revisit_scale, sizeof(tmp_benefit_revisit_scale));
  if (raw_benefit_revisit_scale != 0) {
    _this->_internal_set_benefit_revisit_scale(from._internal_benefit_revisit_scale());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_event_benefit = from._internal_max_event_benefit();
  uint32_t raw_max_event_benefit;
  memcpy(&raw_max_event_benefit, &tmp_max_event_benefit, sizeof(tmp_max_event_benefit));
  if (raw_max_event_benefit != 0) {
    _this->_internal_set_max_event_benefit(from._internal_max_event_benefit());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_total_benefit = from._internal_max_total_benefit();
  uint32_t raw_max_total_benefit;
  memcpy(&raw_max_total_benefit, &tmp_max_total_benefit, sizeof(tmp_max_total_benefit));
  if (raw_max_total_benefit != 0) {
    _this->_internal_set_max_total_benefit(from._internal_max_total_benefit());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_mdl_hard_limit = from._internal_mdl_hard_limit();
  uint32_t raw_mdl_hard_limit;
  memcpy(&raw_mdl_hard_limit, &tmp_mdl_hard_limit, sizeof(tmp_mdl_hard_limit));
  if (raw_mdl_hard_limit != 0) {
    _this->_internal_set_mdl_hard_limit(from._internal_mdl_hard_limit());
  }
  if (from._internal_hard_limit_min_benefit() != 0) {
    _this->_internal_set_hard_limit_min_benefit(from._internal_hard_limit_min_benefit());
  }
  if (from._internal_mdl_regularize() != 0) {
    _this->_internal_set_mdl_regularize(from._internal_mdl_regularize());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void MdlAdagradLightParameters::CopyFrom(const MdlAdagradLightParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.MdlAdagradLightParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool MdlAdagradLightParameters::IsInitialized() const {
  return true;
}

void MdlAdagradLightParameters::InternalSwap(MdlAdagradLightParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(MdlAdagradLightParameters, _impl_.mdl_regularize_)
      + sizeof(MdlAdagradLightParameters::_impl_.mdl_regularize_)
      - PROTOBUF_FIELD_OFFSET(MdlAdagradLightParameters, _impl_.l2_)>(
          reinterpret_cast<char*>(&_impl_.l2_),
          reinterpret_cast<char*>(&other->_impl_.l2_));
}

::PROTOBUF_NAMESPACE_ID::Metadata MdlAdagradLightParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[14]);
}

// ===================================================================

class AdadeltaParameters::_Internal {
 public:
};

AdadeltaParameters::AdadeltaParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.AdadeltaParameters)
}
AdadeltaParameters::AdadeltaParameters(const AdadeltaParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  AdadeltaParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.rho_){}
    , decltype(_impl_.epsilon_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.rho_, &from._impl_.rho_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.epsilon_) -
    reinterpret_cast<char*>(&_impl_.rho_)) + sizeof(_impl_.epsilon_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.AdadeltaParameters)
}

inline void AdadeltaParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.rho_){0}
    , decltype(_impl_.epsilon_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

AdadeltaParameters::~AdadeltaParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.AdadeltaParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void AdadeltaParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void AdadeltaParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void AdadeltaParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.AdadeltaParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.rho_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.epsilon_) -
      reinterpret_cast<char*>(&_impl_.rho_)) + sizeof(_impl_.epsilon_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* AdadeltaParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float rho = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _impl_.rho_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float epsilon = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 21)) {
          _impl_.epsilon_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* AdadeltaParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.AdadeltaParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float rho = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_rho = this->_internal_rho();
  uint32_t raw_rho;
  memcpy(&raw_rho, &tmp_rho, sizeof(tmp_rho));
  if (raw_rho != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_rho(), target);
  }

  // float epsilon = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = this->_internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(2, this->_internal_epsilon(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.AdadeltaParameters)
  return target;
}

size_t AdadeltaParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.AdadeltaParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float rho = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_rho = this->_internal_rho();
  uint32_t raw_rho;
  memcpy(&raw_rho, &tmp_rho, sizeof(tmp_rho));
  if (raw_rho != 0) {
    total_size += 1 + 4;
  }

  // float epsilon = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = this->_internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    total_size += 1 + 4;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData AdadeltaParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    AdadeltaParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*AdadeltaParameters::GetClassData() const { return &_class_data_; }


void AdadeltaParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<AdadeltaParameters*>(&to_msg);
  auto& from = static_cast<const AdadeltaParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.AdadeltaParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_rho = from._internal_rho();
  uint32_t raw_rho;
  memcpy(&raw_rho, &tmp_rho, sizeof(tmp_rho));
  if (raw_rho != 0) {
    _this->_internal_set_rho(from._internal_rho());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = from._internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    _this->_internal_set_epsilon(from._internal_epsilon());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void AdadeltaParameters::CopyFrom(const AdadeltaParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.AdadeltaParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool AdadeltaParameters::IsInitialized() const {
  return true;
}

void AdadeltaParameters::InternalSwap(AdadeltaParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(AdadeltaParameters, _impl_.epsilon_)
      + sizeof(AdadeltaParameters::_impl_.epsilon_)
      - PROTOBUF_FIELD_OFFSET(AdadeltaParameters, _impl_.rho_)>(
          reinterpret_cast<char*>(&_impl_.rho_),
          reinterpret_cast<char*>(&other->_impl_.rho_));
}

::PROTOBUF_NAMESPACE_ID::Metadata AdadeltaParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[15]);
}

// ===================================================================

class ProximalAdagradParameters::_Internal {
 public:
};

ProximalAdagradParameters::ProximalAdagradParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.ProximalAdagradParameters)
}
ProximalAdagradParameters::ProximalAdagradParameters(const ProximalAdagradParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  ProximalAdagradParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.l1_){}
    , decltype(_impl_.l2_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.l1_, &from._impl_.l1_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.l2_) -
    reinterpret_cast<char*>(&_impl_.l1_)) + sizeof(_impl_.l2_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.ProximalAdagradParameters)
}

inline void ProximalAdagradParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.l1_){0}
    , decltype(_impl_.l2_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

ProximalAdagradParameters::~ProximalAdagradParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.ProximalAdagradParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void ProximalAdagradParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void ProximalAdagradParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void ProximalAdagradParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.ProximalAdagradParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.l1_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.l2_) -
      reinterpret_cast<char*>(&_impl_.l1_)) + sizeof(_impl_.l2_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ProximalAdagradParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float l1 = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _impl_.l1_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float l2 = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 21)) {
          _impl_.l2_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ProximalAdagradParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.ProximalAdagradParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float l1 = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l1 = this->_internal_l1();
  uint32_t raw_l1;
  memcpy(&raw_l1, &tmp_l1, sizeof(tmp_l1));
  if (raw_l1 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_l1(), target);
  }

  // float l2 = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = this->_internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(2, this->_internal_l2(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.ProximalAdagradParameters)
  return target;
}

size_t ProximalAdagradParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.ProximalAdagradParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float l1 = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l1 = this->_internal_l1();
  uint32_t raw_l1;
  memcpy(&raw_l1, &tmp_l1, sizeof(tmp_l1));
  if (raw_l1 != 0) {
    total_size += 1 + 4;
  }

  // float l2 = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = this->_internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    total_size += 1 + 4;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ProximalAdagradParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    ProximalAdagradParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ProximalAdagradParameters::GetClassData() const { return &_class_data_; }


void ProximalAdagradParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<ProximalAdagradParameters*>(&to_msg);
  auto& from = static_cast<const ProximalAdagradParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.ProximalAdagradParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l1 = from._internal_l1();
  uint32_t raw_l1;
  memcpy(&raw_l1, &tmp_l1, sizeof(tmp_l1));
  if (raw_l1 != 0) {
    _this->_internal_set_l1(from._internal_l1());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = from._internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    _this->_internal_set_l2(from._internal_l2());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ProximalAdagradParameters::CopyFrom(const ProximalAdagradParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.ProximalAdagradParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ProximalAdagradParameters::IsInitialized() const {
  return true;
}

void ProximalAdagradParameters::InternalSwap(ProximalAdagradParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(ProximalAdagradParameters, _impl_.l2_)
      + sizeof(ProximalAdagradParameters::_impl_.l2_)
      - PROTOBUF_FIELD_OFFSET(ProximalAdagradParameters, _impl_.l1_)>(
          reinterpret_cast<char*>(&_impl_.l1_),
          reinterpret_cast<char*>(&other->_impl_.l1_));
}

::PROTOBUF_NAMESPACE_ID::Metadata ProximalAdagradParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[16]);
}

// ===================================================================

class OnlineYogiParameters::_Internal {
 public:
};

OnlineYogiParameters::OnlineYogiParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.OnlineYogiParameters)
}
OnlineYogiParameters::OnlineYogiParameters(const OnlineYogiParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  OnlineYogiParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.l1_){}
    , decltype(_impl_.l2_){}
    , decltype(_impl_.beta2_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.l1_, &from._impl_.l1_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.beta2_) -
    reinterpret_cast<char*>(&_impl_.l1_)) + sizeof(_impl_.beta2_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.OnlineYogiParameters)
}

inline void OnlineYogiParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.l1_){0}
    , decltype(_impl_.l2_){0}
    , decltype(_impl_.beta2_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

OnlineYogiParameters::~OnlineYogiParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.OnlineYogiParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void OnlineYogiParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void OnlineYogiParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void OnlineYogiParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.OnlineYogiParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.l1_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.beta2_) -
      reinterpret_cast<char*>(&_impl_.l1_)) + sizeof(_impl_.beta2_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* OnlineYogiParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float l1 = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _impl_.l1_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float l2 = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 21)) {
          _impl_.l2_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float beta2 = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 29)) {
          _impl_.beta2_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* OnlineYogiParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.OnlineYogiParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float l1 = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l1 = this->_internal_l1();
  uint32_t raw_l1;
  memcpy(&raw_l1, &tmp_l1, sizeof(tmp_l1));
  if (raw_l1 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_l1(), target);
  }

  // float l2 = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = this->_internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(2, this->_internal_l2(), target);
  }

  // float beta2 = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = this->_internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(3, this->_internal_beta2(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.OnlineYogiParameters)
  return target;
}

size_t OnlineYogiParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.OnlineYogiParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float l1 = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l1 = this->_internal_l1();
  uint32_t raw_l1;
  memcpy(&raw_l1, &tmp_l1, sizeof(tmp_l1));
  if (raw_l1 != 0) {
    total_size += 1 + 4;
  }

  // float l2 = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = this->_internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    total_size += 1 + 4;
  }

  // float beta2 = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = this->_internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    total_size += 1 + 4;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData OnlineYogiParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    OnlineYogiParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*OnlineYogiParameters::GetClassData() const { return &_class_data_; }


void OnlineYogiParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<OnlineYogiParameters*>(&to_msg);
  auto& from = static_cast<const OnlineYogiParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.OnlineYogiParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l1 = from._internal_l1();
  uint32_t raw_l1;
  memcpy(&raw_l1, &tmp_l1, sizeof(tmp_l1));
  if (raw_l1 != 0) {
    _this->_internal_set_l1(from._internal_l1());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = from._internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    _this->_internal_set_l2(from._internal_l2());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = from._internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    _this->_internal_set_beta2(from._internal_beta2());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void OnlineYogiParameters::CopyFrom(const OnlineYogiParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.OnlineYogiParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool OnlineYogiParameters::IsInitialized() const {
  return true;
}

void OnlineYogiParameters::InternalSwap(OnlineYogiParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(OnlineYogiParameters, _impl_.beta2_)
      + sizeof(OnlineYogiParameters::_impl_.beta2_)
      - PROTOBUF_FIELD_OFFSET(OnlineYogiParameters, _impl_.l1_)>(
          reinterpret_cast<char*>(&_impl_.l1_),
          reinterpret_cast<char*>(&other->_impl_.l1_));
}

::PROTOBUF_NAMESPACE_ID::Metadata OnlineYogiParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[17]);
}

// ===================================================================

class ProximalYogiParameters::_Internal {
 public:
};

ProximalYogiParameters::ProximalYogiParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.ProximalYogiParameters)
}
ProximalYogiParameters::ProximalYogiParameters(const ProximalYogiParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  ProximalYogiParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.l1_){}
    , decltype(_impl_.l2_){}
    , decltype(_impl_.beta1_){}
    , decltype(_impl_.beta2_){}
    , decltype(_impl_.epsilon_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.l1_, &from._impl_.l1_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.epsilon_) -
    reinterpret_cast<char*>(&_impl_.l1_)) + sizeof(_impl_.epsilon_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.ProximalYogiParameters)
}

inline void ProximalYogiParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.l1_){0}
    , decltype(_impl_.l2_){0}
    , decltype(_impl_.beta1_){0}
    , decltype(_impl_.beta2_){0}
    , decltype(_impl_.epsilon_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

ProximalYogiParameters::~ProximalYogiParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.ProximalYogiParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void ProximalYogiParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void ProximalYogiParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void ProximalYogiParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.ProximalYogiParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.l1_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.epsilon_) -
      reinterpret_cast<char*>(&_impl_.l1_)) + sizeof(_impl_.epsilon_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ProximalYogiParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float l1 = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _impl_.l1_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float l2 = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 21)) {
          _impl_.l2_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float beta1 = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 29)) {
          _impl_.beta1_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float beta2 = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 37)) {
          _impl_.beta2_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float epsilon = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 45)) {
          _impl_.epsilon_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ProximalYogiParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.ProximalYogiParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float l1 = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l1 = this->_internal_l1();
  uint32_t raw_l1;
  memcpy(&raw_l1, &tmp_l1, sizeof(tmp_l1));
  if (raw_l1 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_l1(), target);
  }

  // float l2 = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = this->_internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(2, this->_internal_l2(), target);
  }

  // float beta1 = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta1 = this->_internal_beta1();
  uint32_t raw_beta1;
  memcpy(&raw_beta1, &tmp_beta1, sizeof(tmp_beta1));
  if (raw_beta1 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(3, this->_internal_beta1(), target);
  }

  // float beta2 = 4;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = this->_internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(4, this->_internal_beta2(), target);
  }

  // float epsilon = 5;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = this->_internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(5, this->_internal_epsilon(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.ProximalYogiParameters)
  return target;
}

size_t ProximalYogiParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.ProximalYogiParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float l1 = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l1 = this->_internal_l1();
  uint32_t raw_l1;
  memcpy(&raw_l1, &tmp_l1, sizeof(tmp_l1));
  if (raw_l1 != 0) {
    total_size += 1 + 4;
  }

  // float l2 = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = this->_internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    total_size += 1 + 4;
  }

  // float beta1 = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta1 = this->_internal_beta1();
  uint32_t raw_beta1;
  memcpy(&raw_beta1, &tmp_beta1, sizeof(tmp_beta1));
  if (raw_beta1 != 0) {
    total_size += 1 + 4;
  }

  // float beta2 = 4;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = this->_internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    total_size += 1 + 4;
  }

  // float epsilon = 5;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = this->_internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    total_size += 1 + 4;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ProximalYogiParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    ProximalYogiParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ProximalYogiParameters::GetClassData() const { return &_class_data_; }


void ProximalYogiParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<ProximalYogiParameters*>(&to_msg);
  auto& from = static_cast<const ProximalYogiParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.ProximalYogiParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l1 = from._internal_l1();
  uint32_t raw_l1;
  memcpy(&raw_l1, &tmp_l1, sizeof(tmp_l1));
  if (raw_l1 != 0) {
    _this->_internal_set_l1(from._internal_l1());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_l2 = from._internal_l2();
  uint32_t raw_l2;
  memcpy(&raw_l2, &tmp_l2, sizeof(tmp_l2));
  if (raw_l2 != 0) {
    _this->_internal_set_l2(from._internal_l2());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta1 = from._internal_beta1();
  uint32_t raw_beta1;
  memcpy(&raw_beta1, &tmp_beta1, sizeof(tmp_beta1));
  if (raw_beta1 != 0) {
    _this->_internal_set_beta1(from._internal_beta1());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_beta2 = from._internal_beta2();
  uint32_t raw_beta2;
  memcpy(&raw_beta2, &tmp_beta2, sizeof(tmp_beta2));
  if (raw_beta2 != 0) {
    _this->_internal_set_beta2(from._internal_beta2());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_epsilon = from._internal_epsilon();
  uint32_t raw_epsilon;
  memcpy(&raw_epsilon, &tmp_epsilon, sizeof(tmp_epsilon));
  if (raw_epsilon != 0) {
    _this->_internal_set_epsilon(from._internal_epsilon());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ProximalYogiParameters::CopyFrom(const ProximalYogiParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.ProximalYogiParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ProximalYogiParameters::IsInitialized() const {
  return true;
}

void ProximalYogiParameters::InternalSwap(ProximalYogiParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(ProximalYogiParameters, _impl_.epsilon_)
      + sizeof(ProximalYogiParameters::_impl_.epsilon_)
      - PROTOBUF_FIELD_OFFSET(ProximalYogiParameters, _impl_.l1_)>(
          reinterpret_cast<char*>(&_impl_.l1_),
          reinterpret_cast<char*>(&other->_impl_.l1_));
}

::PROTOBUF_NAMESPACE_ID::Metadata ProximalYogiParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[18]);
}

// ===================================================================

class FrequencyEstimatorParameters::_Internal {
 public:
};

FrequencyEstimatorParameters::FrequencyEstimatorParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.FrequencyEstimatorParameters)
}
FrequencyEstimatorParameters::FrequencyEstimatorParameters(const FrequencyEstimatorParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  FrequencyEstimatorParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.tau_){}
    , decltype(_impl_.max_delta_){}
    , decltype(_impl_.outlier_threshold_){}
    , decltype(_impl_.weight_exponent_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.tau_, &from._impl_.tau_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.weight_exponent_) -
    reinterpret_cast<char*>(&_impl_.tau_)) + sizeof(_impl_.weight_exponent_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.FrequencyEstimatorParameters)
}

inline void FrequencyEstimatorParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.tau_){0}
    , decltype(_impl_.max_delta_){0}
    , decltype(_impl_.outlier_threshold_){0}
    , decltype(_impl_.weight_exponent_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

FrequencyEstimatorParameters::~FrequencyEstimatorParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.FrequencyEstimatorParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void FrequencyEstimatorParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void FrequencyEstimatorParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void FrequencyEstimatorParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.FrequencyEstimatorParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.tau_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.weight_exponent_) -
      reinterpret_cast<char*>(&_impl_.tau_)) + sizeof(_impl_.weight_exponent_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* FrequencyEstimatorParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // float tau = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 13)) {
          _impl_.tau_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float max_delta = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 21)) {
          _impl_.max_delta_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float outlier_threshold = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 29)) {
          _impl_.outlier_threshold_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // float weight_exponent = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 37)) {
          _impl_.weight_exponent_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* FrequencyEstimatorParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.FrequencyEstimatorParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // float tau = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_tau = this->_internal_tau();
  uint32_t raw_tau;
  memcpy(&raw_tau, &tmp_tau, sizeof(tmp_tau));
  if (raw_tau != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(1, this->_internal_tau(), target);
  }

  // float max_delta = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_delta = this->_internal_max_delta();
  uint32_t raw_max_delta;
  memcpy(&raw_max_delta, &tmp_max_delta, sizeof(tmp_max_delta));
  if (raw_max_delta != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(2, this->_internal_max_delta(), target);
  }

  // float outlier_threshold = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_outlier_threshold = this->_internal_outlier_threshold();
  uint32_t raw_outlier_threshold;
  memcpy(&raw_outlier_threshold, &tmp_outlier_threshold, sizeof(tmp_outlier_threshold));
  if (raw_outlier_threshold != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(3, this->_internal_outlier_threshold(), target);
  }

  // float weight_exponent = 4;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_weight_exponent = this->_internal_weight_exponent();
  uint32_t raw_weight_exponent;
  memcpy(&raw_weight_exponent, &tmp_weight_exponent, sizeof(tmp_weight_exponent));
  if (raw_weight_exponent != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(4, this->_internal_weight_exponent(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.FrequencyEstimatorParameters)
  return target;
}

size_t FrequencyEstimatorParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.FrequencyEstimatorParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // float tau = 1;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_tau = this->_internal_tau();
  uint32_t raw_tau;
  memcpy(&raw_tau, &tmp_tau, sizeof(tmp_tau));
  if (raw_tau != 0) {
    total_size += 1 + 4;
  }

  // float max_delta = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_delta = this->_internal_max_delta();
  uint32_t raw_max_delta;
  memcpy(&raw_max_delta, &tmp_max_delta, sizeof(tmp_max_delta));
  if (raw_max_delta != 0) {
    total_size += 1 + 4;
  }

  // float outlier_threshold = 3;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_outlier_threshold = this->_internal_outlier_threshold();
  uint32_t raw_outlier_threshold;
  memcpy(&raw_outlier_threshold, &tmp_outlier_threshold, sizeof(tmp_outlier_threshold));
  if (raw_outlier_threshold != 0) {
    total_size += 1 + 4;
  }

  // float weight_exponent = 4;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_weight_exponent = this->_internal_weight_exponent();
  uint32_t raw_weight_exponent;
  memcpy(&raw_weight_exponent, &tmp_weight_exponent, sizeof(tmp_weight_exponent));
  if (raw_weight_exponent != 0) {
    total_size += 1 + 4;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData FrequencyEstimatorParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    FrequencyEstimatorParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*FrequencyEstimatorParameters::GetClassData() const { return &_class_data_; }


void FrequencyEstimatorParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<FrequencyEstimatorParameters*>(&to_msg);
  auto& from = static_cast<const FrequencyEstimatorParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.FrequencyEstimatorParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_tau = from._internal_tau();
  uint32_t raw_tau;
  memcpy(&raw_tau, &tmp_tau, sizeof(tmp_tau));
  if (raw_tau != 0) {
    _this->_internal_set_tau(from._internal_tau());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_max_delta = from._internal_max_delta();
  uint32_t raw_max_delta;
  memcpy(&raw_max_delta, &tmp_max_delta, sizeof(tmp_max_delta));
  if (raw_max_delta != 0) {
    _this->_internal_set_max_delta(from._internal_max_delta());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_outlier_threshold = from._internal_outlier_threshold();
  uint32_t raw_outlier_threshold;
  memcpy(&raw_outlier_threshold, &tmp_outlier_threshold, sizeof(tmp_outlier_threshold));
  if (raw_outlier_threshold != 0) {
    _this->_internal_set_outlier_threshold(from._internal_outlier_threshold());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_weight_exponent = from._internal_weight_exponent();
  uint32_t raw_weight_exponent;
  memcpy(&raw_weight_exponent, &tmp_weight_exponent, sizeof(tmp_weight_exponent));
  if (raw_weight_exponent != 0) {
    _this->_internal_set_weight_exponent(from._internal_weight_exponent());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void FrequencyEstimatorParameters::CopyFrom(const FrequencyEstimatorParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.FrequencyEstimatorParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool FrequencyEstimatorParameters::IsInitialized() const {
  return true;
}

void FrequencyEstimatorParameters::InternalSwap(FrequencyEstimatorParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(FrequencyEstimatorParameters, _impl_.weight_exponent_)
      + sizeof(FrequencyEstimatorParameters::_impl_.weight_exponent_)
      - PROTOBUF_FIELD_OFFSET(FrequencyEstimatorParameters, _impl_.tau_)>(
          reinterpret_cast<char*>(&_impl_.tau_),
          reinterpret_cast<char*>(&other->_impl_.tau_));
}

::PROTOBUF_NAMESPACE_ID::Metadata FrequencyEstimatorParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[19]);
}

// ===================================================================

class UserDefinedProgramParameters::_Internal {
 public:
  static const ::xla::HloModuleProto& program(const UserDefinedProgramParameters* msg);
};

const ::xla::HloModuleProto&
UserDefinedProgramParameters::_Internal::program(const UserDefinedProgramParameters* msg) {
  return *msg->_impl_.program_;
}
void UserDefinedProgramParameters::clear_program() {
  if (GetArenaForAllocation() == nullptr && _impl_.program_ != nullptr) {
    delete _impl_.program_;
  }
  _impl_.program_ = nullptr;
}
UserDefinedProgramParameters::UserDefinedProgramParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.UserDefinedProgramParameters)
}
UserDefinedProgramParameters::UserDefinedProgramParameters(const UserDefinedProgramParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  UserDefinedProgramParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.program_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  if (from._internal_has_program()) {
    _this->_impl_.program_ = new ::xla::HloModuleProto(*from._impl_.program_);
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.UserDefinedProgramParameters)
}

inline void UserDefinedProgramParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.program_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

UserDefinedProgramParameters::~UserDefinedProgramParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.UserDefinedProgramParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void UserDefinedProgramParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (this != internal_default_instance()) delete _impl_.program_;
}

void UserDefinedProgramParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void UserDefinedProgramParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.UserDefinedProgramParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaForAllocation() == nullptr && _impl_.program_ != nullptr) {
    delete _impl_.program_;
  }
  _impl_.program_ = nullptr;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* UserDefinedProgramParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .xla.HloModuleProto program = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_program(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* UserDefinedProgramParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.UserDefinedProgramParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .xla.HloModuleProto program = 1;
  if (this->_internal_has_program()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(1, _Internal::program(this),
        _Internal::program(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.UserDefinedProgramParameters)
  return target;
}

size_t UserDefinedProgramParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.UserDefinedProgramParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .xla.HloModuleProto program = 1;
  if (this->_internal_has_program()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.program_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData UserDefinedProgramParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    UserDefinedProgramParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*UserDefinedProgramParameters::GetClassData() const { return &_class_data_; }


void UserDefinedProgramParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<UserDefinedProgramParameters*>(&to_msg);
  auto& from = static_cast<const UserDefinedProgramParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.UserDefinedProgramParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_has_program()) {
    _this->_internal_mutable_program()->::xla::HloModuleProto::MergeFrom(
        from._internal_program());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void UserDefinedProgramParameters::CopyFrom(const UserDefinedProgramParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.UserDefinedProgramParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool UserDefinedProgramParameters::IsInitialized() const {
  return true;
}

void UserDefinedProgramParameters::InternalSwap(UserDefinedProgramParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_.program_, other->_impl_.program_);
}

::PROTOBUF_NAMESPACE_ID::Metadata UserDefinedProgramParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[20]);
}

// ===================================================================

class AssignParameters::_Internal {
 public:
};

AssignParameters::AssignParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase(arena, is_message_owned) {
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.AssignParameters)
}
AssignParameters::AssignParameters(const AssignParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase() {
  AssignParameters* const _this = this; (void)_this;
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.AssignParameters)
}





const ::PROTOBUF_NAMESPACE_ID::Message::ClassData AssignParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::CopyImpl,
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::MergeImpl,
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*AssignParameters::GetClassData() const { return &_class_data_; }







::PROTOBUF_NAMESPACE_ID::Metadata AssignParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[21]);
}

// ===================================================================

class GradientAccumulationStatus::_Internal {
 public:
};

GradientAccumulationStatus::GradientAccumulationStatus(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase(arena, is_message_owned) {
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.GradientAccumulationStatus)
}
GradientAccumulationStatus::GradientAccumulationStatus(const GradientAccumulationStatus& from)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase() {
  GradientAccumulationStatus* const _this = this; (void)_this;
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.GradientAccumulationStatus)
}





const ::PROTOBUF_NAMESPACE_ID::Message::ClassData GradientAccumulationStatus::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::CopyImpl,
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::MergeImpl,
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GradientAccumulationStatus::GetClassData() const { return &_class_data_; }







::PROTOBUF_NAMESPACE_ID::Metadata GradientAccumulationStatus::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[22]);
}

// ===================================================================

class LowDimensionalPackingStatus::_Internal {
 public:
};

LowDimensionalPackingStatus::LowDimensionalPackingStatus(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase(arena, is_message_owned) {
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.LowDimensionalPackingStatus)
}
LowDimensionalPackingStatus::LowDimensionalPackingStatus(const LowDimensionalPackingStatus& from)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase() {
  LowDimensionalPackingStatus* const _this = this; (void)_this;
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.LowDimensionalPackingStatus)
}





const ::PROTOBUF_NAMESPACE_ID::Message::ClassData LowDimensionalPackingStatus::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::CopyImpl,
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::MergeImpl,
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*LowDimensionalPackingStatus::GetClassData() const { return &_class_data_; }







::PROTOBUF_NAMESPACE_ID::Metadata LowDimensionalPackingStatus::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[23]);
}

// ===================================================================

class HotIdReplicationConfiguration::_Internal {
 public:
};

HotIdReplicationConfiguration::HotIdReplicationConfiguration(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.HotIdReplicationConfiguration)
}
HotIdReplicationConfiguration::HotIdReplicationConfiguration(const HotIdReplicationConfiguration& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  HotIdReplicationConfiguration* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.status_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _this->_impl_.status_ = from._impl_.status_;
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.HotIdReplicationConfiguration)
}

inline void HotIdReplicationConfiguration::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.status_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

HotIdReplicationConfiguration::~HotIdReplicationConfiguration() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.HotIdReplicationConfiguration)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void HotIdReplicationConfiguration::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void HotIdReplicationConfiguration::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void HotIdReplicationConfiguration::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.HotIdReplicationConfiguration)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.status_ = 0;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* HotIdReplicationConfiguration::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .tensorflow.tpu.HotIdReplicationConfiguration.Status status = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_status(static_cast<::tensorflow::tpu::HotIdReplicationConfiguration_Status>(val));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* HotIdReplicationConfiguration::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.HotIdReplicationConfiguration)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.tpu.HotIdReplicationConfiguration.Status status = 1;
  if (this->_internal_status() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      1, this->_internal_status(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.HotIdReplicationConfiguration)
  return target;
}

size_t HotIdReplicationConfiguration::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.HotIdReplicationConfiguration)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.tpu.HotIdReplicationConfiguration.Status status = 1;
  if (this->_internal_status() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_status());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData HotIdReplicationConfiguration::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    HotIdReplicationConfiguration::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*HotIdReplicationConfiguration::GetClassData() const { return &_class_data_; }


void HotIdReplicationConfiguration::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<HotIdReplicationConfiguration*>(&to_msg);
  auto& from = static_cast<const HotIdReplicationConfiguration&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.HotIdReplicationConfiguration)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_status() != 0) {
    _this->_internal_set_status(from._internal_status());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void HotIdReplicationConfiguration::CopyFrom(const HotIdReplicationConfiguration& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.HotIdReplicationConfiguration)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool HotIdReplicationConfiguration::IsInitialized() const {
  return true;
}

void HotIdReplicationConfiguration::InternalSwap(HotIdReplicationConfiguration* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_.status_, other->_impl_.status_);
}

::PROTOBUF_NAMESPACE_ID::Metadata HotIdReplicationConfiguration::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[24]);
}

// ===================================================================

class OptimizationParameters::_Internal {
 public:
  static const ::tensorflow::tpu::LearningRate& learning_rate(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::ClippingLimits& clipping_limits(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::ClippingLimits& gradient_clipping_limits(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::SimulatedQuantization& simulated_quantization(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::HotIdReplicationConfiguration& hot_id_replication_configuration(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::AdagradParameters& adagrad(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::AdagradMomentumParameters& adagrad_momentum(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::BoundedAdagradParameters& bounded_adagrad(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::StochasticGradientDescentParameters& stochastic_gradient_descent(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::FtrlParameters& ftrl(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::AdamParameters& adam(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::MomentumParameters& momentum(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::LionParameters& lion(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::RmsPropParameters& rms_prop(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::CenteredRmsPropParameters& centered_rms_prop(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::MdlAdagradLightParameters& mdl_adagrad_light(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::AdadeltaParameters& adadelta(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::ProximalAdagradParameters& proximal_adagrad(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::OnlineYogiParameters& online_yogi(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::ProximalYogiParameters& proximal_yogi(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::FrequencyEstimatorParameters& frequency_estimator(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::UserDefinedProgramParameters& user_defined_program(const OptimizationParameters* msg);
  static const ::tensorflow::tpu::AssignParameters& assign(const OptimizationParameters* msg);
};

const ::tensorflow::tpu::LearningRate&
OptimizationParameters::_Internal::learning_rate(const OptimizationParameters* msg) {
  return *msg->_impl_.learning_rate_;
}
const ::tensorflow::tpu::ClippingLimits&
OptimizationParameters::_Internal::clipping_limits(const OptimizationParameters* msg) {
  return *msg->_impl_.clipping_limits_;
}
const ::tensorflow::tpu::ClippingLimits&
OptimizationParameters::_Internal::gradient_clipping_limits(const OptimizationParameters* msg) {
  return *msg->_impl_.gradient_clipping_limits_;
}
const ::tensorflow::tpu::SimulatedQuantization&
OptimizationParameters::_Internal::simulated_quantization(const OptimizationParameters* msg) {
  return *msg->_impl_.simulated_quantization_;
}
const ::tensorflow::tpu::HotIdReplicationConfiguration&
OptimizationParameters::_Internal::hot_id_replication_configuration(const OptimizationParameters* msg) {
  return *msg->_impl_.hot_id_replication_configuration_;
}
const ::tensorflow::tpu::AdagradParameters&
OptimizationParameters::_Internal::adagrad(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.adagrad_;
}
const ::tensorflow::tpu::AdagradMomentumParameters&
OptimizationParameters::_Internal::adagrad_momentum(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.adagrad_momentum_;
}
const ::tensorflow::tpu::BoundedAdagradParameters&
OptimizationParameters::_Internal::bounded_adagrad(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.bounded_adagrad_;
}
const ::tensorflow::tpu::StochasticGradientDescentParameters&
OptimizationParameters::_Internal::stochastic_gradient_descent(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.stochastic_gradient_descent_;
}
const ::tensorflow::tpu::FtrlParameters&
OptimizationParameters::_Internal::ftrl(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.ftrl_;
}
const ::tensorflow::tpu::AdamParameters&
OptimizationParameters::_Internal::adam(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.adam_;
}
const ::tensorflow::tpu::MomentumParameters&
OptimizationParameters::_Internal::momentum(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.momentum_;
}
const ::tensorflow::tpu::LionParameters&
OptimizationParameters::_Internal::lion(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.lion_;
}
const ::tensorflow::tpu::RmsPropParameters&
OptimizationParameters::_Internal::rms_prop(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.rms_prop_;
}
const ::tensorflow::tpu::CenteredRmsPropParameters&
OptimizationParameters::_Internal::centered_rms_prop(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.centered_rms_prop_;
}
const ::tensorflow::tpu::MdlAdagradLightParameters&
OptimizationParameters::_Internal::mdl_adagrad_light(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.mdl_adagrad_light_;
}
const ::tensorflow::tpu::AdadeltaParameters&
OptimizationParameters::_Internal::adadelta(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.adadelta_;
}
const ::tensorflow::tpu::ProximalAdagradParameters&
OptimizationParameters::_Internal::proximal_adagrad(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.proximal_adagrad_;
}
const ::tensorflow::tpu::OnlineYogiParameters&
OptimizationParameters::_Internal::online_yogi(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.online_yogi_;
}
const ::tensorflow::tpu::ProximalYogiParameters&
OptimizationParameters::_Internal::proximal_yogi(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.proximal_yogi_;
}
const ::tensorflow::tpu::FrequencyEstimatorParameters&
OptimizationParameters::_Internal::frequency_estimator(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.frequency_estimator_;
}
const ::tensorflow::tpu::UserDefinedProgramParameters&
OptimizationParameters::_Internal::user_defined_program(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.user_defined_program_;
}
const ::tensorflow::tpu::AssignParameters&
OptimizationParameters::_Internal::assign(const OptimizationParameters* msg) {
  return *msg->_impl_.parameters_.assign_;
}
void OptimizationParameters::set_allocated_adagrad(::tensorflow::tpu::AdagradParameters* adagrad) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (adagrad) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(adagrad);
    if (message_arena != submessage_arena) {
      adagrad = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, adagrad, submessage_arena);
    }
    set_has_adagrad();
    _impl_.parameters_.adagrad_ = adagrad;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.adagrad)
}
void OptimizationParameters::set_allocated_adagrad_momentum(::tensorflow::tpu::AdagradMomentumParameters* adagrad_momentum) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (adagrad_momentum) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(adagrad_momentum);
    if (message_arena != submessage_arena) {
      adagrad_momentum = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, adagrad_momentum, submessage_arena);
    }
    set_has_adagrad_momentum();
    _impl_.parameters_.adagrad_momentum_ = adagrad_momentum;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.adagrad_momentum)
}
void OptimizationParameters::set_allocated_bounded_adagrad(::tensorflow::tpu::BoundedAdagradParameters* bounded_adagrad) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (bounded_adagrad) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(bounded_adagrad);
    if (message_arena != submessage_arena) {
      bounded_adagrad = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, bounded_adagrad, submessage_arena);
    }
    set_has_bounded_adagrad();
    _impl_.parameters_.bounded_adagrad_ = bounded_adagrad;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.bounded_adagrad)
}
void OptimizationParameters::set_allocated_stochastic_gradient_descent(::tensorflow::tpu::StochasticGradientDescentParameters* stochastic_gradient_descent) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (stochastic_gradient_descent) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(stochastic_gradient_descent);
    if (message_arena != submessage_arena) {
      stochastic_gradient_descent = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, stochastic_gradient_descent, submessage_arena);
    }
    set_has_stochastic_gradient_descent();
    _impl_.parameters_.stochastic_gradient_descent_ = stochastic_gradient_descent;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.stochastic_gradient_descent)
}
void OptimizationParameters::set_allocated_ftrl(::tensorflow::tpu::FtrlParameters* ftrl) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (ftrl) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(ftrl);
    if (message_arena != submessage_arena) {
      ftrl = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, ftrl, submessage_arena);
    }
    set_has_ftrl();
    _impl_.parameters_.ftrl_ = ftrl;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.ftrl)
}
void OptimizationParameters::set_allocated_adam(::tensorflow::tpu::AdamParameters* adam) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (adam) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(adam);
    if (message_arena != submessage_arena) {
      adam = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, adam, submessage_arena);
    }
    set_has_adam();
    _impl_.parameters_.adam_ = adam;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.adam)
}
void OptimizationParameters::set_allocated_momentum(::tensorflow::tpu::MomentumParameters* momentum) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (momentum) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(momentum);
    if (message_arena != submessage_arena) {
      momentum = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, momentum, submessage_arena);
    }
    set_has_momentum();
    _impl_.parameters_.momentum_ = momentum;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.momentum)
}
void OptimizationParameters::set_allocated_lion(::tensorflow::tpu::LionParameters* lion) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (lion) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(lion);
    if (message_arena != submessage_arena) {
      lion = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, lion, submessage_arena);
    }
    set_has_lion();
    _impl_.parameters_.lion_ = lion;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.lion)
}
void OptimizationParameters::set_allocated_rms_prop(::tensorflow::tpu::RmsPropParameters* rms_prop) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (rms_prop) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(rms_prop);
    if (message_arena != submessage_arena) {
      rms_prop = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, rms_prop, submessage_arena);
    }
    set_has_rms_prop();
    _impl_.parameters_.rms_prop_ = rms_prop;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.rms_prop)
}
void OptimizationParameters::set_allocated_centered_rms_prop(::tensorflow::tpu::CenteredRmsPropParameters* centered_rms_prop) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (centered_rms_prop) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(centered_rms_prop);
    if (message_arena != submessage_arena) {
      centered_rms_prop = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, centered_rms_prop, submessage_arena);
    }
    set_has_centered_rms_prop();
    _impl_.parameters_.centered_rms_prop_ = centered_rms_prop;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.centered_rms_prop)
}
void OptimizationParameters::set_allocated_mdl_adagrad_light(::tensorflow::tpu::MdlAdagradLightParameters* mdl_adagrad_light) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (mdl_adagrad_light) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(mdl_adagrad_light);
    if (message_arena != submessage_arena) {
      mdl_adagrad_light = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, mdl_adagrad_light, submessage_arena);
    }
    set_has_mdl_adagrad_light();
    _impl_.parameters_.mdl_adagrad_light_ = mdl_adagrad_light;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.mdl_adagrad_light)
}
void OptimizationParameters::set_allocated_adadelta(::tensorflow::tpu::AdadeltaParameters* adadelta) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (adadelta) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(adadelta);
    if (message_arena != submessage_arena) {
      adadelta = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, adadelta, submessage_arena);
    }
    set_has_adadelta();
    _impl_.parameters_.adadelta_ = adadelta;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.adadelta)
}
void OptimizationParameters::set_allocated_proximal_adagrad(::tensorflow::tpu::ProximalAdagradParameters* proximal_adagrad) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (proximal_adagrad) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(proximal_adagrad);
    if (message_arena != submessage_arena) {
      proximal_adagrad = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, proximal_adagrad, submessage_arena);
    }
    set_has_proximal_adagrad();
    _impl_.parameters_.proximal_adagrad_ = proximal_adagrad;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.proximal_adagrad)
}
void OptimizationParameters::set_allocated_online_yogi(::tensorflow::tpu::OnlineYogiParameters* online_yogi) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (online_yogi) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(online_yogi);
    if (message_arena != submessage_arena) {
      online_yogi = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, online_yogi, submessage_arena);
    }
    set_has_online_yogi();
    _impl_.parameters_.online_yogi_ = online_yogi;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.online_yogi)
}
void OptimizationParameters::set_allocated_proximal_yogi(::tensorflow::tpu::ProximalYogiParameters* proximal_yogi) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (proximal_yogi) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(proximal_yogi);
    if (message_arena != submessage_arena) {
      proximal_yogi = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, proximal_yogi, submessage_arena);
    }
    set_has_proximal_yogi();
    _impl_.parameters_.proximal_yogi_ = proximal_yogi;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.proximal_yogi)
}
void OptimizationParameters::set_allocated_frequency_estimator(::tensorflow::tpu::FrequencyEstimatorParameters* frequency_estimator) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (frequency_estimator) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(frequency_estimator);
    if (message_arena != submessage_arena) {
      frequency_estimator = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, frequency_estimator, submessage_arena);
    }
    set_has_frequency_estimator();
    _impl_.parameters_.frequency_estimator_ = frequency_estimator;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.frequency_estimator)
}
void OptimizationParameters::set_allocated_user_defined_program(::tensorflow::tpu::UserDefinedProgramParameters* user_defined_program) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (user_defined_program) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(user_defined_program);
    if (message_arena != submessage_arena) {
      user_defined_program = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, user_defined_program, submessage_arena);
    }
    set_has_user_defined_program();
    _impl_.parameters_.user_defined_program_ = user_defined_program;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.user_defined_program)
}
void OptimizationParameters::set_allocated_assign(::tensorflow::tpu::AssignParameters* assign) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_parameters();
  if (assign) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(assign);
    if (message_arena != submessage_arena) {
      assign = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, assign, submessage_arena);
    }
    set_has_assign();
    _impl_.parameters_.assign_ = assign;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.OptimizationParameters.assign)
}
OptimizationParameters::OptimizationParameters(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.OptimizationParameters)
}
OptimizationParameters::OptimizationParameters(const OptimizationParameters& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  OptimizationParameters* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.clipping_limits_){nullptr}
    , decltype(_impl_.gradient_clipping_limits_){nullptr}
    , decltype(_impl_.learning_rate_){nullptr}
    , decltype(_impl_.hot_id_replication_configuration_){nullptr}
    , decltype(_impl_.simulated_quantization_){nullptr}
    , decltype(_impl_.weight_decay_factor_){}
    , decltype(_impl_.gradient_accumulation_status_){}
    , decltype(_impl_.multiply_weight_decay_factor_by_learning_rate_){}
    , decltype(_impl_.low_dimensional_packing_status_){}
    , decltype(_impl_.parameters_){}
    , /*decltype(_impl_._cached_size_)*/{}
    , /*decltype(_impl_._oneof_case_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  if (from._internal_has_clipping_limits()) {
    _this->_impl_.clipping_limits_ = new ::tensorflow::tpu::ClippingLimits(*from._impl_.clipping_limits_);
  }
  if (from._internal_has_gradient_clipping_limits()) {
    _this->_impl_.gradient_clipping_limits_ = new ::tensorflow::tpu::ClippingLimits(*from._impl_.gradient_clipping_limits_);
  }
  if (from._internal_has_learning_rate()) {
    _this->_impl_.learning_rate_ = new ::tensorflow::tpu::LearningRate(*from._impl_.learning_rate_);
  }
  if (from._internal_has_hot_id_replication_configuration()) {
    _this->_impl_.hot_id_replication_configuration_ = new ::tensorflow::tpu::HotIdReplicationConfiguration(*from._impl_.hot_id_replication_configuration_);
  }
  if (from._internal_has_simulated_quantization()) {
    _this->_impl_.simulated_quantization_ = new ::tensorflow::tpu::SimulatedQuantization(*from._impl_.simulated_quantization_);
  }
  ::memcpy(&_impl_.weight_decay_factor_, &from._impl_.weight_decay_factor_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.low_dimensional_packing_status_) -
    reinterpret_cast<char*>(&_impl_.weight_decay_factor_)) + sizeof(_impl_.low_dimensional_packing_status_));
  clear_has_parameters();
  switch (from.parameters_case()) {
    case kAdagrad: {
      _this->_internal_mutable_adagrad()->::tensorflow::tpu::AdagradParameters::MergeFrom(
          from._internal_adagrad());
      break;
    }
    case kAdagradMomentum: {
      _this->_internal_mutable_adagrad_momentum()->::tensorflow::tpu::AdagradMomentumParameters::MergeFrom(
          from._internal_adagrad_momentum());
      break;
    }
    case kBoundedAdagrad: {
      _this->_internal_mutable_bounded_adagrad()->::tensorflow::tpu::BoundedAdagradParameters::MergeFrom(
          from._internal_bounded_adagrad());
      break;
    }
    case kStochasticGradientDescent: {
      _this->_internal_mutable_stochastic_gradient_descent()->::tensorflow::tpu::StochasticGradientDescentParameters::MergeFrom(
          from._internal_stochastic_gradient_descent());
      break;
    }
    case kFtrl: {
      _this->_internal_mutable_ftrl()->::tensorflow::tpu::FtrlParameters::MergeFrom(
          from._internal_ftrl());
      break;
    }
    case kAdam: {
      _this->_internal_mutable_adam()->::tensorflow::tpu::AdamParameters::MergeFrom(
          from._internal_adam());
      break;
    }
    case kMomentum: {
      _this->_internal_mutable_momentum()->::tensorflow::tpu::MomentumParameters::MergeFrom(
          from._internal_momentum());
      break;
    }
    case kLion: {
      _this->_internal_mutable_lion()->::tensorflow::tpu::LionParameters::MergeFrom(
          from._internal_lion());
      break;
    }
    case kRmsProp: {
      _this->_internal_mutable_rms_prop()->::tensorflow::tpu::RmsPropParameters::MergeFrom(
          from._internal_rms_prop());
      break;
    }
    case kCenteredRmsProp: {
      _this->_internal_mutable_centered_rms_prop()->::tensorflow::tpu::CenteredRmsPropParameters::MergeFrom(
          from._internal_centered_rms_prop());
      break;
    }
    case kMdlAdagradLight: {
      _this->_internal_mutable_mdl_adagrad_light()->::tensorflow::tpu::MdlAdagradLightParameters::MergeFrom(
          from._internal_mdl_adagrad_light());
      break;
    }
    case kAdadelta: {
      _this->_internal_mutable_adadelta()->::tensorflow::tpu::AdadeltaParameters::MergeFrom(
          from._internal_adadelta());
      break;
    }
    case kProximalAdagrad: {
      _this->_internal_mutable_proximal_adagrad()->::tensorflow::tpu::ProximalAdagradParameters::MergeFrom(
          from._internal_proximal_adagrad());
      break;
    }
    case kOnlineYogi: {
      _this->_internal_mutable_online_yogi()->::tensorflow::tpu::OnlineYogiParameters::MergeFrom(
          from._internal_online_yogi());
      break;
    }
    case kProximalYogi: {
      _this->_internal_mutable_proximal_yogi()->::tensorflow::tpu::ProximalYogiParameters::MergeFrom(
          from._internal_proximal_yogi());
      break;
    }
    case kFrequencyEstimator: {
      _this->_internal_mutable_frequency_estimator()->::tensorflow::tpu::FrequencyEstimatorParameters::MergeFrom(
          from._internal_frequency_estimator());
      break;
    }
    case kUserDefinedProgram: {
      _this->_internal_mutable_user_defined_program()->::tensorflow::tpu::UserDefinedProgramParameters::MergeFrom(
          from._internal_user_defined_program());
      break;
    }
    case kAssign: {
      _this->_internal_mutable_assign()->::tensorflow::tpu::AssignParameters::MergeFrom(
          from._internal_assign());
      break;
    }
    case PARAMETERS_NOT_SET: {
      break;
    }
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.OptimizationParameters)
}

inline void OptimizationParameters::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.clipping_limits_){nullptr}
    , decltype(_impl_.gradient_clipping_limits_){nullptr}
    , decltype(_impl_.learning_rate_){nullptr}
    , decltype(_impl_.hot_id_replication_configuration_){nullptr}
    , decltype(_impl_.simulated_quantization_){nullptr}
    , decltype(_impl_.weight_decay_factor_){0}
    , decltype(_impl_.gradient_accumulation_status_){0}
    , decltype(_impl_.multiply_weight_decay_factor_by_learning_rate_){false}
    , decltype(_impl_.low_dimensional_packing_status_){0}
    , decltype(_impl_.parameters_){}
    , /*decltype(_impl_._cached_size_)*/{}
    , /*decltype(_impl_._oneof_case_)*/{}
  };
  clear_has_parameters();
}

OptimizationParameters::~OptimizationParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.OptimizationParameters)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void OptimizationParameters::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (this != internal_default_instance()) delete _impl_.clipping_limits_;
  if (this != internal_default_instance()) delete _impl_.gradient_clipping_limits_;
  if (this != internal_default_instance()) delete _impl_.learning_rate_;
  if (this != internal_default_instance()) delete _impl_.hot_id_replication_configuration_;
  if (this != internal_default_instance()) delete _impl_.simulated_quantization_;
  if (has_parameters()) {
    clear_parameters();
  }
}

void OptimizationParameters::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void OptimizationParameters::clear_parameters() {
// @@protoc_insertion_point(one_of_clear_start:tensorflow.tpu.OptimizationParameters)
  switch (parameters_case()) {
    case kAdagrad: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.adagrad_;
      }
      break;
    }
    case kAdagradMomentum: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.adagrad_momentum_;
      }
      break;
    }
    case kBoundedAdagrad: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.bounded_adagrad_;
      }
      break;
    }
    case kStochasticGradientDescent: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.stochastic_gradient_descent_;
      }
      break;
    }
    case kFtrl: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.ftrl_;
      }
      break;
    }
    case kAdam: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.adam_;
      }
      break;
    }
    case kMomentum: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.momentum_;
      }
      break;
    }
    case kLion: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.lion_;
      }
      break;
    }
    case kRmsProp: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.rms_prop_;
      }
      break;
    }
    case kCenteredRmsProp: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.centered_rms_prop_;
      }
      break;
    }
    case kMdlAdagradLight: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.mdl_adagrad_light_;
      }
      break;
    }
    case kAdadelta: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.adadelta_;
      }
      break;
    }
    case kProximalAdagrad: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.proximal_adagrad_;
      }
      break;
    }
    case kOnlineYogi: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.online_yogi_;
      }
      break;
    }
    case kProximalYogi: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.proximal_yogi_;
      }
      break;
    }
    case kFrequencyEstimator: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.frequency_estimator_;
      }
      break;
    }
    case kUserDefinedProgram: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.user_defined_program_;
      }
      break;
    }
    case kAssign: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.parameters_.assign_;
      }
      break;
    }
    case PARAMETERS_NOT_SET: {
      break;
    }
  }
  _impl_._oneof_case_[0] = PARAMETERS_NOT_SET;
}


void OptimizationParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.OptimizationParameters)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaForAllocation() == nullptr && _impl_.clipping_limits_ != nullptr) {
    delete _impl_.clipping_limits_;
  }
  _impl_.clipping_limits_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.gradient_clipping_limits_ != nullptr) {
    delete _impl_.gradient_clipping_limits_;
  }
  _impl_.gradient_clipping_limits_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.learning_rate_ != nullptr) {
    delete _impl_.learning_rate_;
  }
  _impl_.learning_rate_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.hot_id_replication_configuration_ != nullptr) {
    delete _impl_.hot_id_replication_configuration_;
  }
  _impl_.hot_id_replication_configuration_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.simulated_quantization_ != nullptr) {
    delete _impl_.simulated_quantization_;
  }
  _impl_.simulated_quantization_ = nullptr;
  ::memset(&_impl_.weight_decay_factor_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.low_dimensional_packing_status_) -
      reinterpret_cast<char*>(&_impl_.weight_decay_factor_)) + sizeof(_impl_.low_dimensional_packing_status_));
  clear_parameters();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* OptimizationParameters::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .tensorflow.tpu.ClippingLimits clipping_limits = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_clipping_limits(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.AdagradParameters adagrad = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr = ctx->ParseMessage(_internal_mutable_adagrad(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.StochasticGradientDescentParameters stochastic_gradient_descent = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
          ptr = ctx->ParseMessage(_internal_mutable_stochastic_gradient_descent(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.FtrlParameters ftrl = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 42)) {
          ptr = ctx->ParseMessage(_internal_mutable_ftrl(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.AdamParameters adam = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 50)) {
          ptr = ctx->ParseMessage(_internal_mutable_adam(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.ClippingLimits gradient_clipping_limits = 7;
      case 7:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 58)) {
          ptr = ctx->ParseMessage(_internal_mutable_gradient_clipping_limits(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.MomentumParameters momentum = 8;
      case 8:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 66)) {
          ptr = ctx->ParseMessage(_internal_mutable_momentum(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.RmsPropParameters rms_prop = 9;
      case 9:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 74)) {
          ptr = ctx->ParseMessage(_internal_mutable_rms_prop(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.CenteredRmsPropParameters centered_rms_prop = 10;
      case 10:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 82)) {
          ptr = ctx->ParseMessage(_internal_mutable_centered_rms_prop(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.MdlAdagradLightParameters mdl_adagrad_light = 11;
      case 11:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 90)) {
          ptr = ctx->ParseMessage(_internal_mutable_mdl_adagrad_light(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.AdadeltaParameters adadelta = 12;
      case 12:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 98)) {
          ptr = ctx->ParseMessage(_internal_mutable_adadelta(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.LearningRate learning_rate = 13;
      case 13:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 106)) {
          ptr = ctx->ParseMessage(_internal_mutable_learning_rate(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.ProximalAdagradParameters proximal_adagrad = 14;
      case 14:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 114)) {
          ptr = ctx->ParseMessage(_internal_mutable_proximal_adagrad(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // float weight_decay_factor = 16;
      case 16:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 133)) {
          _impl_.weight_decay_factor_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.GradientAccumulationStatus.Status gradient_accumulation_status = 17;
      case 17:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 136)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_gradient_accumulation_status(static_cast<::tensorflow::tpu::GradientAccumulationStatus_Status>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.HotIdReplicationConfiguration hot_id_replication_configuration = 18;
      case 18:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 146)) {
          ptr = ctx->ParseMessage(_internal_mutable_hot_id_replication_configuration(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.BoundedAdagradParameters bounded_adagrad = 19;
      case 19:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 154)) {
          ptr = ctx->ParseMessage(_internal_mutable_bounded_adagrad(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.OnlineYogiParameters online_yogi = 20;
      case 20:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 162)) {
          ptr = ctx->ParseMessage(_internal_mutable_online_yogi(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.ProximalYogiParameters proximal_yogi = 21;
      case 21:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 170)) {
          ptr = ctx->ParseMessage(_internal_mutable_proximal_yogi(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // bool multiply_weight_decay_factor_by_learning_rate = 22;
      case 22:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 176)) {
          _impl_.multiply_weight_decay_factor_by_learning_rate_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.FrequencyEstimatorParameters frequency_estimator = 23;
      case 23:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 186)) {
          ptr = ctx->ParseMessage(_internal_mutable_frequency_estimator(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.UserDefinedProgramParameters user_defined_program = 24;
      case 24:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 194)) {
          ptr = ctx->ParseMessage(_internal_mutable_user_defined_program(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.AssignParameters assign = 25;
      case 25:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 202)) {
          ptr = ctx->ParseMessage(_internal_mutable_assign(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.AdagradMomentumParameters adagrad_momentum = 26;
      case 26:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 210)) {
          ptr = ctx->ParseMessage(_internal_mutable_adagrad_momentum(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.SimulatedQuantization simulated_quantization = 27;
      case 27:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 218)) {
          ptr = ctx->ParseMessage(_internal_mutable_simulated_quantization(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.LowDimensionalPackingStatus.Status low_dimensional_packing_status = 28;
      case 28:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 224)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_low_dimensional_packing_status(static_cast<::tensorflow::tpu::LowDimensionalPackingStatus_Status>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.LionParameters lion = 29;
      case 29:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 234)) {
          ptr = ctx->ParseMessage(_internal_mutable_lion(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* OptimizationParameters::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.OptimizationParameters)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.tpu.ClippingLimits clipping_limits = 2;
  if (this->_internal_has_clipping_limits()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::clipping_limits(this),
        _Internal::clipping_limits(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.AdagradParameters adagrad = 3;
  if (_internal_has_adagrad()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(3, _Internal::adagrad(this),
        _Internal::adagrad(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.StochasticGradientDescentParameters stochastic_gradient_descent = 4;
  if (_internal_has_stochastic_gradient_descent()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(4, _Internal::stochastic_gradient_descent(this),
        _Internal::stochastic_gradient_descent(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.FtrlParameters ftrl = 5;
  if (_internal_has_ftrl()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(5, _Internal::ftrl(this),
        _Internal::ftrl(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.AdamParameters adam = 6;
  if (_internal_has_adam()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(6, _Internal::adam(this),
        _Internal::adam(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.ClippingLimits gradient_clipping_limits = 7;
  if (this->_internal_has_gradient_clipping_limits()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(7, _Internal::gradient_clipping_limits(this),
        _Internal::gradient_clipping_limits(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.MomentumParameters momentum = 8;
  if (_internal_has_momentum()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(8, _Internal::momentum(this),
        _Internal::momentum(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.RmsPropParameters rms_prop = 9;
  if (_internal_has_rms_prop()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(9, _Internal::rms_prop(this),
        _Internal::rms_prop(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.CenteredRmsPropParameters centered_rms_prop = 10;
  if (_internal_has_centered_rms_prop()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(10, _Internal::centered_rms_prop(this),
        _Internal::centered_rms_prop(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.MdlAdagradLightParameters mdl_adagrad_light = 11;
  if (_internal_has_mdl_adagrad_light()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(11, _Internal::mdl_adagrad_light(this),
        _Internal::mdl_adagrad_light(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.AdadeltaParameters adadelta = 12;
  if (_internal_has_adadelta()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(12, _Internal::adadelta(this),
        _Internal::adadelta(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.LearningRate learning_rate = 13;
  if (this->_internal_has_learning_rate()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(13, _Internal::learning_rate(this),
        _Internal::learning_rate(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.ProximalAdagradParameters proximal_adagrad = 14;
  if (_internal_has_proximal_adagrad()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(14, _Internal::proximal_adagrad(this),
        _Internal::proximal_adagrad(this).GetCachedSize(), target, stream);
  }

  // float weight_decay_factor = 16;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_weight_decay_factor = this->_internal_weight_decay_factor();
  uint32_t raw_weight_decay_factor;
  memcpy(&raw_weight_decay_factor, &tmp_weight_decay_factor, sizeof(tmp_weight_decay_factor));
  if (raw_weight_decay_factor != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(16, this->_internal_weight_decay_factor(), target);
  }

  // .tensorflow.tpu.GradientAccumulationStatus.Status gradient_accumulation_status = 17;
  if (this->_internal_gradient_accumulation_status() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      17, this->_internal_gradient_accumulation_status(), target);
  }

  // .tensorflow.tpu.HotIdReplicationConfiguration hot_id_replication_configuration = 18;
  if (this->_internal_has_hot_id_replication_configuration()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(18, _Internal::hot_id_replication_configuration(this),
        _Internal::hot_id_replication_configuration(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.BoundedAdagradParameters bounded_adagrad = 19;
  if (_internal_has_bounded_adagrad()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(19, _Internal::bounded_adagrad(this),
        _Internal::bounded_adagrad(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.OnlineYogiParameters online_yogi = 20;
  if (_internal_has_online_yogi()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(20, _Internal::online_yogi(this),
        _Internal::online_yogi(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.ProximalYogiParameters proximal_yogi = 21;
  if (_internal_has_proximal_yogi()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(21, _Internal::proximal_yogi(this),
        _Internal::proximal_yogi(this).GetCachedSize(), target, stream);
  }

  // bool multiply_weight_decay_factor_by_learning_rate = 22;
  if (this->_internal_multiply_weight_decay_factor_by_learning_rate() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(22, this->_internal_multiply_weight_decay_factor_by_learning_rate(), target);
  }

  // .tensorflow.tpu.FrequencyEstimatorParameters frequency_estimator = 23;
  if (_internal_has_frequency_estimator()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(23, _Internal::frequency_estimator(this),
        _Internal::frequency_estimator(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.UserDefinedProgramParameters user_defined_program = 24;
  if (_internal_has_user_defined_program()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(24, _Internal::user_defined_program(this),
        _Internal::user_defined_program(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.AssignParameters assign = 25;
  if (_internal_has_assign()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(25, _Internal::assign(this),
        _Internal::assign(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.AdagradMomentumParameters adagrad_momentum = 26;
  if (_internal_has_adagrad_momentum()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(26, _Internal::adagrad_momentum(this),
        _Internal::adagrad_momentum(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.SimulatedQuantization simulated_quantization = 27;
  if (this->_internal_has_simulated_quantization()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(27, _Internal::simulated_quantization(this),
        _Internal::simulated_quantization(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.LowDimensionalPackingStatus.Status low_dimensional_packing_status = 28;
  if (this->_internal_low_dimensional_packing_status() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      28, this->_internal_low_dimensional_packing_status(), target);
  }

  // .tensorflow.tpu.LionParameters lion = 29;
  if (_internal_has_lion()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(29, _Internal::lion(this),
        _Internal::lion(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.OptimizationParameters)
  return target;
}

size_t OptimizationParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.OptimizationParameters)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.tpu.ClippingLimits clipping_limits = 2;
  if (this->_internal_has_clipping_limits()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.clipping_limits_);
  }

  // .tensorflow.tpu.ClippingLimits gradient_clipping_limits = 7;
  if (this->_internal_has_gradient_clipping_limits()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.gradient_clipping_limits_);
  }

  // .tensorflow.tpu.LearningRate learning_rate = 13;
  if (this->_internal_has_learning_rate()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.learning_rate_);
  }

  // .tensorflow.tpu.HotIdReplicationConfiguration hot_id_replication_configuration = 18;
  if (this->_internal_has_hot_id_replication_configuration()) {
    total_size += 2 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.hot_id_replication_configuration_);
  }

  // .tensorflow.tpu.SimulatedQuantization simulated_quantization = 27;
  if (this->_internal_has_simulated_quantization()) {
    total_size += 2 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.simulated_quantization_);
  }

  // float weight_decay_factor = 16;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_weight_decay_factor = this->_internal_weight_decay_factor();
  uint32_t raw_weight_decay_factor;
  memcpy(&raw_weight_decay_factor, &tmp_weight_decay_factor, sizeof(tmp_weight_decay_factor));
  if (raw_weight_decay_factor != 0) {
    total_size += 2 + 4;
  }

  // .tensorflow.tpu.GradientAccumulationStatus.Status gradient_accumulation_status = 17;
  if (this->_internal_gradient_accumulation_status() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_gradient_accumulation_status());
  }

  // bool multiply_weight_decay_factor_by_learning_rate = 22;
  if (this->_internal_multiply_weight_decay_factor_by_learning_rate() != 0) {
    total_size += 2 + 1;
  }

  // .tensorflow.tpu.LowDimensionalPackingStatus.Status low_dimensional_packing_status = 28;
  if (this->_internal_low_dimensional_packing_status() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_low_dimensional_packing_status());
  }

  switch (parameters_case()) {
    // .tensorflow.tpu.AdagradParameters adagrad = 3;
    case kAdagrad: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.adagrad_);
      break;
    }
    // .tensorflow.tpu.AdagradMomentumParameters adagrad_momentum = 26;
    case kAdagradMomentum: {
      total_size += 2 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.adagrad_momentum_);
      break;
    }
    // .tensorflow.tpu.BoundedAdagradParameters bounded_adagrad = 19;
    case kBoundedAdagrad: {
      total_size += 2 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.bounded_adagrad_);
      break;
    }
    // .tensorflow.tpu.StochasticGradientDescentParameters stochastic_gradient_descent = 4;
    case kStochasticGradientDescent: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.stochastic_gradient_descent_);
      break;
    }
    // .tensorflow.tpu.FtrlParameters ftrl = 5;
    case kFtrl: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.ftrl_);
      break;
    }
    // .tensorflow.tpu.AdamParameters adam = 6;
    case kAdam: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.adam_);
      break;
    }
    // .tensorflow.tpu.MomentumParameters momentum = 8;
    case kMomentum: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.momentum_);
      break;
    }
    // .tensorflow.tpu.LionParameters lion = 29;
    case kLion: {
      total_size += 2 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.lion_);
      break;
    }
    // .tensorflow.tpu.RmsPropParameters rms_prop = 9;
    case kRmsProp: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.rms_prop_);
      break;
    }
    // .tensorflow.tpu.CenteredRmsPropParameters centered_rms_prop = 10;
    case kCenteredRmsProp: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.centered_rms_prop_);
      break;
    }
    // .tensorflow.tpu.MdlAdagradLightParameters mdl_adagrad_light = 11;
    case kMdlAdagradLight: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.mdl_adagrad_light_);
      break;
    }
    // .tensorflow.tpu.AdadeltaParameters adadelta = 12;
    case kAdadelta: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.adadelta_);
      break;
    }
    // .tensorflow.tpu.ProximalAdagradParameters proximal_adagrad = 14;
    case kProximalAdagrad: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.proximal_adagrad_);
      break;
    }
    // .tensorflow.tpu.OnlineYogiParameters online_yogi = 20;
    case kOnlineYogi: {
      total_size += 2 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.online_yogi_);
      break;
    }
    // .tensorflow.tpu.ProximalYogiParameters proximal_yogi = 21;
    case kProximalYogi: {
      total_size += 2 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.proximal_yogi_);
      break;
    }
    // .tensorflow.tpu.FrequencyEstimatorParameters frequency_estimator = 23;
    case kFrequencyEstimator: {
      total_size += 2 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.frequency_estimator_);
      break;
    }
    // .tensorflow.tpu.UserDefinedProgramParameters user_defined_program = 24;
    case kUserDefinedProgram: {
      total_size += 2 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.user_defined_program_);
      break;
    }
    // .tensorflow.tpu.AssignParameters assign = 25;
    case kAssign: {
      total_size += 2 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.parameters_.assign_);
      break;
    }
    case PARAMETERS_NOT_SET: {
      break;
    }
  }
  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData OptimizationParameters::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    OptimizationParameters::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*OptimizationParameters::GetClassData() const { return &_class_data_; }


void OptimizationParameters::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<OptimizationParameters*>(&to_msg);
  auto& from = static_cast<const OptimizationParameters&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.OptimizationParameters)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_has_clipping_limits()) {
    _this->_internal_mutable_clipping_limits()->::tensorflow::tpu::ClippingLimits::MergeFrom(
        from._internal_clipping_limits());
  }
  if (from._internal_has_gradient_clipping_limits()) {
    _this->_internal_mutable_gradient_clipping_limits()->::tensorflow::tpu::ClippingLimits::MergeFrom(
        from._internal_gradient_clipping_limits());
  }
  if (from._internal_has_learning_rate()) {
    _this->_internal_mutable_learning_rate()->::tensorflow::tpu::LearningRate::MergeFrom(
        from._internal_learning_rate());
  }
  if (from._internal_has_hot_id_replication_configuration()) {
    _this->_internal_mutable_hot_id_replication_configuration()->::tensorflow::tpu::HotIdReplicationConfiguration::MergeFrom(
        from._internal_hot_id_replication_configuration());
  }
  if (from._internal_has_simulated_quantization()) {
    _this->_internal_mutable_simulated_quantization()->::tensorflow::tpu::SimulatedQuantization::MergeFrom(
        from._internal_simulated_quantization());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_weight_decay_factor = from._internal_weight_decay_factor();
  uint32_t raw_weight_decay_factor;
  memcpy(&raw_weight_decay_factor, &tmp_weight_decay_factor, sizeof(tmp_weight_decay_factor));
  if (raw_weight_decay_factor != 0) {
    _this->_internal_set_weight_decay_factor(from._internal_weight_decay_factor());
  }
  if (from._internal_gradient_accumulation_status() != 0) {
    _this->_internal_set_gradient_accumulation_status(from._internal_gradient_accumulation_status());
  }
  if (from._internal_multiply_weight_decay_factor_by_learning_rate() != 0) {
    _this->_internal_set_multiply_weight_decay_factor_by_learning_rate(from._internal_multiply_weight_decay_factor_by_learning_rate());
  }
  if (from._internal_low_dimensional_packing_status() != 0) {
    _this->_internal_set_low_dimensional_packing_status(from._internal_low_dimensional_packing_status());
  }
  switch (from.parameters_case()) {
    case kAdagrad: {
      _this->_internal_mutable_adagrad()->::tensorflow::tpu::AdagradParameters::MergeFrom(
          from._internal_adagrad());
      break;
    }
    case kAdagradMomentum: {
      _this->_internal_mutable_adagrad_momentum()->::tensorflow::tpu::AdagradMomentumParameters::MergeFrom(
          from._internal_adagrad_momentum());
      break;
    }
    case kBoundedAdagrad: {
      _this->_internal_mutable_bounded_adagrad()->::tensorflow::tpu::BoundedAdagradParameters::MergeFrom(
          from._internal_bounded_adagrad());
      break;
    }
    case kStochasticGradientDescent: {
      _this->_internal_mutable_stochastic_gradient_descent()->::tensorflow::tpu::StochasticGradientDescentParameters::MergeFrom(
          from._internal_stochastic_gradient_descent());
      break;
    }
    case kFtrl: {
      _this->_internal_mutable_ftrl()->::tensorflow::tpu::FtrlParameters::MergeFrom(
          from._internal_ftrl());
      break;
    }
    case kAdam: {
      _this->_internal_mutable_adam()->::tensorflow::tpu::AdamParameters::MergeFrom(
          from._internal_adam());
      break;
    }
    case kMomentum: {
      _this->_internal_mutable_momentum()->::tensorflow::tpu::MomentumParameters::MergeFrom(
          from._internal_momentum());
      break;
    }
    case kLion: {
      _this->_internal_mutable_lion()->::tensorflow::tpu::LionParameters::MergeFrom(
          from._internal_lion());
      break;
    }
    case kRmsProp: {
      _this->_internal_mutable_rms_prop()->::tensorflow::tpu::RmsPropParameters::MergeFrom(
          from._internal_rms_prop());
      break;
    }
    case kCenteredRmsProp: {
      _this->_internal_mutable_centered_rms_prop()->::tensorflow::tpu::CenteredRmsPropParameters::MergeFrom(
          from._internal_centered_rms_prop());
      break;
    }
    case kMdlAdagradLight: {
      _this->_internal_mutable_mdl_adagrad_light()->::tensorflow::tpu::MdlAdagradLightParameters::MergeFrom(
          from._internal_mdl_adagrad_light());
      break;
    }
    case kAdadelta: {
      _this->_internal_mutable_adadelta()->::tensorflow::tpu::AdadeltaParameters::MergeFrom(
          from._internal_adadelta());
      break;
    }
    case kProximalAdagrad: {
      _this->_internal_mutable_proximal_adagrad()->::tensorflow::tpu::ProximalAdagradParameters::MergeFrom(
          from._internal_proximal_adagrad());
      break;
    }
    case kOnlineYogi: {
      _this->_internal_mutable_online_yogi()->::tensorflow::tpu::OnlineYogiParameters::MergeFrom(
          from._internal_online_yogi());
      break;
    }
    case kProximalYogi: {
      _this->_internal_mutable_proximal_yogi()->::tensorflow::tpu::ProximalYogiParameters::MergeFrom(
          from._internal_proximal_yogi());
      break;
    }
    case kFrequencyEstimator: {
      _this->_internal_mutable_frequency_estimator()->::tensorflow::tpu::FrequencyEstimatorParameters::MergeFrom(
          from._internal_frequency_estimator());
      break;
    }
    case kUserDefinedProgram: {
      _this->_internal_mutable_user_defined_program()->::tensorflow::tpu::UserDefinedProgramParameters::MergeFrom(
          from._internal_user_defined_program());
      break;
    }
    case kAssign: {
      _this->_internal_mutable_assign()->::tensorflow::tpu::AssignParameters::MergeFrom(
          from._internal_assign());
      break;
    }
    case PARAMETERS_NOT_SET: {
      break;
    }
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void OptimizationParameters::CopyFrom(const OptimizationParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.OptimizationParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool OptimizationParameters::IsInitialized() const {
  return true;
}

void OptimizationParameters::InternalSwap(OptimizationParameters* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(OptimizationParameters, _impl_.low_dimensional_packing_status_)
      + sizeof(OptimizationParameters::_impl_.low_dimensional_packing_status_)
      - PROTOBUF_FIELD_OFFSET(OptimizationParameters, _impl_.clipping_limits_)>(
          reinterpret_cast<char*>(&_impl_.clipping_limits_),
          reinterpret_cast<char*>(&other->_impl_.clipping_limits_));
  swap(_impl_.parameters_, other->_impl_.parameters_);
  swap(_impl_._oneof_case_[0], other->_impl_._oneof_case_[0]);
}

::PROTOBUF_NAMESPACE_ID::Metadata OptimizationParameters::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[25]);
}

// ===================================================================

class StateVariableSpecification_UserDefined::_Internal {
 public:
};

StateVariableSpecification_UserDefined::StateVariableSpecification_UserDefined(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase(arena, is_message_owned) {
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.StateVariableSpecification.UserDefined)
}
StateVariableSpecification_UserDefined::StateVariableSpecification_UserDefined(const StateVariableSpecification_UserDefined& from)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase() {
  StateVariableSpecification_UserDefined* const _this = this; (void)_this;
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.StateVariableSpecification.UserDefined)
}





const ::PROTOBUF_NAMESPACE_ID::Message::ClassData StateVariableSpecification_UserDefined::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::CopyImpl,
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::MergeImpl,
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*StateVariableSpecification_UserDefined::GetClassData() const { return &_class_data_; }







::PROTOBUF_NAMESPACE_ID::Metadata StateVariableSpecification_UserDefined::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[26]);
}

// ===================================================================

class StateVariableSpecification_FillWithConstant::_Internal {
 public:
};

StateVariableSpecification_FillWithConstant::StateVariableSpecification_FillWithConstant(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.StateVariableSpecification.FillWithConstant)
}
StateVariableSpecification_FillWithConstant::StateVariableSpecification_FillWithConstant(const StateVariableSpecification_FillWithConstant& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  StateVariableSpecification_FillWithConstant* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.initial_value_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _this->_impl_.initial_value_ = from._impl_.initial_value_;
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.StateVariableSpecification.FillWithConstant)
}

inline void StateVariableSpecification_FillWithConstant::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.initial_value_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

StateVariableSpecification_FillWithConstant::~StateVariableSpecification_FillWithConstant() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.StateVariableSpecification.FillWithConstant)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void StateVariableSpecification_FillWithConstant::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void StateVariableSpecification_FillWithConstant::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void StateVariableSpecification_FillWithConstant::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.StateVariableSpecification.FillWithConstant)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.initial_value_ = 0;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* StateVariableSpecification_FillWithConstant::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // double initial_value = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 9)) {
          _impl_.initial_value_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<double>(ptr);
          ptr += sizeof(double);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* StateVariableSpecification_FillWithConstant::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.StateVariableSpecification.FillWithConstant)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // double initial_value = 1;
  static_assert(sizeof(uint64_t) == sizeof(double), "Code assumes uint64_t and double are the same size.");
  double tmp_initial_value = this->_internal_initial_value();
  uint64_t raw_initial_value;
  memcpy(&raw_initial_value, &tmp_initial_value, sizeof(tmp_initial_value));
  if (raw_initial_value != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteDoubleToArray(1, this->_internal_initial_value(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.StateVariableSpecification.FillWithConstant)
  return target;
}

size_t StateVariableSpecification_FillWithConstant::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.StateVariableSpecification.FillWithConstant)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // double initial_value = 1;
  static_assert(sizeof(uint64_t) == sizeof(double), "Code assumes uint64_t and double are the same size.");
  double tmp_initial_value = this->_internal_initial_value();
  uint64_t raw_initial_value;
  memcpy(&raw_initial_value, &tmp_initial_value, sizeof(tmp_initial_value));
  if (raw_initial_value != 0) {
    total_size += 1 + 8;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData StateVariableSpecification_FillWithConstant::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    StateVariableSpecification_FillWithConstant::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*StateVariableSpecification_FillWithConstant::GetClassData() const { return &_class_data_; }


void StateVariableSpecification_FillWithConstant::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<StateVariableSpecification_FillWithConstant*>(&to_msg);
  auto& from = static_cast<const StateVariableSpecification_FillWithConstant&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.StateVariableSpecification.FillWithConstant)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  static_assert(sizeof(uint64_t) == sizeof(double), "Code assumes uint64_t and double are the same size.");
  double tmp_initial_value = from._internal_initial_value();
  uint64_t raw_initial_value;
  memcpy(&raw_initial_value, &tmp_initial_value, sizeof(tmp_initial_value));
  if (raw_initial_value != 0) {
    _this->_internal_set_initial_value(from._internal_initial_value());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void StateVariableSpecification_FillWithConstant::CopyFrom(const StateVariableSpecification_FillWithConstant& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.StateVariableSpecification.FillWithConstant)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool StateVariableSpecification_FillWithConstant::IsInitialized() const {
  return true;
}

void StateVariableSpecification_FillWithConstant::InternalSwap(StateVariableSpecification_FillWithConstant* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_.initial_value_, other->_impl_.initial_value_);
}

::PROTOBUF_NAMESPACE_ID::Metadata StateVariableSpecification_FillWithConstant::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[27]);
}

// ===================================================================

class StateVariableSpecification::_Internal {
 public:
  static const ::tensorflow::tpu::StateVariableSpecification_UserDefined& user_defined(const StateVariableSpecification* msg);
  static const ::tensorflow::tpu::StateVariableSpecification_FillWithConstant& fill_with_constant(const StateVariableSpecification* msg);
};

const ::tensorflow::tpu::StateVariableSpecification_UserDefined&
StateVariableSpecification::_Internal::user_defined(const StateVariableSpecification* msg) {
  return *msg->_impl_.usage_.user_defined_;
}
const ::tensorflow::tpu::StateVariableSpecification_FillWithConstant&
StateVariableSpecification::_Internal::fill_with_constant(const StateVariableSpecification* msg) {
  return *msg->_impl_.usage_.fill_with_constant_;
}
void StateVariableSpecification::set_allocated_user_defined(::tensorflow::tpu::StateVariableSpecification_UserDefined* user_defined) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_usage();
  if (user_defined) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(user_defined);
    if (message_arena != submessage_arena) {
      user_defined = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, user_defined, submessage_arena);
    }
    set_has_user_defined();
    _impl_.usage_.user_defined_ = user_defined;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.StateVariableSpecification.user_defined)
}
void StateVariableSpecification::set_allocated_fill_with_constant(::tensorflow::tpu::StateVariableSpecification_FillWithConstant* fill_with_constant) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_usage();
  if (fill_with_constant) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(fill_with_constant);
    if (message_arena != submessage_arena) {
      fill_with_constant = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, fill_with_constant, submessage_arena);
    }
    set_has_fill_with_constant();
    _impl_.usage_.fill_with_constant_ = fill_with_constant;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.tpu.StateVariableSpecification.fill_with_constant)
}
StateVariableSpecification::StateVariableSpecification(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.tpu.StateVariableSpecification)
}
StateVariableSpecification::StateVariableSpecification(const StateVariableSpecification& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  StateVariableSpecification* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.name_){}
    , decltype(_impl_.usage_){}
    , /*decltype(_impl_._cached_size_)*/{}
    , /*decltype(_impl_._oneof_case_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _impl_.name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_name().empty()) {
    _this->_impl_.name_.Set(from._internal_name(), 
      _this->GetArenaForAllocation());
  }
  clear_has_usage();
  switch (from.usage_case()) {
    case kUserDefined: {
      _this->_internal_mutable_user_defined()->::tensorflow::tpu::StateVariableSpecification_UserDefined::MergeFrom(
          from._internal_user_defined());
      break;
    }
    case kFillWithConstant: {
      _this->_internal_mutable_fill_with_constant()->::tensorflow::tpu::StateVariableSpecification_FillWithConstant::MergeFrom(
          from._internal_fill_with_constant());
      break;
    }
    case USAGE_NOT_SET: {
      break;
    }
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.tpu.StateVariableSpecification)
}

inline void StateVariableSpecification::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.name_){}
    , decltype(_impl_.usage_){}
    , /*decltype(_impl_._cached_size_)*/{}
    , /*decltype(_impl_._oneof_case_)*/{}
  };
  _impl_.name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  clear_has_usage();
}

StateVariableSpecification::~StateVariableSpecification() {
  // @@protoc_insertion_point(destructor:tensorflow.tpu.StateVariableSpecification)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void StateVariableSpecification::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.name_.Destroy();
  if (has_usage()) {
    clear_usage();
  }
}

void StateVariableSpecification::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void StateVariableSpecification::clear_usage() {
// @@protoc_insertion_point(one_of_clear_start:tensorflow.tpu.StateVariableSpecification)
  switch (usage_case()) {
    case kUserDefined: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.usage_.user_defined_;
      }
      break;
    }
    case kFillWithConstant: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.usage_.fill_with_constant_;
      }
      break;
    }
    case USAGE_NOT_SET: {
      break;
    }
  }
  _impl_._oneof_case_[0] = USAGE_NOT_SET;
}


void StateVariableSpecification::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.tpu.StateVariableSpecification)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.name_.ClearToEmpty();
  clear_usage();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* StateVariableSpecification::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // string name = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_name();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "tensorflow.tpu.StateVariableSpecification.name"));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.StateVariableSpecification.UserDefined user_defined = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_user_defined(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.tpu.StateVariableSpecification.FillWithConstant fill_with_constant = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr = ctx->ParseMessage(_internal_mutable_fill_with_constant(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* StateVariableSpecification::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.tpu.StateVariableSpecification)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // string name = 1;
  if (!this->_internal_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_name().data(), static_cast<int>(this->_internal_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.tpu.StateVariableSpecification.name");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_name(), target);
  }

  // .tensorflow.tpu.StateVariableSpecification.UserDefined user_defined = 2;
  if (_internal_has_user_defined()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::user_defined(this),
        _Internal::user_defined(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.tpu.StateVariableSpecification.FillWithConstant fill_with_constant = 3;
  if (_internal_has_fill_with_constant()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(3, _Internal::fill_with_constant(this),
        _Internal::fill_with_constant(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.tpu.StateVariableSpecification)
  return target;
}

size_t StateVariableSpecification::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.tpu.StateVariableSpecification)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // string name = 1;
  if (!this->_internal_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_name());
  }

  switch (usage_case()) {
    // .tensorflow.tpu.StateVariableSpecification.UserDefined user_defined = 2;
    case kUserDefined: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.usage_.user_defined_);
      break;
    }
    // .tensorflow.tpu.StateVariableSpecification.FillWithConstant fill_with_constant = 3;
    case kFillWithConstant: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.usage_.fill_with_constant_);
      break;
    }
    case USAGE_NOT_SET: {
      break;
    }
  }
  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData StateVariableSpecification::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    StateVariableSpecification::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*StateVariableSpecification::GetClassData() const { return &_class_data_; }


void StateVariableSpecification::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<StateVariableSpecification*>(&to_msg);
  auto& from = static_cast<const StateVariableSpecification&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.tpu.StateVariableSpecification)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_name().empty()) {
    _this->_internal_set_name(from._internal_name());
  }
  switch (from.usage_case()) {
    case kUserDefined: {
      _this->_internal_mutable_user_defined()->::tensorflow::tpu::StateVariableSpecification_UserDefined::MergeFrom(
          from._internal_user_defined());
      break;
    }
    case kFillWithConstant: {
      _this->_internal_mutable_fill_with_constant()->::tensorflow::tpu::StateVariableSpecification_FillWithConstant::MergeFrom(
          from._internal_fill_with_constant());
      break;
    }
    case USAGE_NOT_SET: {
      break;
    }
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void StateVariableSpecification::CopyFrom(const StateVariableSpecification& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.tpu.StateVariableSpecification)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool StateVariableSpecification::IsInitialized() const {
  return true;
}

void StateVariableSpecification::InternalSwap(StateVariableSpecification* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.name_, lhs_arena,
      &other->_impl_.name_, rhs_arena
  );
  swap(_impl_.usage_, other->_impl_.usage_);
  swap(_impl_._oneof_case_[0], other->_impl_._oneof_case_[0]);
}

::PROTOBUF_NAMESPACE_ID::Metadata StateVariableSpecification::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2ftpu_2foptimization_5fparameters_2eproto[28]);
}

// @@protoc_insertion_point(namespace_scope)
}  // namespace tpu
}  // namespace tensorflow
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::ClippingLimits*
Arena::CreateMaybeMessage< ::tensorflow::tpu::ClippingLimits >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::ClippingLimits >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::SimulatedQuantization*
Arena::CreateMaybeMessage< ::tensorflow::tpu::SimulatedQuantization >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::SimulatedQuantization >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::DynamicLearningRate*
Arena::CreateMaybeMessage< ::tensorflow::tpu::DynamicLearningRate >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::DynamicLearningRate >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::LearningRate*
Arena::CreateMaybeMessage< ::tensorflow::tpu::LearningRate >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::LearningRate >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::AdagradParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::AdagradParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::AdagradParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::AdagradMomentumParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::AdagradMomentumParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::AdagradMomentumParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::BoundedAdagradParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::BoundedAdagradParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::BoundedAdagradParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::StochasticGradientDescentParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::StochasticGradientDescentParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::StochasticGradientDescentParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::FtrlParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::FtrlParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::FtrlParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::AdamParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::AdamParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::AdamParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::MomentumParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::MomentumParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::MomentumParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::LionParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::LionParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::LionParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::RmsPropParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::RmsPropParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::RmsPropParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::CenteredRmsPropParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::CenteredRmsPropParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::CenteredRmsPropParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::MdlAdagradLightParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::MdlAdagradLightParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::MdlAdagradLightParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::AdadeltaParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::AdadeltaParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::AdadeltaParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::ProximalAdagradParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::ProximalAdagradParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::ProximalAdagradParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::OnlineYogiParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::OnlineYogiParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::OnlineYogiParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::ProximalYogiParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::ProximalYogiParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::ProximalYogiParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::FrequencyEstimatorParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::FrequencyEstimatorParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::FrequencyEstimatorParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::UserDefinedProgramParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::UserDefinedProgramParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::UserDefinedProgramParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::AssignParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::AssignParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::AssignParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::GradientAccumulationStatus*
Arena::CreateMaybeMessage< ::tensorflow::tpu::GradientAccumulationStatus >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::GradientAccumulationStatus >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::LowDimensionalPackingStatus*
Arena::CreateMaybeMessage< ::tensorflow::tpu::LowDimensionalPackingStatus >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::LowDimensionalPackingStatus >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::HotIdReplicationConfiguration*
Arena::CreateMaybeMessage< ::tensorflow::tpu::HotIdReplicationConfiguration >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::HotIdReplicationConfiguration >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::OptimizationParameters*
Arena::CreateMaybeMessage< ::tensorflow::tpu::OptimizationParameters >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::OptimizationParameters >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::StateVariableSpecification_UserDefined*
Arena::CreateMaybeMessage< ::tensorflow::tpu::StateVariableSpecification_UserDefined >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::StateVariableSpecification_UserDefined >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::StateVariableSpecification_FillWithConstant*
Arena::CreateMaybeMessage< ::tensorflow::tpu::StateVariableSpecification_FillWithConstant >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::StateVariableSpecification_FillWithConstant >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::tpu::StateVariableSpecification*
Arena::CreateMaybeMessage< ::tensorflow::tpu::StateVariableSpecification >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::tpu::StateVariableSpecification >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
