// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/rewriter_config.proto

#include "tensorflow/core/protobuf/rewriter_config.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG

namespace _pb = ::PROTOBUF_NAMESPACE_ID;
namespace _pbi = _pb::internal;

namespace tensorflow {
PROTOBUF_CONSTEXPR AutoParallelOptions::AutoParallelOptions(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.enable_)*/false
  , /*decltype(_impl_.num_replicas_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct AutoParallelOptionsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR AutoParallelOptionsDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~AutoParallelOptionsDefaultTypeInternal() {}
  union {
    AutoParallelOptions _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 AutoParallelOptionsDefaultTypeInternal _AutoParallelOptions_default_instance_;
PROTOBUF_CONSTEXPR ScopedAllocatorOptions::ScopedAllocatorOptions(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.enable_op_)*/{}
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct ScopedAllocatorOptionsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR ScopedAllocatorOptionsDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~ScopedAllocatorOptionsDefaultTypeInternal() {}
  union {
    ScopedAllocatorOptions _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 ScopedAllocatorOptionsDefaultTypeInternal _ScopedAllocatorOptions_default_instance_;
PROTOBUF_CONSTEXPR RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse::RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse(
    ::_pbi::ConstantInitialized) {}
struct RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUseDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUseDefaultTypeInternal() {}
  union {
    RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUseDefaultTypeInternal _RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse_default_instance_;
PROTOBUF_CONSTEXPR RewriterConfig_CustomGraphOptimizer::RewriterConfig_CustomGraphOptimizer(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.parameter_map_)*/{::_pbi::ConstantInitialized()}
  , /*decltype(_impl_.name_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct RewriterConfig_CustomGraphOptimizerDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RewriterConfig_CustomGraphOptimizerDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~RewriterConfig_CustomGraphOptimizerDefaultTypeInternal() {}
  union {
    RewriterConfig_CustomGraphOptimizer _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RewriterConfig_CustomGraphOptimizerDefaultTypeInternal _RewriterConfig_CustomGraphOptimizer_default_instance_;
PROTOBUF_CONSTEXPR RewriterConfig::RewriterConfig(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.optimizers_)*/{}
  , /*decltype(_impl_.custom_optimizers_)*/{}
  , /*decltype(_impl_.memory_optimizer_target_node_name_scope_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.auto_parallel_)*/nullptr
  , /*decltype(_impl_.scoped_allocator_opts_)*/nullptr
  , /*decltype(_impl_.inter_optimizer_verifier_config_)*/nullptr
  , /*decltype(_impl_.post_optimization_verifier_config_)*/nullptr
  , /*decltype(_impl_.layout_optimizer_)*/0
  , /*decltype(_impl_.constant_folding_)*/0
  , /*decltype(_impl_.memory_optimization_)*/0
  , /*decltype(_impl_.arithmetic_optimization_)*/0
  , /*decltype(_impl_.dependency_optimization_)*/0
  , /*decltype(_impl_.loop_optimization_)*/0
  , /*decltype(_impl_.function_optimization_)*/0
  , /*decltype(_impl_.debug_stripper_)*/0
  , /*decltype(_impl_.meta_optimizer_iterations_)*/0
  , /*decltype(_impl_.shape_optimization_)*/0
  , /*decltype(_impl_.remapping_)*/0
  , /*decltype(_impl_.scoped_allocator_optimization_)*/0
  , /*decltype(_impl_.min_graph_nodes_)*/0
  , /*decltype(_impl_.pin_to_host_optimization_)*/0
  , /*decltype(_impl_.meta_optimizer_timeout_ms_)*/int64_t{0}
  , /*decltype(_impl_.disable_model_pruning_)*/false
  , /*decltype(_impl_.disable_meta_optimizer_)*/false
  , /*decltype(_impl_.disable_tfg_optimizer_)*/false
  , /*decltype(_impl_.experimental_disable_compressed_tensor_optimization_)*/false
  , /*decltype(_impl_.implementation_selector_)*/0
  , /*decltype(_impl_.auto_mixed_precision_)*/0
  , /*decltype(_impl_.common_subgraph_elimination_)*/0
  , /*decltype(_impl_.experimental_disable_folding_quantization_emulation_)*/false
  , /*decltype(_impl_.fail_on_optimizer_errors_)*/false
  , /*decltype(_impl_.auto_mixed_precision_mkl_)*/0
  , /*decltype(_impl_.use_plugin_optimizers_)*/0
  , /*decltype(_impl_.auto_mixed_precision_cpu_)*/0
  , /*decltype(_impl_.experimental_conditional_code_motion_)*/0
  , /*decltype(_impl_.auto_mixed_precision_onednn_bfloat16_)*/0
  , /*decltype(_impl_.cpu_layout_conversion_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct RewriterConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RewriterConfigDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~RewriterConfigDefaultTypeInternal() {}
  union {
    RewriterConfig _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RewriterConfigDefaultTypeInternal _RewriterConfig_default_instance_;
}  // namespace tensorflow
static ::_pb::Metadata file_level_metadata_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto[5];
static const ::_pb::EnumDescriptor* file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto[4];
static constexpr ::_pb::ServiceDescriptor const** file_level_service_descriptors_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto = nullptr;

const uint32_t TableStruct_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::AutoParallelOptions, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::AutoParallelOptions, _impl_.enable_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::AutoParallelOptions, _impl_.num_replicas_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::ScopedAllocatorOptions, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::ScopedAllocatorOptions, _impl_.enable_op_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse, _has_bits_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse, key_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse, value_),
  0,
  1,
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig_CustomGraphOptimizer, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig_CustomGraphOptimizer, _impl_.name_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig_CustomGraphOptimizer, _impl_.parameter_map_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.cpu_layout_conversion_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.layout_optimizer_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.constant_folding_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.shape_optimization_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.remapping_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.common_subgraph_elimination_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.arithmetic_optimization_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.dependency_optimization_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.loop_optimization_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.function_optimization_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.debug_stripper_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.disable_model_pruning_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.scoped_allocator_optimization_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.pin_to_host_optimization_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.implementation_selector_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.auto_mixed_precision_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.auto_mixed_precision_mkl_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.auto_mixed_precision_onednn_bfloat16_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.auto_mixed_precision_cpu_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.disable_meta_optimizer_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.disable_tfg_optimizer_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.use_plugin_optimizers_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.experimental_conditional_code_motion_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.meta_optimizer_iterations_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.min_graph_nodes_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.experimental_disable_compressed_tensor_optimization_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.experimental_disable_folding_quantization_emulation_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.memory_optimization_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.memory_optimizer_target_node_name_scope_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.meta_optimizer_timeout_ms_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.auto_parallel_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.fail_on_optimizer_errors_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.scoped_allocator_opts_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.optimizers_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.custom_optimizers_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.inter_optimizer_verifier_config_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::RewriterConfig, _impl_.post_optimization_verifier_config_),
};
static const ::_pbi::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, -1, sizeof(::tensorflow::AutoParallelOptions)},
  { 8, -1, -1, sizeof(::tensorflow::ScopedAllocatorOptions)},
  { 15, 23, -1, sizeof(::tensorflow::RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse)},
  { 25, -1, -1, sizeof(::tensorflow::RewriterConfig_CustomGraphOptimizer)},
  { 33, -1, -1, sizeof(::tensorflow::RewriterConfig)},
};

static const ::_pb::Message* const file_default_instances[] = {
  &::tensorflow::_AutoParallelOptions_default_instance_._instance,
  &::tensorflow::_ScopedAllocatorOptions_default_instance_._instance,
  &::tensorflow::_RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse_default_instance_._instance,
  &::tensorflow::_RewriterConfig_CustomGraphOptimizer_default_instance_._instance,
  &::tensorflow::_RewriterConfig_default_instance_._instance,
};

const char descriptor_table_protodef_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n.tensorflow/core/protobuf/rewriter_conf"
  "ig.proto\022\ntensorflow\032*tensorflow/core/fr"
  "amework/attr_value.proto\032.tensorflow/cor"
  "e/protobuf/verifier_config.proto\";\n\023Auto"
  "ParallelOptions\022\016\n\006enable\030\001 \001(\010\022\024\n\014num_r"
  "eplicas\030\002 \001(\005\"+\n\026ScopedAllocatorOptions\022"
  "\021\n\tenable_op\030\001 \003(\t\"\225\026\n\016RewriterConfig\022C\n"
  "\025cpu_layout_conversion\0302 \001(\0162$.tensorflo"
  "w.RewriterConfig.CpuLayout\022;\n\020layout_opt"
  "imizer\030\001 \001(\0162!.tensorflow.RewriterConfig"
  ".Toggle\022;\n\020constant_folding\030\003 \001(\0162!.tens"
  "orflow.RewriterConfig.Toggle\022=\n\022shape_op"
  "timization\030\r \001(\0162!.tensorflow.RewriterCo"
  "nfig.Toggle\0224\n\tremapping\030\016 \001(\0162!.tensorf"
  "low.RewriterConfig.Toggle\022F\n\033common_subg"
  "raph_elimination\030\030 \001(\0162!.tensorflow.Rewr"
  "iterConfig.Toggle\022B\n\027arithmetic_optimiza"
  "tion\030\007 \001(\0162!.tensorflow.RewriterConfig.T"
  "oggle\022B\n\027dependency_optimization\030\010 \001(\0162!"
  ".tensorflow.RewriterConfig.Toggle\022<\n\021loo"
  "p_optimization\030\t \001(\0162!.tensorflow.Rewrit"
  "erConfig.Toggle\022@\n\025function_optimization"
  "\030\n \001(\0162!.tensorflow.RewriterConfig.Toggl"
  "e\0229\n\016debug_stripper\030\013 \001(\0162!.tensorflow.R"
  "ewriterConfig.Toggle\022\035\n\025disable_model_pr"
  "uning\030\002 \001(\010\022H\n\035scoped_allocator_optimiza"
  "tion\030\017 \001(\0162!.tensorflow.RewriterConfig.T"
  "oggle\022C\n\030pin_to_host_optimization\030\022 \001(\0162"
  "!.tensorflow.RewriterConfig.Toggle\022B\n\027im"
  "plementation_selector\030\026 \001(\0162!.tensorflow"
  ".RewriterConfig.Toggle\022\?\n\024auto_mixed_pre"
  "cision\030\027 \001(\0162!.tensorflow.RewriterConfig"
  ".Toggle\022C\n\030auto_mixed_precision_mkl\030\031 \001("
  "\0162!.tensorflow.RewriterConfig.Toggle\022O\n$"
  "auto_mixed_precision_onednn_bfloat16\030\037 \001"
  "(\0162!.tensorflow.RewriterConfig.Toggle\022C\n"
  "\030auto_mixed_precision_cpu\030\035 \001(\0162!.tensor"
  "flow.RewriterConfig.Toggle\022\036\n\026disable_me"
  "ta_optimizer\030\023 \001(\010\022\035\n\025disable_tfg_optimi"
  "zer\030  \001(\010\022@\n\025use_plugin_optimizers\030\034 \001(\016"
  "2!.tensorflow.RewriterConfig.Toggle\022O\n$e"
  "xperimental_conditional_code_motion\030\036 \001("
  "\0162!.tensorflow.RewriterConfig.Toggle\022O\n\031"
  "meta_optimizer_iterations\030\014 \001(\0162,.tensor"
  "flow.RewriterConfig.NumIterationsType\022\027\n"
  "\017min_graph_nodes\030\021 \001(\005\022;\n3experimental_d"
  "isable_compressed_tensor_optimization\030\032 "
  "\001(\010\022;\n3experimental_disable_folding_quan"
  "tization_emulation\030\033 \001(\010\022B\n\023memory_optim"
  "ization\030\004 \001(\0162%.tensorflow.RewriterConfi"
  "g.MemOptType\022/\n\'memory_optimizer_target_"
  "node_name_scope\030\006 \001(\t\022!\n\031meta_optimizer_"
  "timeout_ms\030\024 \001(\003\0226\n\rauto_parallel\030\005 \001(\0132"
  "\037.tensorflow.AutoParallelOptions\022 \n\030fail"
  "_on_optimizer_errors\030\025 \001(\010\022A\n\025scoped_all"
  "ocator_opts\030\020 \001(\0132\".tensorflow.ScopedAll"
  "ocatorOptions\022\022\n\noptimizers\030d \003(\t\022K\n\021cus"
  "tom_optimizers\030\310\001 \003(\0132/.tensorflow.Rewri"
  "terConfig.CustomGraphOptimizer\022D\n\037inter_"
  "optimizer_verifier_config\030\254\002 \001(\0132\032.tenso"
  "rflow.VerifierConfig\022F\n!post_optimizatio"
  "n_verifier_config\030\255\002 \001(\0132\032.tensorflow.Ve"
  "rifierConfig\032\312\001\n\024CustomGraphOptimizer\022\014\n"
  "\004name\030\001 \001(\t\022X\n\rparameter_map\030\002 \003(\0132A.ten"
  "sorflow.RewriterConfig.CustomGraphOptimi"
  "zer.ParameterMapEntry\032J\n\021ParameterMapEnt"
  "ry\022\013\n\003key\030\001 \001(\t\022$\n\005value\030\002 \001(\0132\025.tensorf"
  "low.AttrValue:\0028\001\"d\n\006Toggle\022\013\n\007DEFAULT\020\000"
  "\022\006\n\002ON\020\001\022\007\n\003OFF\020\002\022\016\n\nAGGRESSIVE\020\003\022\025\n\021EXP"
  "ERIMENTAL_MLIR\020\004\022\025\n\021EXPERIMENTAL_BOTH\020\005\""
  "I\n\tCpuLayout\022\030\n\024NO_CONVERSION_ON_CPU\020\000\022\020"
  "\n\014NCHW_TO_NHWC\020\001\022\020\n\014NHWC_TO_NCHW\020\002\"<\n\021Nu"
  "mIterationsType\022\025\n\021DEFAULT_NUM_ITERS\020\000\022\007"
  "\n\003ONE\020\001\022\007\n\003TWO\020\002\"\237\001\n\nMemOptType\022\023\n\017DEFAU"
  "LT_MEM_OPT\020\000\022\016\n\nNO_MEM_OPT\020\001\022\n\n\006MANUAL\020\002"
  "\022\027\n\023SWAPPING_HEURISTICS\020\004\022\034\n\030RECOMPUTATI"
  "ON_HEURISTICS\020\005\022\031\n\025SCHEDULING_HEURISTICS"
  "\020\006\022\016\n\nHEURISTICS\020\003B\214\001\n\030org.tensorflow.fr"
  "ameworkB\024RewriterConfigProtosP\001ZUgithub."
  "com/tensorflow/tensorflow/tensorflow/go/"
  "core/protobuf/for_core_protos_go_proto\370\001"
  "\001b\006proto3"
  ;
static const ::_pbi::DescriptorTable* const descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_deps[2] = {
  &::descriptor_table_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto,
  &::descriptor_table_tensorflow_2fcore_2fprotobuf_2fverifier_5fconfig_2eproto,
};
static ::_pbi::once_flag descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_once;
const ::_pbi::DescriptorTable descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto = {
    false, false, 3249, descriptor_table_protodef_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto,
    "tensorflow/core/protobuf/rewriter_config.proto",
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_once, descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_deps, 2, 5,
    schemas, file_default_instances, TableStruct_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto::offsets,
    file_level_metadata_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto, file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto,
    file_level_service_descriptors_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto,
};
PROTOBUF_ATTRIBUTE_WEAK const ::_pbi::DescriptorTable* descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_getter() {
  return &descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto;
}

// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::_pbi::AddDescriptorsRunner dynamic_init_dummy_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto(&descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto);
namespace tensorflow {
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* RewriterConfig_Toggle_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto);
  return file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto[0];
}
bool RewriterConfig_Toggle_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
    case 3:
    case 4:
    case 5:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr RewriterConfig_Toggle RewriterConfig::DEFAULT;
constexpr RewriterConfig_Toggle RewriterConfig::ON;
constexpr RewriterConfig_Toggle RewriterConfig::OFF;
constexpr RewriterConfig_Toggle RewriterConfig::AGGRESSIVE;
constexpr RewriterConfig_Toggle RewriterConfig::EXPERIMENTAL_MLIR;
constexpr RewriterConfig_Toggle RewriterConfig::EXPERIMENTAL_BOTH;
constexpr RewriterConfig_Toggle RewriterConfig::Toggle_MIN;
constexpr RewriterConfig_Toggle RewriterConfig::Toggle_MAX;
constexpr int RewriterConfig::Toggle_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* RewriterConfig_CpuLayout_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto);
  return file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto[1];
}
bool RewriterConfig_CpuLayout_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr RewriterConfig_CpuLayout RewriterConfig::NO_CONVERSION_ON_CPU;
constexpr RewriterConfig_CpuLayout RewriterConfig::NCHW_TO_NHWC;
constexpr RewriterConfig_CpuLayout RewriterConfig::NHWC_TO_NCHW;
constexpr RewriterConfig_CpuLayout RewriterConfig::CpuLayout_MIN;
constexpr RewriterConfig_CpuLayout RewriterConfig::CpuLayout_MAX;
constexpr int RewriterConfig::CpuLayout_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* RewriterConfig_NumIterationsType_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto);
  return file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto[2];
}
bool RewriterConfig_NumIterationsType_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr RewriterConfig_NumIterationsType RewriterConfig::DEFAULT_NUM_ITERS;
constexpr RewriterConfig_NumIterationsType RewriterConfig::ONE;
constexpr RewriterConfig_NumIterationsType RewriterConfig::TWO;
constexpr RewriterConfig_NumIterationsType RewriterConfig::NumIterationsType_MIN;
constexpr RewriterConfig_NumIterationsType RewriterConfig::NumIterationsType_MAX;
constexpr int RewriterConfig::NumIterationsType_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* RewriterConfig_MemOptType_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto);
  return file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto[3];
}
bool RewriterConfig_MemOptType_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
    case 3:
    case 4:
    case 5:
    case 6:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr RewriterConfig_MemOptType RewriterConfig::DEFAULT_MEM_OPT;
constexpr RewriterConfig_MemOptType RewriterConfig::NO_MEM_OPT;
constexpr RewriterConfig_MemOptType RewriterConfig::MANUAL;
constexpr RewriterConfig_MemOptType RewriterConfig::SWAPPING_HEURISTICS;
constexpr RewriterConfig_MemOptType RewriterConfig::RECOMPUTATION_HEURISTICS;
constexpr RewriterConfig_MemOptType RewriterConfig::SCHEDULING_HEURISTICS;
constexpr RewriterConfig_MemOptType RewriterConfig::HEURISTICS;
constexpr RewriterConfig_MemOptType RewriterConfig::MemOptType_MIN;
constexpr RewriterConfig_MemOptType RewriterConfig::MemOptType_MAX;
constexpr int RewriterConfig::MemOptType_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

// ===================================================================

class AutoParallelOptions::_Internal {
 public:
};

AutoParallelOptions::AutoParallelOptions(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.AutoParallelOptions)
}
AutoParallelOptions::AutoParallelOptions(const AutoParallelOptions& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  AutoParallelOptions* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.enable_){}
    , decltype(_impl_.num_replicas_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.enable_, &from._impl_.enable_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.num_replicas_) -
    reinterpret_cast<char*>(&_impl_.enable_)) + sizeof(_impl_.num_replicas_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.AutoParallelOptions)
}

inline void AutoParallelOptions::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.enable_){false}
    , decltype(_impl_.num_replicas_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

AutoParallelOptions::~AutoParallelOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.AutoParallelOptions)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void AutoParallelOptions::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void AutoParallelOptions::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void AutoParallelOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.AutoParallelOptions)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.enable_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.num_replicas_) -
      reinterpret_cast<char*>(&_impl_.enable_)) + sizeof(_impl_.num_replicas_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* AutoParallelOptions::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // bool enable = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.enable_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 num_replicas = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.num_replicas_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* AutoParallelOptions::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.AutoParallelOptions)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // bool enable = 1;
  if (this->_internal_enable() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(1, this->_internal_enable(), target);
  }

  // int32 num_replicas = 2;
  if (this->_internal_num_replicas() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(2, this->_internal_num_replicas(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.AutoParallelOptions)
  return target;
}

size_t AutoParallelOptions::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.AutoParallelOptions)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // bool enable = 1;
  if (this->_internal_enable() != 0) {
    total_size += 1 + 1;
  }

  // int32 num_replicas = 2;
  if (this->_internal_num_replicas() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_num_replicas());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData AutoParallelOptions::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    AutoParallelOptions::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*AutoParallelOptions::GetClassData() const { return &_class_data_; }


void AutoParallelOptions::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<AutoParallelOptions*>(&to_msg);
  auto& from = static_cast<const AutoParallelOptions&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.AutoParallelOptions)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_enable() != 0) {
    _this->_internal_set_enable(from._internal_enable());
  }
  if (from._internal_num_replicas() != 0) {
    _this->_internal_set_num_replicas(from._internal_num_replicas());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void AutoParallelOptions::CopyFrom(const AutoParallelOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.AutoParallelOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool AutoParallelOptions::IsInitialized() const {
  return true;
}

void AutoParallelOptions::InternalSwap(AutoParallelOptions* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(AutoParallelOptions, _impl_.num_replicas_)
      + sizeof(AutoParallelOptions::_impl_.num_replicas_)
      - PROTOBUF_FIELD_OFFSET(AutoParallelOptions, _impl_.enable_)>(
          reinterpret_cast<char*>(&_impl_.enable_),
          reinterpret_cast<char*>(&other->_impl_.enable_));
}

::PROTOBUF_NAMESPACE_ID::Metadata AutoParallelOptions::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto[0]);
}

// ===================================================================

class ScopedAllocatorOptions::_Internal {
 public:
};

ScopedAllocatorOptions::ScopedAllocatorOptions(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.ScopedAllocatorOptions)
}
ScopedAllocatorOptions::ScopedAllocatorOptions(const ScopedAllocatorOptions& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  ScopedAllocatorOptions* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.enable_op_){from._impl_.enable_op_}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:tensorflow.ScopedAllocatorOptions)
}

inline void ScopedAllocatorOptions::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.enable_op_){arena}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

ScopedAllocatorOptions::~ScopedAllocatorOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.ScopedAllocatorOptions)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void ScopedAllocatorOptions::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.enable_op_.~RepeatedPtrField();
}

void ScopedAllocatorOptions::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void ScopedAllocatorOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ScopedAllocatorOptions)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.enable_op_.Clear();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ScopedAllocatorOptions::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // repeated string enable_op = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr -= 1;
          do {
            ptr += 1;
            auto str = _internal_add_enable_op();
            ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
            CHK_(ptr);
            CHK_(::_pbi::VerifyUTF8(str, "tensorflow.ScopedAllocatorOptions.enable_op"));
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<10>(ptr));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ScopedAllocatorOptions::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ScopedAllocatorOptions)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // repeated string enable_op = 1;
  for (int i = 0, n = this->_internal_enable_op_size(); i < n; i++) {
    const auto& s = this->_internal_enable_op(i);
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      s.data(), static_cast<int>(s.length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.ScopedAllocatorOptions.enable_op");
    target = stream->WriteString(1, s, target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ScopedAllocatorOptions)
  return target;
}

size_t ScopedAllocatorOptions::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.ScopedAllocatorOptions)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated string enable_op = 1;
  total_size += 1 *
      ::PROTOBUF_NAMESPACE_ID::internal::FromIntSize(_impl_.enable_op_.size());
  for (int i = 0, n = _impl_.enable_op_.size(); i < n; i++) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
      _impl_.enable_op_.Get(i));
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ScopedAllocatorOptions::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    ScopedAllocatorOptions::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ScopedAllocatorOptions::GetClassData() const { return &_class_data_; }


void ScopedAllocatorOptions::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<ScopedAllocatorOptions*>(&to_msg);
  auto& from = static_cast<const ScopedAllocatorOptions&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ScopedAllocatorOptions)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.enable_op_.MergeFrom(from._impl_.enable_op_);
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ScopedAllocatorOptions::CopyFrom(const ScopedAllocatorOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ScopedAllocatorOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ScopedAllocatorOptions::IsInitialized() const {
  return true;
}

void ScopedAllocatorOptions::InternalSwap(ScopedAllocatorOptions* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.enable_op_.InternalSwap(&other->_impl_.enable_op_);
}

::PROTOBUF_NAMESPACE_ID::Metadata ScopedAllocatorOptions::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto[1]);
}

// ===================================================================

RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse::RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse() {}
RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse::RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena)
    : SuperType(arena) {}
void RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse::MergeFrom(const RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse& other) {
  MergeFromInternal(other);
}
::PROTOBUF_NAMESPACE_ID::Metadata RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto[2]);
}

// ===================================================================

class RewriterConfig_CustomGraphOptimizer::_Internal {
 public:
};

void RewriterConfig_CustomGraphOptimizer::clear_parameter_map() {
  _impl_.parameter_map_.Clear();
}
RewriterConfig_CustomGraphOptimizer::RewriterConfig_CustomGraphOptimizer(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  if (arena != nullptr && !is_message_owned) {
    arena->OwnCustomDestructor(this, &RewriterConfig_CustomGraphOptimizer::ArenaDtor);
  }
  // @@protoc_insertion_point(arena_constructor:tensorflow.RewriterConfig.CustomGraphOptimizer)
}
RewriterConfig_CustomGraphOptimizer::RewriterConfig_CustomGraphOptimizer(const RewriterConfig_CustomGraphOptimizer& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  RewriterConfig_CustomGraphOptimizer* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      /*decltype(_impl_.parameter_map_)*/{}
    , decltype(_impl_.name_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _this->_impl_.parameter_map_.MergeFrom(from._impl_.parameter_map_);
  _impl_.name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_name().empty()) {
    _this->_impl_.name_.Set(from._internal_name(), 
      _this->GetArenaForAllocation());
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.RewriterConfig.CustomGraphOptimizer)
}

inline void RewriterConfig_CustomGraphOptimizer::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      /*decltype(_impl_.parameter_map_)*/{::_pbi::ArenaInitialized(), arena}
    , decltype(_impl_.name_){}
    , /*decltype(_impl_._cached_size_)*/{}
  };
  _impl_.name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

RewriterConfig_CustomGraphOptimizer::~RewriterConfig_CustomGraphOptimizer() {
  // @@protoc_insertion_point(destructor:tensorflow.RewriterConfig.CustomGraphOptimizer)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    ArenaDtor(this);
    return;
  }
  SharedDtor();
}

inline void RewriterConfig_CustomGraphOptimizer::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.parameter_map_.Destruct();
  _impl_.parameter_map_.~MapField();
  _impl_.name_.Destroy();
}

void RewriterConfig_CustomGraphOptimizer::ArenaDtor(void* object) {
  RewriterConfig_CustomGraphOptimizer* _this = reinterpret_cast< RewriterConfig_CustomGraphOptimizer* >(object);
  _this->_impl_.parameter_map_.Destruct();
}
void RewriterConfig_CustomGraphOptimizer::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void RewriterConfig_CustomGraphOptimizer::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RewriterConfig.CustomGraphOptimizer)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.parameter_map_.Clear();
  _impl_.name_.ClearToEmpty();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* RewriterConfig_CustomGraphOptimizer::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // string name = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_name();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "tensorflow.RewriterConfig.CustomGraphOptimizer.name"));
        } else
          goto handle_unusual;
        continue;
      // map<string, .tensorflow.AttrValue> parameter_map = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(&_impl_.parameter_map_, ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<18>(ptr));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* RewriterConfig_CustomGraphOptimizer::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RewriterConfig.CustomGraphOptimizer)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // string name = 1;
  if (!this->_internal_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_name().data(), static_cast<int>(this->_internal_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RewriterConfig.CustomGraphOptimizer.name");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_name(), target);
  }

  // map<string, .tensorflow.AttrValue> parameter_map = 2;
  if (!this->_internal_parameter_map().empty()) {
    using MapType = ::_pb::Map<std::string, ::tensorflow::AttrValue>;
    using WireHelper = RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse::Funcs;
    const auto& map_field = this->_internal_parameter_map();
    auto check_utf8 = [](const MapType::value_type& entry) {
      (void)entry;
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
        entry.first.data(), static_cast<int>(entry.first.length()),
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
        "tensorflow.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry.key");
    };

    if (stream->IsSerializationDeterministic() && map_field.size() > 1) {
      for (const auto& entry : ::_pbi::MapSorterPtr<MapType>(map_field)) {
        target = WireHelper::InternalSerialize(2, entry.first, entry.second, target, stream);
        check_utf8(entry);
      }
    } else {
      for (const auto& entry : map_field) {
        target = WireHelper::InternalSerialize(2, entry.first, entry.second, target, stream);
        check_utf8(entry);
      }
    }
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RewriterConfig.CustomGraphOptimizer)
  return target;
}

size_t RewriterConfig_CustomGraphOptimizer::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RewriterConfig.CustomGraphOptimizer)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // map<string, .tensorflow.AttrValue> parameter_map = 2;
  total_size += 1 *
      ::PROTOBUF_NAMESPACE_ID::internal::FromIntSize(this->_internal_parameter_map_size());
  for (::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::AttrValue >::const_iterator
      it = this->_internal_parameter_map().begin();
      it != this->_internal_parameter_map().end(); ++it) {
    total_size += RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse::Funcs::ByteSizeLong(it->first, it->second);
  }

  // string name = 1;
  if (!this->_internal_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_name());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData RewriterConfig_CustomGraphOptimizer::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    RewriterConfig_CustomGraphOptimizer::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*RewriterConfig_CustomGraphOptimizer::GetClassData() const { return &_class_data_; }


void RewriterConfig_CustomGraphOptimizer::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<RewriterConfig_CustomGraphOptimizer*>(&to_msg);
  auto& from = static_cast<const RewriterConfig_CustomGraphOptimizer&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RewriterConfig.CustomGraphOptimizer)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.parameter_map_.MergeFrom(from._impl_.parameter_map_);
  if (!from._internal_name().empty()) {
    _this->_internal_set_name(from._internal_name());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void RewriterConfig_CustomGraphOptimizer::CopyFrom(const RewriterConfig_CustomGraphOptimizer& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RewriterConfig.CustomGraphOptimizer)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RewriterConfig_CustomGraphOptimizer::IsInitialized() const {
  return true;
}

void RewriterConfig_CustomGraphOptimizer::InternalSwap(RewriterConfig_CustomGraphOptimizer* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.parameter_map_.InternalSwap(&other->_impl_.parameter_map_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.name_, lhs_arena,
      &other->_impl_.name_, rhs_arena
  );
}

::PROTOBUF_NAMESPACE_ID::Metadata RewriterConfig_CustomGraphOptimizer::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto[3]);
}

// ===================================================================

class RewriterConfig::_Internal {
 public:
  static const ::tensorflow::AutoParallelOptions& auto_parallel(const RewriterConfig* msg);
  static const ::tensorflow::ScopedAllocatorOptions& scoped_allocator_opts(const RewriterConfig* msg);
  static const ::tensorflow::VerifierConfig& inter_optimizer_verifier_config(const RewriterConfig* msg);
  static const ::tensorflow::VerifierConfig& post_optimization_verifier_config(const RewriterConfig* msg);
};

const ::tensorflow::AutoParallelOptions&
RewriterConfig::_Internal::auto_parallel(const RewriterConfig* msg) {
  return *msg->_impl_.auto_parallel_;
}
const ::tensorflow::ScopedAllocatorOptions&
RewriterConfig::_Internal::scoped_allocator_opts(const RewriterConfig* msg) {
  return *msg->_impl_.scoped_allocator_opts_;
}
const ::tensorflow::VerifierConfig&
RewriterConfig::_Internal::inter_optimizer_verifier_config(const RewriterConfig* msg) {
  return *msg->_impl_.inter_optimizer_verifier_config_;
}
const ::tensorflow::VerifierConfig&
RewriterConfig::_Internal::post_optimization_verifier_config(const RewriterConfig* msg) {
  return *msg->_impl_.post_optimization_verifier_config_;
}
void RewriterConfig::clear_inter_optimizer_verifier_config() {
  if (GetArenaForAllocation() == nullptr && _impl_.inter_optimizer_verifier_config_ != nullptr) {
    delete _impl_.inter_optimizer_verifier_config_;
  }
  _impl_.inter_optimizer_verifier_config_ = nullptr;
}
void RewriterConfig::clear_post_optimization_verifier_config() {
  if (GetArenaForAllocation() == nullptr && _impl_.post_optimization_verifier_config_ != nullptr) {
    delete _impl_.post_optimization_verifier_config_;
  }
  _impl_.post_optimization_verifier_config_ = nullptr;
}
RewriterConfig::RewriterConfig(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.RewriterConfig)
}
RewriterConfig::RewriterConfig(const RewriterConfig& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  RewriterConfig* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.optimizers_){from._impl_.optimizers_}
    , decltype(_impl_.custom_optimizers_){from._impl_.custom_optimizers_}
    , decltype(_impl_.memory_optimizer_target_node_name_scope_){}
    , decltype(_impl_.auto_parallel_){nullptr}
    , decltype(_impl_.scoped_allocator_opts_){nullptr}
    , decltype(_impl_.inter_optimizer_verifier_config_){nullptr}
    , decltype(_impl_.post_optimization_verifier_config_){nullptr}
    , decltype(_impl_.layout_optimizer_){}
    , decltype(_impl_.constant_folding_){}
    , decltype(_impl_.memory_optimization_){}
    , decltype(_impl_.arithmetic_optimization_){}
    , decltype(_impl_.dependency_optimization_){}
    , decltype(_impl_.loop_optimization_){}
    , decltype(_impl_.function_optimization_){}
    , decltype(_impl_.debug_stripper_){}
    , decltype(_impl_.meta_optimizer_iterations_){}
    , decltype(_impl_.shape_optimization_){}
    , decltype(_impl_.remapping_){}
    , decltype(_impl_.scoped_allocator_optimization_){}
    , decltype(_impl_.min_graph_nodes_){}
    , decltype(_impl_.pin_to_host_optimization_){}
    , decltype(_impl_.meta_optimizer_timeout_ms_){}
    , decltype(_impl_.disable_model_pruning_){}
    , decltype(_impl_.disable_meta_optimizer_){}
    , decltype(_impl_.disable_tfg_optimizer_){}
    , decltype(_impl_.experimental_disable_compressed_tensor_optimization_){}
    , decltype(_impl_.implementation_selector_){}
    , decltype(_impl_.auto_mixed_precision_){}
    , decltype(_impl_.common_subgraph_elimination_){}
    , decltype(_impl_.experimental_disable_folding_quantization_emulation_){}
    , decltype(_impl_.fail_on_optimizer_errors_){}
    , decltype(_impl_.auto_mixed_precision_mkl_){}
    , decltype(_impl_.use_plugin_optimizers_){}
    , decltype(_impl_.auto_mixed_precision_cpu_){}
    , decltype(_impl_.experimental_conditional_code_motion_){}
    , decltype(_impl_.auto_mixed_precision_onednn_bfloat16_){}
    , decltype(_impl_.cpu_layout_conversion_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _impl_.memory_optimizer_target_node_name_scope_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.memory_optimizer_target_node_name_scope_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_memory_optimizer_target_node_name_scope().empty()) {
    _this->_impl_.memory_optimizer_target_node_name_scope_.Set(from._internal_memory_optimizer_target_node_name_scope(), 
      _this->GetArenaForAllocation());
  }
  if (from._internal_has_auto_parallel()) {
    _this->_impl_.auto_parallel_ = new ::tensorflow::AutoParallelOptions(*from._impl_.auto_parallel_);
  }
  if (from._internal_has_scoped_allocator_opts()) {
    _this->_impl_.scoped_allocator_opts_ = new ::tensorflow::ScopedAllocatorOptions(*from._impl_.scoped_allocator_opts_);
  }
  if (from._internal_has_inter_optimizer_verifier_config()) {
    _this->_impl_.inter_optimizer_verifier_config_ = new ::tensorflow::VerifierConfig(*from._impl_.inter_optimizer_verifier_config_);
  }
  if (from._internal_has_post_optimization_verifier_config()) {
    _this->_impl_.post_optimization_verifier_config_ = new ::tensorflow::VerifierConfig(*from._impl_.post_optimization_verifier_config_);
  }
  ::memcpy(&_impl_.layout_optimizer_, &from._impl_.layout_optimizer_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.cpu_layout_conversion_) -
    reinterpret_cast<char*>(&_impl_.layout_optimizer_)) + sizeof(_impl_.cpu_layout_conversion_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.RewriterConfig)
}

inline void RewriterConfig::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.optimizers_){arena}
    , decltype(_impl_.custom_optimizers_){arena}
    , decltype(_impl_.memory_optimizer_target_node_name_scope_){}
    , decltype(_impl_.auto_parallel_){nullptr}
    , decltype(_impl_.scoped_allocator_opts_){nullptr}
    , decltype(_impl_.inter_optimizer_verifier_config_){nullptr}
    , decltype(_impl_.post_optimization_verifier_config_){nullptr}
    , decltype(_impl_.layout_optimizer_){0}
    , decltype(_impl_.constant_folding_){0}
    , decltype(_impl_.memory_optimization_){0}
    , decltype(_impl_.arithmetic_optimization_){0}
    , decltype(_impl_.dependency_optimization_){0}
    , decltype(_impl_.loop_optimization_){0}
    , decltype(_impl_.function_optimization_){0}
    , decltype(_impl_.debug_stripper_){0}
    , decltype(_impl_.meta_optimizer_iterations_){0}
    , decltype(_impl_.shape_optimization_){0}
    , decltype(_impl_.remapping_){0}
    , decltype(_impl_.scoped_allocator_optimization_){0}
    , decltype(_impl_.min_graph_nodes_){0}
    , decltype(_impl_.pin_to_host_optimization_){0}
    , decltype(_impl_.meta_optimizer_timeout_ms_){int64_t{0}}
    , decltype(_impl_.disable_model_pruning_){false}
    , decltype(_impl_.disable_meta_optimizer_){false}
    , decltype(_impl_.disable_tfg_optimizer_){false}
    , decltype(_impl_.experimental_disable_compressed_tensor_optimization_){false}
    , decltype(_impl_.implementation_selector_){0}
    , decltype(_impl_.auto_mixed_precision_){0}
    , decltype(_impl_.common_subgraph_elimination_){0}
    , decltype(_impl_.experimental_disable_folding_quantization_emulation_){false}
    , decltype(_impl_.fail_on_optimizer_errors_){false}
    , decltype(_impl_.auto_mixed_precision_mkl_){0}
    , decltype(_impl_.use_plugin_optimizers_){0}
    , decltype(_impl_.auto_mixed_precision_cpu_){0}
    , decltype(_impl_.experimental_conditional_code_motion_){0}
    , decltype(_impl_.auto_mixed_precision_onednn_bfloat16_){0}
    , decltype(_impl_.cpu_layout_conversion_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
  _impl_.memory_optimizer_target_node_name_scope_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.memory_optimizer_target_node_name_scope_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

RewriterConfig::~RewriterConfig() {
  // @@protoc_insertion_point(destructor:tensorflow.RewriterConfig)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void RewriterConfig::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.optimizers_.~RepeatedPtrField();
  _impl_.custom_optimizers_.~RepeatedPtrField();
  _impl_.memory_optimizer_target_node_name_scope_.Destroy();
  if (this != internal_default_instance()) delete _impl_.auto_parallel_;
  if (this != internal_default_instance()) delete _impl_.scoped_allocator_opts_;
  if (this != internal_default_instance()) delete _impl_.inter_optimizer_verifier_config_;
  if (this != internal_default_instance()) delete _impl_.post_optimization_verifier_config_;
}

void RewriterConfig::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void RewriterConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RewriterConfig)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.optimizers_.Clear();
  _impl_.custom_optimizers_.Clear();
  _impl_.memory_optimizer_target_node_name_scope_.ClearToEmpty();
  if (GetArenaForAllocation() == nullptr && _impl_.auto_parallel_ != nullptr) {
    delete _impl_.auto_parallel_;
  }
  _impl_.auto_parallel_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.scoped_allocator_opts_ != nullptr) {
    delete _impl_.scoped_allocator_opts_;
  }
  _impl_.scoped_allocator_opts_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.inter_optimizer_verifier_config_ != nullptr) {
    delete _impl_.inter_optimizer_verifier_config_;
  }
  _impl_.inter_optimizer_verifier_config_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.post_optimization_verifier_config_ != nullptr) {
    delete _impl_.post_optimization_verifier_config_;
  }
  _impl_.post_optimization_verifier_config_ = nullptr;
  ::memset(&_impl_.layout_optimizer_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.cpu_layout_conversion_) -
      reinterpret_cast<char*>(&_impl_.layout_optimizer_)) + sizeof(_impl_.cpu_layout_conversion_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* RewriterConfig::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .tensorflow.RewriterConfig.Toggle layout_optimizer = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_layout_optimizer(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // bool disable_model_pruning = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.disable_model_pruning_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle constant_folding = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_constant_folding(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_memory_optimization(static_cast<::tensorflow::RewriterConfig_MemOptType>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.AutoParallelOptions auto_parallel = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 42)) {
          ptr = ctx->ParseMessage(_internal_mutable_auto_parallel(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // string memory_optimizer_target_node_name_scope = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 50)) {
          auto str = _internal_mutable_memory_optimizer_target_node_name_scope();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "tensorflow.RewriterConfig.memory_optimizer_target_node_name_scope"));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;
      case 7:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 56)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_arithmetic_optimization(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle dependency_optimization = 8;
      case 8:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 64)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_dependency_optimization(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle loop_optimization = 9;
      case 9:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 72)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_loop_optimization(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle function_optimization = 10;
      case 10:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 80)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_function_optimization(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle debug_stripper = 11;
      case 11:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 88)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_debug_stripper(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;
      case 12:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 96)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_meta_optimizer_iterations(static_cast<::tensorflow::RewriterConfig_NumIterationsType>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle shape_optimization = 13;
      case 13:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 104)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_shape_optimization(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle remapping = 14;
      case 14:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 112)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_remapping(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;
      case 15:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 120)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_scoped_allocator_optimization(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;
      case 16:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 130)) {
          ptr = ctx->ParseMessage(_internal_mutable_scoped_allocator_opts(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 min_graph_nodes = 17;
      case 17:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 136)) {
          _impl_.min_graph_nodes_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;
      case 18:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 144)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_pin_to_host_optimization(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // bool disable_meta_optimizer = 19;
      case 19:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 152)) {
          _impl_.disable_meta_optimizer_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int64 meta_optimizer_timeout_ms = 20;
      case 20:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 160)) {
          _impl_.meta_optimizer_timeout_ms_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // bool fail_on_optimizer_errors = 21;
      case 21:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 168)) {
          _impl_.fail_on_optimizer_errors_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle implementation_selector = 22;
      case 22:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 176)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_implementation_selector(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle auto_mixed_precision = 23;
      case 23:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 184)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_auto_mixed_precision(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle common_subgraph_elimination = 24;
      case 24:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 192)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_common_subgraph_elimination(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle auto_mixed_precision_mkl = 25;
      case 25:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 200)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_auto_mixed_precision_mkl(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // bool experimental_disable_compressed_tensor_optimization = 26;
      case 26:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 208)) {
          _impl_.experimental_disable_compressed_tensor_optimization_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // bool experimental_disable_folding_quantization_emulation = 27;
      case 27:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 216)) {
          _impl_.experimental_disable_folding_quantization_emulation_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle use_plugin_optimizers = 28;
      case 28:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 224)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_use_plugin_optimizers(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle auto_mixed_precision_cpu = 29;
      case 29:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 232)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_auto_mixed_precision_cpu(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle experimental_conditional_code_motion = 30;
      case 30:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 240)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_experimental_conditional_code_motion(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.Toggle auto_mixed_precision_onednn_bfloat16 = 31;
      case 31:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 248)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_auto_mixed_precision_onednn_bfloat16(static_cast<::tensorflow::RewriterConfig_Toggle>(val));
        } else
          goto handle_unusual;
        continue;
      // bool disable_tfg_optimizer = 32;
      case 32:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 0)) {
          _impl_.disable_tfg_optimizer_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.RewriterConfig.CpuLayout cpu_layout_conversion = 50;
      case 50:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 144)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_cpu_layout_conversion(static_cast<::tensorflow::RewriterConfig_CpuLayout>(val));
        } else
          goto handle_unusual;
        continue;
      // repeated string optimizers = 100;
      case 100:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
          ptr -= 2;
          do {
            ptr += 2;
            auto str = _internal_add_optimizers();
            ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
            CHK_(ptr);
            CHK_(::_pbi::VerifyUTF8(str, "tensorflow.RewriterConfig.optimizers"));
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<802>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;
      case 200:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 66)) {
          ptr -= 2;
          do {
            ptr += 2;
            ptr = ctx->ParseMessage(_internal_add_custom_optimizers(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<1602>(ptr));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;
      case 300:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 98)) {
          ptr = ctx->ParseMessage(_internal_mutable_inter_optimizer_verifier_config(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.VerifierConfig post_optimization_verifier_config = 301;
      case 301:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 106)) {
          ptr = ctx->ParseMessage(_internal_mutable_post_optimization_verifier_config(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* RewriterConfig::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RewriterConfig)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.RewriterConfig.Toggle layout_optimizer = 1;
  if (this->_internal_layout_optimizer() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      1, this->_internal_layout_optimizer(), target);
  }

  // bool disable_model_pruning = 2;
  if (this->_internal_disable_model_pruning() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(2, this->_internal_disable_model_pruning(), target);
  }

  // .tensorflow.RewriterConfig.Toggle constant_folding = 3;
  if (this->_internal_constant_folding() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      3, this->_internal_constant_folding(), target);
  }

  // .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;
  if (this->_internal_memory_optimization() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      4, this->_internal_memory_optimization(), target);
  }

  // .tensorflow.AutoParallelOptions auto_parallel = 5;
  if (this->_internal_has_auto_parallel()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(5, _Internal::auto_parallel(this),
        _Internal::auto_parallel(this).GetCachedSize(), target, stream);
  }

  // string memory_optimizer_target_node_name_scope = 6;
  if (!this->_internal_memory_optimizer_target_node_name_scope().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_memory_optimizer_target_node_name_scope().data(), static_cast<int>(this->_internal_memory_optimizer_target_node_name_scope().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RewriterConfig.memory_optimizer_target_node_name_scope");
    target = stream->WriteStringMaybeAliased(
        6, this->_internal_memory_optimizer_target_node_name_scope(), target);
  }

  // .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;
  if (this->_internal_arithmetic_optimization() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      7, this->_internal_arithmetic_optimization(), target);
  }

  // .tensorflow.RewriterConfig.Toggle dependency_optimization = 8;
  if (this->_internal_dependency_optimization() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      8, this->_internal_dependency_optimization(), target);
  }

  // .tensorflow.RewriterConfig.Toggle loop_optimization = 9;
  if (this->_internal_loop_optimization() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      9, this->_internal_loop_optimization(), target);
  }

  // .tensorflow.RewriterConfig.Toggle function_optimization = 10;
  if (this->_internal_function_optimization() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      10, this->_internal_function_optimization(), target);
  }

  // .tensorflow.RewriterConfig.Toggle debug_stripper = 11;
  if (this->_internal_debug_stripper() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      11, this->_internal_debug_stripper(), target);
  }

  // .tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;
  if (this->_internal_meta_optimizer_iterations() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      12, this->_internal_meta_optimizer_iterations(), target);
  }

  // .tensorflow.RewriterConfig.Toggle shape_optimization = 13;
  if (this->_internal_shape_optimization() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      13, this->_internal_shape_optimization(), target);
  }

  // .tensorflow.RewriterConfig.Toggle remapping = 14;
  if (this->_internal_remapping() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      14, this->_internal_remapping(), target);
  }

  // .tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;
  if (this->_internal_scoped_allocator_optimization() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      15, this->_internal_scoped_allocator_optimization(), target);
  }

  // .tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;
  if (this->_internal_has_scoped_allocator_opts()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(16, _Internal::scoped_allocator_opts(this),
        _Internal::scoped_allocator_opts(this).GetCachedSize(), target, stream);
  }

  // int32 min_graph_nodes = 17;
  if (this->_internal_min_graph_nodes() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(17, this->_internal_min_graph_nodes(), target);
  }

  // .tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;
  if (this->_internal_pin_to_host_optimization() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      18, this->_internal_pin_to_host_optimization(), target);
  }

  // bool disable_meta_optimizer = 19;
  if (this->_internal_disable_meta_optimizer() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(19, this->_internal_disable_meta_optimizer(), target);
  }

  // int64 meta_optimizer_timeout_ms = 20;
  if (this->_internal_meta_optimizer_timeout_ms() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt64ToArray(20, this->_internal_meta_optimizer_timeout_ms(), target);
  }

  // bool fail_on_optimizer_errors = 21;
  if (this->_internal_fail_on_optimizer_errors() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(21, this->_internal_fail_on_optimizer_errors(), target);
  }

  // .tensorflow.RewriterConfig.Toggle implementation_selector = 22;
  if (this->_internal_implementation_selector() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      22, this->_internal_implementation_selector(), target);
  }

  // .tensorflow.RewriterConfig.Toggle auto_mixed_precision = 23;
  if (this->_internal_auto_mixed_precision() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      23, this->_internal_auto_mixed_precision(), target);
  }

  // .tensorflow.RewriterConfig.Toggle common_subgraph_elimination = 24;
  if (this->_internal_common_subgraph_elimination() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      24, this->_internal_common_subgraph_elimination(), target);
  }

  // .tensorflow.RewriterConfig.Toggle auto_mixed_precision_mkl = 25;
  if (this->_internal_auto_mixed_precision_mkl() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      25, this->_internal_auto_mixed_precision_mkl(), target);
  }

  // bool experimental_disable_compressed_tensor_optimization = 26;
  if (this->_internal_experimental_disable_compressed_tensor_optimization() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(26, this->_internal_experimental_disable_compressed_tensor_optimization(), target);
  }

  // bool experimental_disable_folding_quantization_emulation = 27;
  if (this->_internal_experimental_disable_folding_quantization_emulation() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(27, this->_internal_experimental_disable_folding_quantization_emulation(), target);
  }

  // .tensorflow.RewriterConfig.Toggle use_plugin_optimizers = 28;
  if (this->_internal_use_plugin_optimizers() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      28, this->_internal_use_plugin_optimizers(), target);
  }

  // .tensorflow.RewriterConfig.Toggle auto_mixed_precision_cpu = 29;
  if (this->_internal_auto_mixed_precision_cpu() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      29, this->_internal_auto_mixed_precision_cpu(), target);
  }

  // .tensorflow.RewriterConfig.Toggle experimental_conditional_code_motion = 30;
  if (this->_internal_experimental_conditional_code_motion() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      30, this->_internal_experimental_conditional_code_motion(), target);
  }

  // .tensorflow.RewriterConfig.Toggle auto_mixed_precision_onednn_bfloat16 = 31;
  if (this->_internal_auto_mixed_precision_onednn_bfloat16() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      31, this->_internal_auto_mixed_precision_onednn_bfloat16(), target);
  }

  // bool disable_tfg_optimizer = 32;
  if (this->_internal_disable_tfg_optimizer() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(32, this->_internal_disable_tfg_optimizer(), target);
  }

  // .tensorflow.RewriterConfig.CpuLayout cpu_layout_conversion = 50;
  if (this->_internal_cpu_layout_conversion() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      50, this->_internal_cpu_layout_conversion(), target);
  }

  // repeated string optimizers = 100;
  for (int i = 0, n = this->_internal_optimizers_size(); i < n; i++) {
    const auto& s = this->_internal_optimizers(i);
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      s.data(), static_cast<int>(s.length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RewriterConfig.optimizers");
    target = stream->WriteString(100, s, target);
  }

  // repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_custom_optimizers_size()); i < n; i++) {
    const auto& repfield = this->_internal_custom_optimizers(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(200, repfield, repfield.GetCachedSize(), target, stream);
  }

  // .tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;
  if (this->_internal_has_inter_optimizer_verifier_config()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(300, _Internal::inter_optimizer_verifier_config(this),
        _Internal::inter_optimizer_verifier_config(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.VerifierConfig post_optimization_verifier_config = 301;
  if (this->_internal_has_post_optimization_verifier_config()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(301, _Internal::post_optimization_verifier_config(this),
        _Internal::post_optimization_verifier_config(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RewriterConfig)
  return target;
}

size_t RewriterConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RewriterConfig)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated string optimizers = 100;
  total_size += 2 *
      ::PROTOBUF_NAMESPACE_ID::internal::FromIntSize(_impl_.optimizers_.size());
  for (int i = 0, n = _impl_.optimizers_.size(); i < n; i++) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
      _impl_.optimizers_.Get(i));
  }

  // repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;
  total_size += 2UL * this->_internal_custom_optimizers_size();
  for (const auto& msg : this->_impl_.custom_optimizers_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // string memory_optimizer_target_node_name_scope = 6;
  if (!this->_internal_memory_optimizer_target_node_name_scope().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_memory_optimizer_target_node_name_scope());
  }

  // .tensorflow.AutoParallelOptions auto_parallel = 5;
  if (this->_internal_has_auto_parallel()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.auto_parallel_);
  }

  // .tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;
  if (this->_internal_has_scoped_allocator_opts()) {
    total_size += 2 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.scoped_allocator_opts_);
  }

  // .tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;
  if (this->_internal_has_inter_optimizer_verifier_config()) {
    total_size += 2 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.inter_optimizer_verifier_config_);
  }

  // .tensorflow.VerifierConfig post_optimization_verifier_config = 301;
  if (this->_internal_has_post_optimization_verifier_config()) {
    total_size += 2 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.post_optimization_verifier_config_);
  }

  // .tensorflow.RewriterConfig.Toggle layout_optimizer = 1;
  if (this->_internal_layout_optimizer() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_layout_optimizer());
  }

  // .tensorflow.RewriterConfig.Toggle constant_folding = 3;
  if (this->_internal_constant_folding() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_constant_folding());
  }

  // .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;
  if (this->_internal_memory_optimization() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_memory_optimization());
  }

  // .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;
  if (this->_internal_arithmetic_optimization() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_arithmetic_optimization());
  }

  // .tensorflow.RewriterConfig.Toggle dependency_optimization = 8;
  if (this->_internal_dependency_optimization() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_dependency_optimization());
  }

  // .tensorflow.RewriterConfig.Toggle loop_optimization = 9;
  if (this->_internal_loop_optimization() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_loop_optimization());
  }

  // .tensorflow.RewriterConfig.Toggle function_optimization = 10;
  if (this->_internal_function_optimization() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_function_optimization());
  }

  // .tensorflow.RewriterConfig.Toggle debug_stripper = 11;
  if (this->_internal_debug_stripper() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_debug_stripper());
  }

  // .tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;
  if (this->_internal_meta_optimizer_iterations() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_meta_optimizer_iterations());
  }

  // .tensorflow.RewriterConfig.Toggle shape_optimization = 13;
  if (this->_internal_shape_optimization() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_shape_optimization());
  }

  // .tensorflow.RewriterConfig.Toggle remapping = 14;
  if (this->_internal_remapping() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_remapping());
  }

  // .tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;
  if (this->_internal_scoped_allocator_optimization() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_scoped_allocator_optimization());
  }

  // int32 min_graph_nodes = 17;
  if (this->_internal_min_graph_nodes() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::Int32Size(
        this->_internal_min_graph_nodes());
  }

  // .tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;
  if (this->_internal_pin_to_host_optimization() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_pin_to_host_optimization());
  }

  // int64 meta_optimizer_timeout_ms = 20;
  if (this->_internal_meta_optimizer_timeout_ms() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::Int64Size(
        this->_internal_meta_optimizer_timeout_ms());
  }

  // bool disable_model_pruning = 2;
  if (this->_internal_disable_model_pruning() != 0) {
    total_size += 1 + 1;
  }

  // bool disable_meta_optimizer = 19;
  if (this->_internal_disable_meta_optimizer() != 0) {
    total_size += 2 + 1;
  }

  // bool disable_tfg_optimizer = 32;
  if (this->_internal_disable_tfg_optimizer() != 0) {
    total_size += 2 + 1;
  }

  // bool experimental_disable_compressed_tensor_optimization = 26;
  if (this->_internal_experimental_disable_compressed_tensor_optimization() != 0) {
    total_size += 2 + 1;
  }

  // .tensorflow.RewriterConfig.Toggle implementation_selector = 22;
  if (this->_internal_implementation_selector() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_implementation_selector());
  }

  // .tensorflow.RewriterConfig.Toggle auto_mixed_precision = 23;
  if (this->_internal_auto_mixed_precision() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_auto_mixed_precision());
  }

  // .tensorflow.RewriterConfig.Toggle common_subgraph_elimination = 24;
  if (this->_internal_common_subgraph_elimination() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_common_subgraph_elimination());
  }

  // bool experimental_disable_folding_quantization_emulation = 27;
  if (this->_internal_experimental_disable_folding_quantization_emulation() != 0) {
    total_size += 2 + 1;
  }

  // bool fail_on_optimizer_errors = 21;
  if (this->_internal_fail_on_optimizer_errors() != 0) {
    total_size += 2 + 1;
  }

  // .tensorflow.RewriterConfig.Toggle auto_mixed_precision_mkl = 25;
  if (this->_internal_auto_mixed_precision_mkl() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_auto_mixed_precision_mkl());
  }

  // .tensorflow.RewriterConfig.Toggle use_plugin_optimizers = 28;
  if (this->_internal_use_plugin_optimizers() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_use_plugin_optimizers());
  }

  // .tensorflow.RewriterConfig.Toggle auto_mixed_precision_cpu = 29;
  if (this->_internal_auto_mixed_precision_cpu() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_auto_mixed_precision_cpu());
  }

  // .tensorflow.RewriterConfig.Toggle experimental_conditional_code_motion = 30;
  if (this->_internal_experimental_conditional_code_motion() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_experimental_conditional_code_motion());
  }

  // .tensorflow.RewriterConfig.Toggle auto_mixed_precision_onednn_bfloat16 = 31;
  if (this->_internal_auto_mixed_precision_onednn_bfloat16() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_auto_mixed_precision_onednn_bfloat16());
  }

  // .tensorflow.RewriterConfig.CpuLayout cpu_layout_conversion = 50;
  if (this->_internal_cpu_layout_conversion() != 0) {
    total_size += 2 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_cpu_layout_conversion());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData RewriterConfig::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    RewriterConfig::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*RewriterConfig::GetClassData() const { return &_class_data_; }


void RewriterConfig::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<RewriterConfig*>(&to_msg);
  auto& from = static_cast<const RewriterConfig&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RewriterConfig)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.optimizers_.MergeFrom(from._impl_.optimizers_);
  _this->_impl_.custom_optimizers_.MergeFrom(from._impl_.custom_optimizers_);
  if (!from._internal_memory_optimizer_target_node_name_scope().empty()) {
    _this->_internal_set_memory_optimizer_target_node_name_scope(from._internal_memory_optimizer_target_node_name_scope());
  }
  if (from._internal_has_auto_parallel()) {
    _this->_internal_mutable_auto_parallel()->::tensorflow::AutoParallelOptions::MergeFrom(
        from._internal_auto_parallel());
  }
  if (from._internal_has_scoped_allocator_opts()) {
    _this->_internal_mutable_scoped_allocator_opts()->::tensorflow::ScopedAllocatorOptions::MergeFrom(
        from._internal_scoped_allocator_opts());
  }
  if (from._internal_has_inter_optimizer_verifier_config()) {
    _this->_internal_mutable_inter_optimizer_verifier_config()->::tensorflow::VerifierConfig::MergeFrom(
        from._internal_inter_optimizer_verifier_config());
  }
  if (from._internal_has_post_optimization_verifier_config()) {
    _this->_internal_mutable_post_optimization_verifier_config()->::tensorflow::VerifierConfig::MergeFrom(
        from._internal_post_optimization_verifier_config());
  }
  if (from._internal_layout_optimizer() != 0) {
    _this->_internal_set_layout_optimizer(from._internal_layout_optimizer());
  }
  if (from._internal_constant_folding() != 0) {
    _this->_internal_set_constant_folding(from._internal_constant_folding());
  }
  if (from._internal_memory_optimization() != 0) {
    _this->_internal_set_memory_optimization(from._internal_memory_optimization());
  }
  if (from._internal_arithmetic_optimization() != 0) {
    _this->_internal_set_arithmetic_optimization(from._internal_arithmetic_optimization());
  }
  if (from._internal_dependency_optimization() != 0) {
    _this->_internal_set_dependency_optimization(from._internal_dependency_optimization());
  }
  if (from._internal_loop_optimization() != 0) {
    _this->_internal_set_loop_optimization(from._internal_loop_optimization());
  }
  if (from._internal_function_optimization() != 0) {
    _this->_internal_set_function_optimization(from._internal_function_optimization());
  }
  if (from._internal_debug_stripper() != 0) {
    _this->_internal_set_debug_stripper(from._internal_debug_stripper());
  }
  if (from._internal_meta_optimizer_iterations() != 0) {
    _this->_internal_set_meta_optimizer_iterations(from._internal_meta_optimizer_iterations());
  }
  if (from._internal_shape_optimization() != 0) {
    _this->_internal_set_shape_optimization(from._internal_shape_optimization());
  }
  if (from._internal_remapping() != 0) {
    _this->_internal_set_remapping(from._internal_remapping());
  }
  if (from._internal_scoped_allocator_optimization() != 0) {
    _this->_internal_set_scoped_allocator_optimization(from._internal_scoped_allocator_optimization());
  }
  if (from._internal_min_graph_nodes() != 0) {
    _this->_internal_set_min_graph_nodes(from._internal_min_graph_nodes());
  }
  if (from._internal_pin_to_host_optimization() != 0) {
    _this->_internal_set_pin_to_host_optimization(from._internal_pin_to_host_optimization());
  }
  if (from._internal_meta_optimizer_timeout_ms() != 0) {
    _this->_internal_set_meta_optimizer_timeout_ms(from._internal_meta_optimizer_timeout_ms());
  }
  if (from._internal_disable_model_pruning() != 0) {
    _this->_internal_set_disable_model_pruning(from._internal_disable_model_pruning());
  }
  if (from._internal_disable_meta_optimizer() != 0) {
    _this->_internal_set_disable_meta_optimizer(from._internal_disable_meta_optimizer());
  }
  if (from._internal_disable_tfg_optimizer() != 0) {
    _this->_internal_set_disable_tfg_optimizer(from._internal_disable_tfg_optimizer());
  }
  if (from._internal_experimental_disable_compressed_tensor_optimization() != 0) {
    _this->_internal_set_experimental_disable_compressed_tensor_optimization(from._internal_experimental_disable_compressed_tensor_optimization());
  }
  if (from._internal_implementation_selector() != 0) {
    _this->_internal_set_implementation_selector(from._internal_implementation_selector());
  }
  if (from._internal_auto_mixed_precision() != 0) {
    _this->_internal_set_auto_mixed_precision(from._internal_auto_mixed_precision());
  }
  if (from._internal_common_subgraph_elimination() != 0) {
    _this->_internal_set_common_subgraph_elimination(from._internal_common_subgraph_elimination());
  }
  if (from._internal_experimental_disable_folding_quantization_emulation() != 0) {
    _this->_internal_set_experimental_disable_folding_quantization_emulation(from._internal_experimental_disable_folding_quantization_emulation());
  }
  if (from._internal_fail_on_optimizer_errors() != 0) {
    _this->_internal_set_fail_on_optimizer_errors(from._internal_fail_on_optimizer_errors());
  }
  if (from._internal_auto_mixed_precision_mkl() != 0) {
    _this->_internal_set_auto_mixed_precision_mkl(from._internal_auto_mixed_precision_mkl());
  }
  if (from._internal_use_plugin_optimizers() != 0) {
    _this->_internal_set_use_plugin_optimizers(from._internal_use_plugin_optimizers());
  }
  if (from._internal_auto_mixed_precision_cpu() != 0) {
    _this->_internal_set_auto_mixed_precision_cpu(from._internal_auto_mixed_precision_cpu());
  }
  if (from._internal_experimental_conditional_code_motion() != 0) {
    _this->_internal_set_experimental_conditional_code_motion(from._internal_experimental_conditional_code_motion());
  }
  if (from._internal_auto_mixed_precision_onednn_bfloat16() != 0) {
    _this->_internal_set_auto_mixed_precision_onednn_bfloat16(from._internal_auto_mixed_precision_onednn_bfloat16());
  }
  if (from._internal_cpu_layout_conversion() != 0) {
    _this->_internal_set_cpu_layout_conversion(from._internal_cpu_layout_conversion());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void RewriterConfig::CopyFrom(const RewriterConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RewriterConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RewriterConfig::IsInitialized() const {
  return true;
}

void RewriterConfig::InternalSwap(RewriterConfig* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.optimizers_.InternalSwap(&other->_impl_.optimizers_);
  _impl_.custom_optimizers_.InternalSwap(&other->_impl_.custom_optimizers_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.memory_optimizer_target_node_name_scope_, lhs_arena,
      &other->_impl_.memory_optimizer_target_node_name_scope_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RewriterConfig, _impl_.cpu_layout_conversion_)
      + sizeof(RewriterConfig::_impl_.cpu_layout_conversion_)
      - PROTOBUF_FIELD_OFFSET(RewriterConfig, _impl_.auto_parallel_)>(
          reinterpret_cast<char*>(&_impl_.auto_parallel_),
          reinterpret_cast<char*>(&other->_impl_.auto_parallel_));
}

::PROTOBUF_NAMESPACE_ID::Metadata RewriterConfig::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_getter, &descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto_once,
      file_level_metadata_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto[4]);
}

// @@protoc_insertion_point(namespace_scope)
}  // namespace tensorflow
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::tensorflow::AutoParallelOptions*
Arena::CreateMaybeMessage< ::tensorflow::AutoParallelOptions >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::AutoParallelOptions >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::ScopedAllocatorOptions*
Arena::CreateMaybeMessage< ::tensorflow::ScopedAllocatorOptions >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::ScopedAllocatorOptions >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse*
Arena::CreateMaybeMessage< ::tensorflow::RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::RewriterConfig_CustomGraphOptimizer*
Arena::CreateMaybeMessage< ::tensorflow::RewriterConfig_CustomGraphOptimizer >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::RewriterConfig_CustomGraphOptimizer >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::RewriterConfig*
Arena::CreateMaybeMessage< ::tensorflow::RewriterConfig >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::RewriterConfig >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
